{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç HTML data extraction for TTD Newsletter\n",
    "\n",
    "This notebook is used to find, test, and evaluate methods of extraction over HTML data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_url</th>\n",
       "      <th>link_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4426</td>\n",
       "      <td>4379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3137</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://jobs.ashbyhq.com/tldr.tech</td>\n",
       "      <td>venturebeat.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  link_url      link_domain\n",
       "count                                 4426             4379\n",
       "unique                                3137              103\n",
       "top     https://jobs.ashbyhq.com/tldr.tech  venturebeat.com\n",
       "freq                                    20              283"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "good_articles = pd.read_csv('../research/data/good_articles.csv')\n",
    "good_articles = good_articles[['link_url', 'link_domain']]\n",
    "good_articles.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 methods to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from publicsuffix2 import get_sld\n",
    "\n",
    "def extract_domain_urllib(url):\n",
    "    \"\"\"\n",
    "    Extracts the domain name from a URL using urllib.parse.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL string.\n",
    "\n",
    "    Returns:\n",
    "    str: The domain name.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    parsed_url = parsed_url.netloc\n",
    "    parsed_url = re.sub(r'^www.', '', parsed_url)\n",
    "    return parsed_url\n",
    "\n",
    "def extract_domain_regex(url):\n",
    "    \"\"\"\n",
    "    Extracts the domain name from a URL using regular expressions.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL string.\n",
    "\n",
    "    Returns:\n",
    "    str: The domain name, or None if no match is found.\n",
    "    \"\"\"\n",
    "    pattern = r'(?<=://)([^/]+)'\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        parsed_url = re.sub(r'^www.', '', match.group(1))\n",
    "        return parsed_url\n",
    "    return None\n",
    "\n",
    "def extract_root_domain_psl(url):\n",
    "    \"\"\"\n",
    "    Extracts the root domain from a URL using publicsuffix2.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL string.\n",
    "\n",
    "    Returns:\n",
    "    str: The root domain.\n",
    "    \"\"\"\n",
    "    domain = urlparse(url).netloc\n",
    "    return get_sld(domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_articles['domain_urllib'] = good_articles['link_url'].apply(extract_domain_urllib)\n",
    "good_articles['domain_regex'] = good_articles['link_url'].apply(extract_domain_regex)\n",
    "good_articles['root_domain_psl'] = good_articles['link_url'].apply(extract_root_domain_psl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_articles['match_urllib'] = good_articles['domain_urllib'] == good_articles['link_domain']\n",
    "good_articles['match_regex'] = good_articles['domain_regex'] == good_articles['link_domain']\n",
    "good_articles['match_psl'] = good_articles['root_domain_psl'] == good_articles['link_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_url</th>\n",
       "      <th>link_domain</th>\n",
       "      <th>domain_urllib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://hai.stanford.edu/news/hallucinating-la...</td>\n",
       "      <td>stanford.edu</td>\n",
       "      <td>hai.stanford.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://blog.research.google/2024/02/a-decoder...</td>\n",
       "      <td>research.google</td>\n",
       "      <td>blog.research.google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://aws.amazon.com/blogs/apn/automating-si...</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>aws.amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://docs.google.com/presentation/d/14b5gkR...</td>\n",
       "      <td>google.com</td>\n",
       "      <td>docs.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://home.mlops.community/public/videos/mlo...</td>\n",
       "      <td>mlops.community</td>\n",
       "      <td>home.mlops.community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://blog.allenai.org/olmo-open-language-mo...</td>\n",
       "      <td>allenai.org</td>\n",
       "      <td>blog.allenai.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://docs.llamaindex.ai/en/latest/examples/...</td>\n",
       "      <td>llamaindex.ai</td>\n",
       "      <td>docs.llamaindex.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>https://blog.langchain.dev/winning-in-ai-means...</td>\n",
       "      <td>langchain.dev</td>\n",
       "      <td>blog.langchain.dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://ai.meta.com/blog/v-jepa-yann-lecun-ai-...</td>\n",
       "      <td>meta.com</td>\n",
       "      <td>ai.meta.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>https://bair.berkeley.edu/blog/2024/02/18/comp...</td>\n",
       "      <td>berkeley.edu</td>\n",
       "      <td>bair.berkeley.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>https://developer.microsoft.com/en-us/reactor/...</td>\n",
       "      <td>microsoft.com</td>\n",
       "      <td>developer.microsoft.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>https://txt.cohere.com/command-r/</td>\n",
       "      <td>cohere.com</td>\n",
       "      <td>txt.cohere.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>https://podcasts.apple.com/us/podcast/lets-tal...</td>\n",
       "      <td>apple.com</td>\n",
       "      <td>podcasts.apple.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>https://platform.openai.com/docs/chatgpt-educa...</td>\n",
       "      <td>openai.com</td>\n",
       "      <td>platform.openai.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>https://cajundiscordian.medium.com/is-lamda-se...</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>cajundiscordian.medium.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>https://news.mit.edu/2024/ai-generates-high-qu...</td>\n",
       "      <td>mit.edu</td>\n",
       "      <td>news.mit.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>https://spectrum.ieee.org/humanoid-robot-apptr...</td>\n",
       "      <td>ieee.org</td>\n",
       "      <td>spectrum.ieee.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>/privacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>https://dev-discuss.pytorch.org/t/meta-pytorch...</td>\n",
       "      <td>pytorch.org</td>\n",
       "      <td>dev-discuss.pytorch.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>https://about.fb.com/news/2025/02/meta-ai-laun...</td>\n",
       "      <td>fb.com</td>\n",
       "      <td>about.fb.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>https://developers.googleblog.com/en/gemini-em...</td>\n",
       "      <td>googleblog.com</td>\n",
       "      <td>developers.googleblog.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>https://research.nvidia.com/labs/lpr/storm/?ut...</td>\n",
       "      <td>nvidia.com</td>\n",
       "      <td>research.nvidia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>https://heartbeat.comet.ml/how-to-build-a-text...</td>\n",
       "      <td>comet.ml</td>\n",
       "      <td>heartbeat.comet.ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>https://blog.tensorflow.org/2022/11/building-t...</td>\n",
       "      <td>tensorflow.org</td>\n",
       "      <td>blog.tensorflow.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>https://community.arm.com/developer/ip-product...</td>\n",
       "      <td>arm.com</td>\n",
       "      <td>community.arm.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>https://app.wandb.ai/sayakpaul/tale-of-quantiz...</td>\n",
       "      <td>wandb.ai</td>\n",
       "      <td>app.wandb.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>https://ai.facebook.com/blog/textless-nlp-gene...</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>ai.facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>https://txt.cohere.ai/introducing-sandbox-cohe...</td>\n",
       "      <td>cohere.ai</td>\n",
       "      <td>txt.cohere.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>https://heartbeat.fritz.ai/sentiment-analysis-...</td>\n",
       "      <td>fritz.ai</td>\n",
       "      <td>heartbeat.fritz.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>https://blog.arduino.cc/2021/09/24/arduino-nic...</td>\n",
       "      <td>arduino.cc</td>\n",
       "      <td>blog.arduino.cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>https://haystack.deepset.ai/blog/langfuse-inte...</td>\n",
       "      <td>deepset.ai</td>\n",
       "      <td>haystack.deepset.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3579371.3589049</td>\n",
       "      <td>acm.org</td>\n",
       "      <td>dl.acm.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>https://research.ibm.com/blog/foundation-model...</td>\n",
       "      <td>ibm.com</td>\n",
       "      <td>research.ibm.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>https://blog.ml.cmu.edu/2025/01/02/inductive-b...</td>\n",
       "      <td>cmu.edu</td>\n",
       "      <td>blog.ml.cmu.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>https://magazine.sebastianraschka.com/p/llm-tr...</td>\n",
       "      <td>sebastianraschka.com</td>\n",
       "      <td>magazine.sebastianraschka.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>https://assets.anthropic.com/m/7e1ab885d1b2417...</td>\n",
       "      <td>anthropic.com</td>\n",
       "      <td>assets.anthropic.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               link_url           link_domain  \\\n",
       "10    https://hai.stanford.edu/news/hallucinating-la...          stanford.edu   \n",
       "11    https://blog.research.google/2024/02/a-decoder...       research.google   \n",
       "13    https://aws.amazon.com/blogs/apn/automating-si...            amazon.com   \n",
       "14    https://docs.google.com/presentation/d/14b5gkR...            google.com   \n",
       "16    https://home.mlops.community/public/videos/mlo...       mlops.community   \n",
       "19    https://blog.allenai.org/olmo-open-language-mo...           allenai.org   \n",
       "30    https://docs.llamaindex.ai/en/latest/examples/...         llamaindex.ai   \n",
       "36    https://blog.langchain.dev/winning-in-ai-means...         langchain.dev   \n",
       "37    https://ai.meta.com/blog/v-jepa-yann-lecun-ai-...              meta.com   \n",
       "41    https://bair.berkeley.edu/blog/2024/02/18/comp...          berkeley.edu   \n",
       "58    https://developer.microsoft.com/en-us/reactor/...         microsoft.com   \n",
       "66                    https://txt.cohere.com/command-r/            cohere.com   \n",
       "117   https://podcasts.apple.com/us/podcast/lets-tal...             apple.com   \n",
       "127   https://platform.openai.com/docs/chatgpt-educa...            openai.com   \n",
       "130   https://cajundiscordian.medium.com/is-lamda-se...            medium.com   \n",
       "187   https://news.mit.edu/2024/ai-generates-high-qu...               mit.edu   \n",
       "194   https://spectrum.ieee.org/humanoid-robot-apptr...              ieee.org   \n",
       "208                                            /privacy                   NaN   \n",
       "211   https://dev-discuss.pytorch.org/t/meta-pytorch...           pytorch.org   \n",
       "225   https://about.fb.com/news/2025/02/meta-ai-laun...                fb.com   \n",
       "304   https://developers.googleblog.com/en/gemini-em...        googleblog.com   \n",
       "305   https://research.nvidia.com/labs/lpr/storm/?ut...            nvidia.com   \n",
       "379   https://heartbeat.comet.ml/how-to-build-a-text...              comet.ml   \n",
       "382   https://blog.tensorflow.org/2022/11/building-t...        tensorflow.org   \n",
       "410   https://community.arm.com/developer/ip-product...               arm.com   \n",
       "483   https://app.wandb.ai/sayakpaul/tale-of-quantiz...              wandb.ai   \n",
       "504   https://ai.facebook.com/blog/textless-nlp-gene...          facebook.com   \n",
       "570   https://txt.cohere.ai/introducing-sandbox-cohe...             cohere.ai   \n",
       "615   https://heartbeat.fritz.ai/sentiment-analysis-...              fritz.ai   \n",
       "672   https://blog.arduino.cc/2021/09/24/arduino-nic...            arduino.cc   \n",
       "685   https://haystack.deepset.ai/blog/langfuse-inte...            deepset.ai   \n",
       "910      https://dl.acm.org/doi/10.1145/3579371.3589049               acm.org   \n",
       "1067  https://research.ibm.com/blog/foundation-model...               ibm.com   \n",
       "1070  https://blog.ml.cmu.edu/2025/01/02/inductive-b...               cmu.edu   \n",
       "1187  https://magazine.sebastianraschka.com/p/llm-tr...  sebastianraschka.com   \n",
       "2413  https://assets.anthropic.com/m/7e1ab885d1b2417...         anthropic.com   \n",
       "\n",
       "                      domain_urllib  \n",
       "10                 hai.stanford.edu  \n",
       "11             blog.research.google  \n",
       "13                   aws.amazon.com  \n",
       "14                  docs.google.com  \n",
       "16             home.mlops.community  \n",
       "19                 blog.allenai.org  \n",
       "30               docs.llamaindex.ai  \n",
       "36               blog.langchain.dev  \n",
       "37                      ai.meta.com  \n",
       "41                bair.berkeley.edu  \n",
       "58          developer.microsoft.com  \n",
       "66                   txt.cohere.com  \n",
       "117              podcasts.apple.com  \n",
       "127             platform.openai.com  \n",
       "130      cajundiscordian.medium.com  \n",
       "187                    news.mit.edu  \n",
       "194               spectrum.ieee.org  \n",
       "208                                  \n",
       "211         dev-discuss.pytorch.org  \n",
       "225                    about.fb.com  \n",
       "304       developers.googleblog.com  \n",
       "305             research.nvidia.com  \n",
       "379              heartbeat.comet.ml  \n",
       "382             blog.tensorflow.org  \n",
       "410               community.arm.com  \n",
       "483                    app.wandb.ai  \n",
       "504                 ai.facebook.com  \n",
       "570                   txt.cohere.ai  \n",
       "615              heartbeat.fritz.ai  \n",
       "672                 blog.arduino.cc  \n",
       "685             haystack.deepset.ai  \n",
       "910                      dl.acm.org  \n",
       "1067               research.ibm.com  \n",
       "1070                blog.ml.cmu.edu  \n",
       "1187  magazine.sebastianraschka.com  \n",
       "2413           assets.anthropic.com  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "suffix = '_urllib'\n",
    "filtered = good_articles[(good_articles['match'+suffix]==False) | (good_articles['link_domain'].isna())]\n",
    "filtered.drop_duplicates(subset=['link_domain'], keep='first')[['link_url', 'link_domain', 'domain'+suffix]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_url</th>\n",
       "      <th>link_domain</th>\n",
       "      <th>domain_regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://hai.stanford.edu/news/hallucinating-la...</td>\n",
       "      <td>stanford.edu</td>\n",
       "      <td>hai.stanford.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://blog.research.google/2024/02/a-decoder...</td>\n",
       "      <td>research.google</td>\n",
       "      <td>blog.research.google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://aws.amazon.com/blogs/apn/automating-si...</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>aws.amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://docs.google.com/presentation/d/14b5gkR...</td>\n",
       "      <td>google.com</td>\n",
       "      <td>docs.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://home.mlops.community/public/videos/mlo...</td>\n",
       "      <td>mlops.community</td>\n",
       "      <td>home.mlops.community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://blog.allenai.org/olmo-open-language-mo...</td>\n",
       "      <td>allenai.org</td>\n",
       "      <td>blog.allenai.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://docs.llamaindex.ai/en/latest/examples/...</td>\n",
       "      <td>llamaindex.ai</td>\n",
       "      <td>docs.llamaindex.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>https://blog.langchain.dev/winning-in-ai-means...</td>\n",
       "      <td>langchain.dev</td>\n",
       "      <td>blog.langchain.dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://ai.meta.com/blog/v-jepa-yann-lecun-ai-...</td>\n",
       "      <td>meta.com</td>\n",
       "      <td>ai.meta.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>https://bair.berkeley.edu/blog/2024/02/18/comp...</td>\n",
       "      <td>berkeley.edu</td>\n",
       "      <td>bair.berkeley.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>https://developer.microsoft.com/en-us/reactor/...</td>\n",
       "      <td>microsoft.com</td>\n",
       "      <td>developer.microsoft.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>https://txt.cohere.com/command-r/</td>\n",
       "      <td>cohere.com</td>\n",
       "      <td>txt.cohere.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>https://podcasts.apple.com/us/podcast/lets-tal...</td>\n",
       "      <td>apple.com</td>\n",
       "      <td>podcasts.apple.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>https://platform.openai.com/docs/chatgpt-educa...</td>\n",
       "      <td>openai.com</td>\n",
       "      <td>platform.openai.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>https://cajundiscordian.medium.com/is-lamda-se...</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>cajundiscordian.medium.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>https://news.mit.edu/2024/ai-generates-high-qu...</td>\n",
       "      <td>mit.edu</td>\n",
       "      <td>news.mit.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>https://spectrum.ieee.org/humanoid-robot-apptr...</td>\n",
       "      <td>ieee.org</td>\n",
       "      <td>spectrum.ieee.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>/privacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>https://dev-discuss.pytorch.org/t/meta-pytorch...</td>\n",
       "      <td>pytorch.org</td>\n",
       "      <td>dev-discuss.pytorch.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>https://about.fb.com/news/2025/02/meta-ai-laun...</td>\n",
       "      <td>fb.com</td>\n",
       "      <td>about.fb.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>https://developers.googleblog.com/en/gemini-em...</td>\n",
       "      <td>googleblog.com</td>\n",
       "      <td>developers.googleblog.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>https://research.nvidia.com/labs/lpr/storm/?ut...</td>\n",
       "      <td>nvidia.com</td>\n",
       "      <td>research.nvidia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>https://heartbeat.comet.ml/how-to-build-a-text...</td>\n",
       "      <td>comet.ml</td>\n",
       "      <td>heartbeat.comet.ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>https://blog.tensorflow.org/2022/11/building-t...</td>\n",
       "      <td>tensorflow.org</td>\n",
       "      <td>blog.tensorflow.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>https://community.arm.com/developer/ip-product...</td>\n",
       "      <td>arm.com</td>\n",
       "      <td>community.arm.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>https://app.wandb.ai/sayakpaul/tale-of-quantiz...</td>\n",
       "      <td>wandb.ai</td>\n",
       "      <td>app.wandb.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>https://ai.facebook.com/blog/textless-nlp-gene...</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>ai.facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>https://txt.cohere.ai/introducing-sandbox-cohe...</td>\n",
       "      <td>cohere.ai</td>\n",
       "      <td>txt.cohere.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>https://heartbeat.fritz.ai/sentiment-analysis-...</td>\n",
       "      <td>fritz.ai</td>\n",
       "      <td>heartbeat.fritz.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>https://blog.arduino.cc/2021/09/24/arduino-nic...</td>\n",
       "      <td>arduino.cc</td>\n",
       "      <td>blog.arduino.cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>https://haystack.deepset.ai/blog/langfuse-inte...</td>\n",
       "      <td>deepset.ai</td>\n",
       "      <td>haystack.deepset.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3579371.3589049</td>\n",
       "      <td>acm.org</td>\n",
       "      <td>dl.acm.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>https://research.ibm.com/blog/foundation-model...</td>\n",
       "      <td>ibm.com</td>\n",
       "      <td>research.ibm.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>https://blog.ml.cmu.edu/2025/01/02/inductive-b...</td>\n",
       "      <td>cmu.edu</td>\n",
       "      <td>blog.ml.cmu.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>https://magazine.sebastianraschka.com/p/llm-tr...</td>\n",
       "      <td>sebastianraschka.com</td>\n",
       "      <td>magazine.sebastianraschka.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>https://assets.anthropic.com/m/7e1ab885d1b2417...</td>\n",
       "      <td>anthropic.com</td>\n",
       "      <td>assets.anthropic.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               link_url           link_domain  \\\n",
       "10    https://hai.stanford.edu/news/hallucinating-la...          stanford.edu   \n",
       "11    https://blog.research.google/2024/02/a-decoder...       research.google   \n",
       "13    https://aws.amazon.com/blogs/apn/automating-si...            amazon.com   \n",
       "14    https://docs.google.com/presentation/d/14b5gkR...            google.com   \n",
       "16    https://home.mlops.community/public/videos/mlo...       mlops.community   \n",
       "19    https://blog.allenai.org/olmo-open-language-mo...           allenai.org   \n",
       "30    https://docs.llamaindex.ai/en/latest/examples/...         llamaindex.ai   \n",
       "36    https://blog.langchain.dev/winning-in-ai-means...         langchain.dev   \n",
       "37    https://ai.meta.com/blog/v-jepa-yann-lecun-ai-...              meta.com   \n",
       "41    https://bair.berkeley.edu/blog/2024/02/18/comp...          berkeley.edu   \n",
       "58    https://developer.microsoft.com/en-us/reactor/...         microsoft.com   \n",
       "66                    https://txt.cohere.com/command-r/            cohere.com   \n",
       "117   https://podcasts.apple.com/us/podcast/lets-tal...             apple.com   \n",
       "127   https://platform.openai.com/docs/chatgpt-educa...            openai.com   \n",
       "130   https://cajundiscordian.medium.com/is-lamda-se...            medium.com   \n",
       "187   https://news.mit.edu/2024/ai-generates-high-qu...               mit.edu   \n",
       "194   https://spectrum.ieee.org/humanoid-robot-apptr...              ieee.org   \n",
       "208                                            /privacy                   NaN   \n",
       "211   https://dev-discuss.pytorch.org/t/meta-pytorch...           pytorch.org   \n",
       "225   https://about.fb.com/news/2025/02/meta-ai-laun...                fb.com   \n",
       "304   https://developers.googleblog.com/en/gemini-em...        googleblog.com   \n",
       "305   https://research.nvidia.com/labs/lpr/storm/?ut...            nvidia.com   \n",
       "379   https://heartbeat.comet.ml/how-to-build-a-text...              comet.ml   \n",
       "382   https://blog.tensorflow.org/2022/11/building-t...        tensorflow.org   \n",
       "410   https://community.arm.com/developer/ip-product...               arm.com   \n",
       "483   https://app.wandb.ai/sayakpaul/tale-of-quantiz...              wandb.ai   \n",
       "504   https://ai.facebook.com/blog/textless-nlp-gene...          facebook.com   \n",
       "570   https://txt.cohere.ai/introducing-sandbox-cohe...             cohere.ai   \n",
       "615   https://heartbeat.fritz.ai/sentiment-analysis-...              fritz.ai   \n",
       "672   https://blog.arduino.cc/2021/09/24/arduino-nic...            arduino.cc   \n",
       "685   https://haystack.deepset.ai/blog/langfuse-inte...            deepset.ai   \n",
       "910      https://dl.acm.org/doi/10.1145/3579371.3589049               acm.org   \n",
       "1067  https://research.ibm.com/blog/foundation-model...               ibm.com   \n",
       "1070  https://blog.ml.cmu.edu/2025/01/02/inductive-b...               cmu.edu   \n",
       "1187  https://magazine.sebastianraschka.com/p/llm-tr...  sebastianraschka.com   \n",
       "2413  https://assets.anthropic.com/m/7e1ab885d1b2417...         anthropic.com   \n",
       "\n",
       "                       domain_regex  \n",
       "10                 hai.stanford.edu  \n",
       "11             blog.research.google  \n",
       "13                   aws.amazon.com  \n",
       "14                  docs.google.com  \n",
       "16             home.mlops.community  \n",
       "19                 blog.allenai.org  \n",
       "30               docs.llamaindex.ai  \n",
       "36               blog.langchain.dev  \n",
       "37                      ai.meta.com  \n",
       "41                bair.berkeley.edu  \n",
       "58          developer.microsoft.com  \n",
       "66                   txt.cohere.com  \n",
       "117              podcasts.apple.com  \n",
       "127             platform.openai.com  \n",
       "130      cajundiscordian.medium.com  \n",
       "187                    news.mit.edu  \n",
       "194               spectrum.ieee.org  \n",
       "208                            None  \n",
       "211         dev-discuss.pytorch.org  \n",
       "225                    about.fb.com  \n",
       "304       developers.googleblog.com  \n",
       "305             research.nvidia.com  \n",
       "379              heartbeat.comet.ml  \n",
       "382             blog.tensorflow.org  \n",
       "410               community.arm.com  \n",
       "483                    app.wandb.ai  \n",
       "504                 ai.facebook.com  \n",
       "570                   txt.cohere.ai  \n",
       "615              heartbeat.fritz.ai  \n",
       "672                 blog.arduino.cc  \n",
       "685             haystack.deepset.ai  \n",
       "910                      dl.acm.org  \n",
       "1067               research.ibm.com  \n",
       "1070                blog.ml.cmu.edu  \n",
       "1187  magazine.sebastianraschka.com  \n",
       "2413           assets.anthropic.com  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "suffix = '_regex'\n",
    "filtered = good_articles[(good_articles['match'+suffix]==False) | (good_articles['link_domain'].isna())]\n",
    "filtered.drop_duplicates(subset=['link_domain'], keep='first')[['link_url', 'link_domain', 'domain'+suffix]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_url</th>\n",
       "      <th>link_domain</th>\n",
       "      <th>root_domain_psl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>/privacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     link_url link_domain root_domain_psl\n",
       "208  /privacy         NaN            None"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "suffix = '_psl'\n",
    "filtered = good_articles[(good_articles['match'+suffix]==False) | (good_articles['link_domain'].isna())]\n",
    "filtered.drop_duplicates(subset=['link_domain'], keep='first')[['link_url', 'link_domain', 'root_domain'+suffix]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. urllib and regex approaches are similar.\n",
    "2. root_domain_psl and link_domain are similar.\n",
    "- 1. seems better than 2. -> we pick urllib as our method to extract domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Content extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "def fetch_html(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.encoding = 'utf-8'\n",
    "        response.raise_for_status()  # Raises HTTPError for bad responses\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "test_url = \"https://neptune.ai/blog/hyperparameter-optimization-for-llms\"\n",
    "html = fetch_html(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### package html_content_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "            TL;DR        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The rise of large language models (LLMs) is bringing advances in text generation and contextual understanding. Hyperparameters control the size of LLMs, their training process, and how they generate outputs.\n",
      "An optimal combination of hyperparameters is fundamental to efficiently pre-training and fine-tuning LLMs. Since LLM training is computationally intensive, exhaustive experimentation is not viable. This rules out traditional machine-learning hyperparameter optimization (HPO) methods that rely on systematically exploring the hyperparameter space by training many models with slightly different configurations.\n",
      "When configuring models and training processes, LLM developers rely on a thorough understanding of each hyperparameter‚Äôs influence, insights from fundamental research, and empirical evidence gained from training state-of-the-art foundation models. Methods for estimating optimal hyperparameter values with limited compute budgets and adapting hyperparameters throughout the training process can help pre-training and fine-tuning.\n",
      "After reading this article, you‚Äôll be able to answer the following questions:\n",
      "\n",
      "What key hyperparameters should be considered when developing, training, and applying LLMs?\n",
      "How does each hyperparameter influence the LLM, and which trade-offs do we need to be aware of?\n",
      "How can we select an optimal combination of hyperparameters in our scenario without fully training multiple model variants?\n",
      "What advanced hyperparameter optimization techniques are available for LLMs, and when can we apply them?\n",
      "\n",
      "LLM hyperparameters\n",
      "A hyperparameter is a configuration value that controls the behavior of a machine-learning model during the training or inference process. Unlike model parameters (the weights), which are learned directly from the training data, hyperparameters are defined by the model developers. A hyperparameter can be constant or adjusted dynamically according to predefined rules or schedules.\n",
      "Model size\n",
      "In the case of LLMs, we often work with pre-trained models, where the activation functions, internal architecture of layers or blocks, and their connections‚Äîall examples of hyperparameters‚Äîare fixed. If our pre-trained LLM of choice is available in different sizes, the model size is the only hyperparameter affecting the model‚Äôs makeup we can actively control.\n",
      "The size of an LLM refers to the total number of parameters it contains, which influences the model‚Äôs capacity to understand and generate complex language patterns. Hyperparameters set and tuned during pre-training influence the total size of an LLM.\n",
      "One hyperparameter influencing a model‚Äôs size is its depth, corresponding to the total number of layers stacked sequentially. Each additional layer in an LLM adds more parameters, such as the weights for the self-attention mechanism and feed-forward layers in a transformer block.\n",
      "Another hyperparameter influencing an LLM‚Äôs size is its hidden size, which refers to the dimensionality of the token embeddings and the internal representations within each layer. The hidden size determines how richly the model can encode information about each input token and how effectively it can process complex language patterns. A larger hidden size means each token is represented in a higher-dimensional space, allowing the model to capture more detailed semantic and syntactic nuances.\n",
      "Further, the number of parallel attention heads in each transformer block influences the size of the LLM. Multiple heads allow the model to focus on different input aspects simultaneously. Through multi-query and grouped-query attention, we can reduce the number of necessary parameters.\n",
      "Finally, the vocabulary size and context window (maximum sequence length) also impact the model‚Äôs size. They determine the language diversity a model can handle and the context length it can maintain, respectively.These hyperparameters, set before beginning the training process and unable to be changed later, determine the model size. For example, GPT-3 has 96 layers, a hidden size of 12,288, 96 attention heads, a vocabulary of 50,257 tokens, and a context window of 2,048 tokens, resulting in a total of 175 billion parameters.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                What Does GPT-3 Mean For the Future of MLOps? With David Hershey            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning rate\n",
      "The learning rate (LR) is a critical hyperparameter in training LLMs. Optimizing these hyperparameters is essential for efficient learning, stable convergence, and good generalization to unseen data.\n",
      "The learning rate determines how much model weights are changed during each update. A high learning rate helps speed up the training process but increases the risk of instability and overfitting. A low learning rate increases stability and tends to benefit generalization but leads to slow training.\n",
      "In the case of LLMs, the learning rate is typically not constant but varies as training progresses. This variation is governed by a learning rate schedule (LRS). The schedule is usually tied to the number of tokens seen‚Äîeither directly, or indirectly through the number of samples, steps, or epochs. At a high level, it contains phases of a rising, constant, and decreasing learning rate.\n",
      "How does the learning rate affect training duration and quality?\n",
      "Following theoretical work by Stanford researcher Kaiyue Wen and colleagues published in December 2024, we can think of LLM training as progressing along a loss landscape that looks like a river valley. They hypothesize that the existence and overall direction of the river are due to the facts and knowledge an LLM learns, which are reflected as highly deterministic and, therefore, easy-to-predict tokens. The valley slopes arise from flexibility and ambiguity inherent to language, i.e., hard-to-predict tokens.\n",
      "\n",
      "\n",
      "In this picture, the training goal is to reach the river mouth, at which point we should be as close to the bottom of the valley as possible. The first crucial insight is that it does not matter whether we stay at the bottom of the valley until then. Thus, if we can make faster progress down the river by bouncing back and forth between points high up the loss valley‚Äôs slopes, we can do this without affecting the final outcome.\n",
      "Thus, we should aim to use a high learning rate‚Äîresulting in large steps towards the loss minimum but leading to wildly fluctuating loss values‚Äîfor as long as possible. Towards the end of the training, the learning rate should be decreased to a very low value. This will slow down progress towards the river mouth but reduce the oscillations to a point where we constantly stay at the valley‚Äôs bottom, i.e., the local loss minimum.\n",
      "However, all of this is only going to work if we are already in a sufficiently deep loss river valley. When training is first starting, a high learning rate will lead to undirected jumps across the loss landscape. To avoid this, learning rate schedules for LLMs start with a small learning rate and slowly ramp it up to its maximum value. This is called the warmup phase.\n",
      "Cosine schedule\n",
      "The cosine schedule (also known as cosine decay or cosine annealing) implements this approach by starting with a linear warmup phase that brings the learning rate to its maximum value, followed by a slow decay following the cosine function:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LR(t) = LRmin + 0.5 (LRmax ‚Äì LRmin) (1 + cos(œÄ t/T)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here, LRmin and LRmax are the minimum and maximum learning rates, t is the training step, and T is the total number of training steps. The advantage of this schedule is that it stays close to the peak learning rate for a long time, and the final decay is gradual. It‚Äôs also easy to implement, as it depends on just three hyperparameters (LRmax, LRmin, and T) linked by the cosine function.\n",
      "Cosine schedules have been highly popular for pretraining LLMs. For example, it was used for BLOOM, a 176-billion-parameter multilingual model developed by the BigScience Research Workshop and released in 2022. In an initial warmup phase, the learning rate was ramped to a peak of 6 x 10-5 over 375 million tokens. Afterward, it was lowered to 10% of this value with cosine decay over 410 million tokens and remained at this value. The implementation and detailed description are publicly accessible in BLOOM‚Äôs GitHub repository.\n",
      "For pre-training their Llama 3 405B model, Meta used a slightly more involved variant of the cosine schedule. In the first stage, a warm-up phase of up to 8,000 steps brought the learning rate to a maximum of 8 x 10-5. Subsequently, the learning rate decreased to 8 x 10-7 over 1.2 million steps with a cosine decay. After the second stage focused on training the LLM up to its final context length of 128,000 tokens, the learning rate linearly decreased to 0 over 40 million tokens in the third stage. Supervised fine-tuning was conducted over about 9,000 steps with a learning rate of 10-5.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Fine-Tuning Llama 3 with LoRA: Step-by-Step Guide            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A major disadvantage of the cosine schedule is that the total number of training steps has to be known beforehand. When training large foundation models, the total compute budget is typically set, and the optimal number of training tokens can be estimated. However, when fine-tuning or experimenting, it would be preferable to base the decision on when to end training on the model‚Äôs performance.\n",
      "Warmup-stable-decay schedule\n",
      "The warmup-stable-decay (WSD) schedule is a simple protocol introduced by Shengding Hu and colleagues at Tsinghua University in 2024. It starts with a linear warmup to the maximum learning rate, keeps the learning rate constant for the majority of the training, and ramps it down at the end.\n",
      "Through experiments, they found that a decay phase that makes up 10% of the total length is sufficient. They also demonstrated that a WSD schedule leads to a lower loss than a cosine schedule. According to Wen and colleagues at Stanford, this can readily be understood in the river valley picture. In the WSD schedule, the learning rate stays at a high value longer than in the cosine schedule. Hence, we make it further down the valley before dropping to its bottom. Further, their analysis shows that training progress in the stable phase is dominated by learning to predict deterministic tokens (facts and knowledge), while in the decay phase, the LLM learns the stochastic tokens (language variability).\n",
      "\n",
      "\n",
      "While a WSD schedule yields a lower loss for the same training budget, knowing the total number of training steps ahead of time is still required for scheduling the decay phase. However, the WSD schedule offers a straightforward way to extend the total number of training steps retroactively: If we find that our final model‚Äôs performance is unsatisfactory, we can resume training from a model snapshot taken at the end of the stable phase. This beams us back a small distance up the loss river valley, from where we continue making large jumpy steps towards the river mouth as if we had never descended down to the valley‚Äôs bottom in the first place.\n",
      "Restarting this way, we still benefit from 90% of the compute budget spent so far. It allows us to determine the compute budget we need as we go, producing fully trained intermediate models‚Äîsomething that the cosine schedule inherently does not allow for.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aside\n",
      " \n",
      "\n",
      "\n",
      "    \n",
      "    Track months-long model training with more confidence. Use neptune.ai forking feature to iterate faster and optimize the usage of GPU resources.\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "With Neptune, users can visualize forked training out of the box. This means you can:\n",
      "\n",
      "Test multiple configs at the same time. Stop the runs that don‚Äôt improve accuracy. And continue from the most accurate last step. \n",
      "Restart failed training sessions from any previous step. The training history is inherited, and the entire experiment is visible on a single chart. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tSee in app\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Check the documentation\n",
      "\n",
      "\n",
      "\n",
      "Play with an interactive example project\n",
      "\n",
      "\n",
      "\n",
      "Get in touch¬†to go through a custom demo with our engineering team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cyclical cosine schedule\n",
      "Returning to a high learning rate after decaying to a minimum is not a new idea in machine learning. Long established in gradient-free optimization, it was made popular for deep learning training through the ‚ÄúStochastic Gradient Descent with Warm Restarts‚Äù technique proposed by Ilya Loshchilov and Frank Hutter in 2017. The learning rate is governed by a function very similar to the one for the cosine schedule:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LR(t) = LRmin + 0.5 (LRmax ‚àí LRmin) (1 + cos(œÄ (t mod T)/T))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This time, T is not the total number of training steps but is understood as the schedule‚Äôs period. For example, we might train for 10,000 steps with T = 1,000, leading to ten consecutive cosine decay cycles. Commonly, LRmax is set to a new, lower value at the beginning of each cycle.\n",
      "In the loss landscape river valley, we‚Äôre climbing down to the bottom over T steps, making ever slower progress down the river as we keep closer to the bottom. Then, we immediately go back to make large jumps toward the river mouth high up the valley‚Äôs slopes.\n",
      "Right at the beginning of a new cosine cycle, the loss will be significantly higher than it was previously. This could be due to the jump in the learning rate, which might perturb the model. However, Wen and colleagues argue, based on their experiments and theoretical insights, that it is the result of training with a small learning rate for too long.\n",
      "Whatever the cause, this doesn‚Äôt just make training less efficient. It‚Äôs also an obstacle to continue model training later. Whether we aim to further pre-train on newly acquired or different data, fine-tune an LLM, or incrementally evolve a model in a continual learning scenario‚Äîideally, we could take a model snapshot and train it effectively, making the most of the compute budget we have available and the compute budget we have already spent. The learning rate schedule used during pretraining directly impacts this.\n",
      "Cyclical warmup-stable-decay schedule\n",
      "The Warmup-Stable-Decay (WSD) schedule allows continuing training from the final model checkpoint of the stable phase without incurring a loss penalty. This preserves a large fraction of the compute budget spent, as we only have to discard what we spent on intermediate decay phases. But this is not negligible at the scale of LLM pretraining, where the costs regularly exceed tens of millions of US dollars.\n",
      "As Wen and colleagues found, starting from the final decay phase model checkpoint in a WSD schedule does not cause the same loss penalty as the cosine schedule. As the WSD schedule‚Äôs decay phase is rather short, they hypothesize it does not have the same destructive effect as the cosine schedule‚Äôs long and slow decay. Given a total compute budget, consecutively repeating the WSD cycle is more efficient than restarting from the final checkpoint of the latest stable phase.\n",
      "A cyclical WSD schedule is easier to implement than WSD restarts, as the model evolves continuously down the loss landscape river valley, and no prior checkpoints have to be reloaded. It also helps downstream users, who initially often utilize few-shot prompting to adapt an LLM to their use case. If they later decide to fine-tune it, and the LLM is trained with a WSD schedule, training the same model checkpoint they already use for inference is efficient.\n",
      "Learning behavior\n",
      "In a neural network, the weights are the parameters of its neurons learned during training. In an LLM, weights include the query, key, and value matrices in the attention heads and the activation function parameters in the feed-forward layers. While the learning rate governs the scale of changes made to the model‚Äôs weights, we can also control how the weights change on a more fine-grained level.\n",
      "Weight decay\n",
      "Employing weight decay during training penalizes large weights, preventing small parts of the model from dominating its output. Weight decay in stochastic gradient descent is implemented by adding a term to the loss function. For example, using L2 regularization, the adapted loss function looks like this:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "L = Lorig¬†+ Œª Œ£iwi2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here, Lorig is the original loss function, Œª is the weight decay factor, and wi are the model weights.\n",
      "Weight decay has been applied to transformer-based NLP models since the beginning. In the seminal 2018 paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, the authors state that they trained the model using ‚ÄúAdam with [a] learning rate of 1e-4, Œ≤‚ÇÅ=0.9, Œ≤‚ÇÇ=0.999, L2 weight decay of 0.01, learning rate warm up over the first 10,000 steps, and linear decay of the learning rate.‚Äù\n",
      "As Ilya Loshchilov and Frank Hutter point out in their 2019 paper Decoupled Weight Decay Regularization, in adaptive optimizers like Adam, L2 regularization and weight decay are not identical, and L2 regularization is not effective. In Adam, the gradient of the regularization term is scaled with the gradient of Lorig, which leads to minimal regularization for terms in L for which the gradient is large. They introduced the AdamW optimizer, where the weight decay term is independent of the gradient-based update. AdamW is widely used for LLMs, such as for training Megatron-LM (2019), Llama 1 (2023), Llama 2 (2023), and Llama 3 (2024).\n",
      "In LLM pretraining, models often see each training sample only once. Thus, overfitting to training data, which weight decay helps prevent in traditional deep learning scenarios, is only of concern if there are many similar or even identical samples in the training dataset. Still, weight decay positively affects training speed and the final loss.\n",
      "According to a 2023 analysis by Francesco D‚ÄôAngelo and colleagues at EPFL, this is because weight decay increases the effective learning rate. The effective learning rate at training step t is defined as LR(t)/||wt||2, the learning rate scaled by the inverse norm of the weight vector. The smaller the weights, the larger the influence of a weight update. Further, D‚ÄôAngelo and colleagues find that weight decay stabilizes training in reduced floating-point precision.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                How to Optimize GPU Usage During Model Training with neptune.ai¬†            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Gradient clipping\n",
      "Gradient clipping caps gradient magnitudes, helping maintain numerical stability. In the river valley analogy, we impose a threshold on slope steepness when deciding where to move next. Rather than jumping off a cliff, we treat it as a moderately steep hillside.\n",
      "There are two common types of gradient clipping:\n",
      "\n",
      "Clipping by value: Set predefined minimum and maximum values for gradient magnitudes. A gradient component is clipped to the respective limit if it exceeds these thresholds. This approach has the key benefit of not requiring access to the entire gradient vector.\n",
      "Clipping by norm: The entire gradient vector is scaled down if the norm exceeds a specified threshold. For example, Nvidia‚Äôs original Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism paper first published in 2019 notes: ‚Äú[W]e use global gradient norm clipping of 1.0 to improve the stability of training large models.‚Äù In contrast to clipping by value, this preserves the gradient vector‚Äôs direction but requires access to the entire gradient vector to compute.\n",
      "\n",
      "In 2022, Yang and Ma introduced the Component-Wise Gradient Norm Clipping (CWGNC) approach for fine-tuning LLMs. In a nutshell, CWGNC applies gradient-clipping by norm separately to components in the LLM, such as the key, query, and value matrices or feed-forward layers. This stabilizes the training of each component individually, which might progress at significantly different rates.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Position: Understanding LLMs Requires More Than Statistical Generalization [Paper Reflection]            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Next-token generation\n",
      "LLMs are autoregressive language models. They predict the next token by taking the sequence of previously generated tokens as input and producing a vector containing a probability for each token in the vocabulary. Different post-processing techniques can be used to determine the next token from these probabilities.\n",
      "Temperature\n",
      "Typically, LLMs use a softmax function as the final step in computing token probabilities. A temperature parameter controls this function.\n",
      "The temperature influences the degree of randomness (or ‚Äúoriginality‚Äù or ‚Äúcreativity‚Äù) in an LLM‚Äôs predicted text. At low temperatures, the model becomes more deterministic, rarely considering less likely options and instead focusing on the tokens with the highest probabilities. Conversely, a high temperature increases unpredictability, allowing the model to choose from a broader range of tokens. Thus, lower temperatures are helpful when you need reliable answers, while higher temperatures lead to more varied and surprising outputs.\n",
      "The Text Gen Playground Hugging Face Space allows users to experiment with different temperature settings and models. By inputting a prompt and adjusting the temperature parameter, you can observe how the model‚Äôs output varies from predictable and deterministic to creative and varied.\n",
      "For example, using the prompt ‚ÄúThe sun rises in the‚Äù at different temperatures:\n",
      "\n",
      "Low Temperature (e.g., T = 0.2): The model will likely complete the sentence with ‚Äúeast,‚Äù reflecting a common and expected continuation.\n",
      "High Temperature (e.g., T = 1.2): The model might generate more imaginative completions like ‚Äúmorning haze‚Äù or ‚Äúgolden skies,‚Äù showcasing increased creativity.\n",
      "\n",
      "Adjusting the temperature parameter in such playgrounds provides valuable insights into controlling the balance between determinism and creativity in language model outputs.\n",
      "Sampling strategy\n",
      "Given the vector of probabilities, there are many ways to select the next token.\n",
      "A straightforward strategy is always picking the most likely token. Since the sampling process only considers the probabilities for the very next token, this ‚Äúgreedy decoding‚Äù leads to highly probable multi-token sequences being discarded if they start with a token that ‚Äì viewed in isolation ‚Äì is less likely.\n",
      "Using beam search or random sampling according to the token probabilities can mitigate this. While the former produces deterministic outputs and thus no variety, the latter can lead to the selection of highly improbable tokens, producing nonsensical sequences.\n",
      "A more balanced approach is top-k sampling, which restricts sampling of the next token to the k most probable tokens. Alternatively, in top-p sampling, only the most likely tokens up to a cumulative probability of p are considered. This approach adapts dynamically to the probability distribution, sampling from many tokens in uncertain scenarios and picking from only a few when the model is more confident. (p and k can be adjusted during training or inference time.)\n",
      "As ML Engineers, we can fine-tune temperature and sampling strategy parameters according to your project needs. For example, if our tasks require precision (e.g., technical writing or summarization), we‚Äôll use lower temperatures and top-k sampling to prioritize high-probability tokens. If we need more diversity, we‚Äôll begin with common default values (temperature 0.7, top-k: k = 40, top-p: p = 0.9). We‚Äôll iteratively adjust them based on the qualitative evaluation of outputs and document our findings to build a shared knowledge base with your team.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Customizing LLM Output: Post-Processing Techniques¬†            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How do we find the optimal hyperparameters?\n",
      "LLM training involves many hyperparameters, resulting in a combinatorial explosion of the search space. Simply guessing hyperparameters is unlikely to yield good results. Further, hyperparameters interact in complex ways, so the optimal value for one may depend on the values of others. Thus, adjusting hyperparameters one at a time may lead to suboptimal solutions, as we easily become trapped in local optima and don‚Äôt adequately explore the hyperparameter space.\n",
      "Finding an optimal combination of hyperparameters requires a systematic approach. First, it‚Äôs paramount to understand the relevant hyperparameters and their influence on the particular LLM. It‚Äôs essential to research how similar architectures were trained or how the LLM we want to fine-tune was pre-trained. Further, we should clarify the available time, our compute budget, and the training objectives.\n",
      "Next, we can sketch a roadmap. Can we afford to conduct experiments with particular hyperparameter combinations we believe are useful? Do we already have an experiment tracker and resource monitoring in place, or do we need to set it up first? What will be the decision points and criteria that ensure we end up with a fully trained LLM at the end of the project? Finally, we can start executing this roadmap and adjust our plans as we gather more information and insight.\n",
      "The BLOOM team published a detailed paper on their preliminary experiments to determine the optimal model size and architecture. They describe how they started with GPT-3‚Äôs hyperparameters and conducted trial runs to estimate the optimal balance between model size and number of tokens given their fixed compute budget. Similar experiments were run by the Meta team that trained Llama3, who also aimed to predict downstream task performance.\n",
      "Can we use traditional machine learning hyperparameter optimization methods for LLMs?\n",
      "Methods for systematic hyperparameter optimization have long been studied in machine learning:\n",
      "\n",
      "Learning curve analysis involves training models with varying hyperparameters over several epochs and plotting the loss to identify trends. In deep-learning models, plotting the gradient can further help assess whether and how efficiently a model learns.\n",
      "\n",
      "\n",
      "Grid search systematically steps through the hyperparameter space, training a model for each possible combination. Random search samples the hyperparameter space, training models for randomly selected combinations.\n",
      "\n",
      "While these approaches have successfully been applied to optimize LLM hyperparameters, their use is severely limited by the fact that LLMs are very expensive to train. The computational and memory requirements make it unviable to train large numbers of models. If training a model takes several months on a large cluster, we‚Äôll only get one shot at a full training run.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Observability in LLMOps: Different Levels of Scale            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Advanced strategies for LLM hyperparameter optimization\n",
      "Beyond starting from a well-known hyperparameter combination and systematically conducting experiments, there is a range of approaches for automatically identifying or optimizing LLM hyperparameters in specific circumstances.\n",
      "Population-based training (PBT)\n",
      "Population-Based Training (PBT) is an approach pioneered by Google DeepMind that combines the concepts of evolutionary search and online training. Instead of fixing hyperparameters at the start of training and leaving them static throughout the process, PBT adapts them dynamically, informed by the models‚Äô performance.\n",
      "In a nutshell, the population-based training process consists of the following steps:\n",
      "\n",
      "Set up a population of models, each with unique hyperparameters hi and weights i.¬†\n",
      "Train each model, updating i every iteration.\n",
      "After a fixed number of iterations, evaluate each model‚Äôs performance on a validation dataset.\n",
      "Identify models that are underperforming relative to others. Replace their current weights‚Äã and hyperparameters with those of a better-performing model (exploitation).\n",
      "Slightly perturb the hyperparameters of previously underperforming models to prevent the population from converging to a single configuration too early and improve diversity (exploration).\n",
      "Conclude the training if the compute budget is exhausted or the objective has been met. Otherwise, repeat the process starting from step 2.\n",
      "\n",
      "This process initially appears resource-intensive since it requires maintaining and updating multiple models simultaneously, which can increase total GPU hours. However, PBT‚Äôs dynamic refinement of hyperparameters during training can significantly save wall-clock time. By avoiding restarting from scratch for each hyperparameter configuration and leveraging partially trained models, PBT reduces the number of training epochs needed to achieve optimal performance.\n",
      "The 2017 DeepMind study on Population-Based Training (PBT) showcased its potential for LLMs by fine-tuning the first transformer model on the WMT 2014 English-German machine translation benchmark. They manually optimized a baseline model and compared it to a model where they used PBT to optimize the dropouts for different layers and the learning rate. Their evaluation showed that the PBT-optimized model outperformed their hand-tuned baseline. Further, they discovered that the learning rate schedule generated through PBT mimicked the human-created one. Starting with a small learning rate, it then jumped to a high value before something resembling an exponential decay‚Äù brought it down to a low value again. DeepMind‚Äôs original PBT transformer model also learned noticeably faster.\n",
      "Ray Tune is a hyperparameter tuning library that supports population-based training. It is part of the open-source Ray framework for scaling machine-learning applications. The Ray Tune documentation includes an example of tuning BERT and RoBERTa on the GLUE benchmark dataset using population-based training.\n",
      "Bayesian optimization\n",
      "Bayesian optimization is a popular method for efficiently navigating the hyperparameter space by building a probabilistic model (surrogate model) of the influence of the hyperparameters on the objective (e.g., validation loss). The surrogate model is used to predict promising hyperparameter combinations to try next. The results of this exploration are then used to refine the surrogate model.\n",
      "The 2024 paper Crafting Efficient Fine-Tuning Strategies for Large Language Models investigates the applicability of Bayesian optimization to fine-tuning LLMs. First, a population of N models is trained for a pre-defined budget t1. As each model is trained, the surrogate model is updated, and the updated version is used to set the hyperparameters of the next model. Once all N models are trained, the top k models are selected and are trained up to t2. Finally, the best model among the k fully trained models is selected.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                How to Optimize Hyperparameter Search Using Bayesian Optimization and Optuna¬†            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Adaptive Low-Rank Adaptation (LoRA)\n",
      "Low-Rank Adaptation (LoRA) is a popular technique for reducing the memory footprint and computational demands when fine-tuning LLMs. In brief, the idea is to represent the weights of the fine-tuned model as¬†\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Wfine = Wpre + ‚àÜW =¬† Wpre + BA\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here, the fine-tuned weights Wfine are the sum of the original weights Wpre and a difference ‚àÜW, which is the product of two matrices, B and A. Only B and A are updated during fine-tuning, while Wpre remains unchanged. If Wpre and ‚àÜW have dimensions m x n, B and A have dimensions m x r and r x n, respectively. If the rank r is much smaller than m and n, the number of weights to be updated is greatly reduced, leading to faster training progress while requiring less memory.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                LLM Fine-Tuning and Model Selection Using Neptune and Transformers¬†            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In practice, it is often unclear to which LLM components LoRA should be applied for the best outcome. While we know that not all weights influence task performance equally, identifying which components are important for a particular objective would require extensive ablation studies. Thus, LoRA is often applied across all suitable weight matrices in a model.\n",
      "AdaLoRA (Adaptive Low-Rank Adaptation) is a method to allocate a given parameter budget across weight matrices. The core idea is to apply LoRA to all LLM components but to use different values for the rank r. Important components use a matrix pair with a large r, leading to a ‚àÜW with many weights. Less important components are approximated using a lower-rank matrix pair. AdaLoRA assigns an importance score to each component and sets the values for r such that the total number of weights remains within the user-defined budget. This leads to an optimal training outcome for a fixed compute and memory budget.\n",
      "AdaMoLE (Adaptive Mixture of Low-Rank Adaptation Experts) similarly aims to reduce the number of weights that need to be updated. It replaces the single low-rank matrix pair of the original LoRA with a collection of multiple matrix pairs (LoRA experts) that are activated dynamically based on the input context. This enables the LLM to learn different tasks with a minimal total number of weights.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Mixture of Experts LLMs: Key Concepts Explained            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hands-on: LLM hyperparameter optimization with neptune.ai\n",
      "Optuna is a framework for optimizing hyperparameter search using Bayesian optimization. It can be applied to various machine-learning tasks, including LLM hyperparameter tuning.\n",
      "To see this in action, we‚Äôve prepared a Colab notebook that walks you through the process of finding the optimal combination of learning rate, batch size, and number of epochs for fine-tuning a Hugging Face Transformers model on the IMBD dataset.\n",
      "The tutorial uses neptune.ai to track training progress and analyze the different hyperparameters. If you don‚Äôt want to go through the tutorial yourself right now, you can still explore example results in this public Neptune project.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Editor‚Äôs note\n",
      " \n",
      "\n",
      "\n",
      "    \n",
      "    How about being one of the first to access Neptune Scale?\n",
      "    \n",
      "Neptune Scale is our upcoming product release built for teams that train foundation models. It offers enhanced scalability and exciting new features. You can join our beta program to benefit from Neptune Scale earlier.\n",
      "\n",
      "\n",
      "\n",
      "See the docs¬†or watch a short¬†product demo (2 min)\n",
      "\n",
      "\n",
      "\n",
      "Play with a live Neptune Scale project\n",
      "\n",
      "\n",
      "\n",
      "Request your early access\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What‚Äôs next in LLM hyperparameter optimization?\n",
      "Finding an optimal combination of hyperparameters is essential for training LLMs. In this article, we‚Äôve reviewed key LLM hyperparameters and their influence on the model and training performance. We‚Äôve also discussed how to approach hyperparameter optimization systematically and explored methods to assist or even automate this task in certain scenarios.From the examples of hyperparameter choices for state-of-the-art LLMs, we‚Äôve seen that while architectures, training tasks, and data change, most models are trained with relatively similar learning rate schedules and optimizer configurations. As our understanding of the model and training mechanics deepens and more experiments yield empirical evidence, we‚Äôll likely see an evolution of the standard recipes and more diversity.\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tWas the article useful?\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tYes\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tNo\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tSuggest changes\t\t\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Your email\n",
      "\n",
      " Your message (optional)\n",
      "\n",
      "\n",
      "This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I am familiar with the Privacy Policy*\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Submit\n",
      "\n",
      "Œî\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tMore about\t\t\t\n",
      "\t\t\tHyperparameter Optimization For LLMs: Advanced Strategies\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\tCheck out our \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "product resources \n",
      "and\n",
      "\n",
      "\n",
      "\n",
      "related articles below:\n",
      "\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRelated article\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tFrom Research to Production: Building The Most Scalable Experiment Tracker For Foundation Models\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRelated article\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tHow to Build and Evaluate a RAG System Using LangChain, Ragas, and neptune.ai\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRelated article\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tFine-Tuning Llama 3 with LoRA: Step-by-Step Guide\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tProduct resource\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tHow Neptune Helps Artera Bring AI Solutions to Market Faster\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tExplore more content topics:\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tComputer Vision\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tGeneral\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tLLMOps\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tML Model Development\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tML Tools\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tMLOps\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tNatural Language Processing\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tPaper Reflections\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tProduct Updates\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tReinforcement Learning\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tTabular Data\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tTime Series\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from html_content_extractor import extract_content\n",
    "\n",
    "content = extract_content(html, format='plaintext')\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "            TL;DR        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The rise of large language models (LLMs) is bringing advances in text generation and contextual understanding. Hyperparameters control the size of LLMs, their training process, and how they generate outputs.\n",
      "An optimal combination of hyperparameters is fundamental to efficiently pre-training and fine-tuning LLMs. Since LLM training is computationally intensive, exhaustive experimentation is not viable. This rules out traditional machine-learning hyperparameter optimization (HPO) methods that rely on systematically exploring the hyperparameter space by training many models with slightly different configurations.\n",
      "When configuring models and training processes, LLM developers rely on a thorough understanding of each hyperparameter‚Äôs influence, insights from fundamental research, and empirical evidence gained from training state-of-the-art foundation models. Methods for estimating optimal hyperparameter values with limited compute budgets and adapting hyperparameters throughout the training process can help pre-training and fine-tuning.\n",
      "After reading this article, you‚Äôll be able to answer the following questions:\n",
      "\n",
      "What key hyperparameters should be considered when developing, training, and applying LLMs?\n",
      "How does each hyperparameter influence the LLM, and which trade-offs do we need to be aware of?\n",
      "How can we select an optimal combination of hyperparameters in our scenario without fully training multiple model variants?\n",
      "What advanced hyperparameter optimization techniques are available for LLMs, and when can we apply them?\n",
      "\n",
      "LLM hyperparameters\n",
      "A hyperparameter is a configuration value that controls the behavior of a machine-learning model during the training or inference process. Unlike model parameters (the weights), which are learned directly from the training data, hyperparameters are defined by the model developers. A hyperparameter can be constant or adjusted dynamically according to predefined rules or schedules.\n",
      "Model size\n",
      "In the case of LLMs, we often work with pre-trained models, where the activation functions, internal architecture of layers or blocks, and their connections‚Äîall examples of hyperparameters‚Äîare fixed. If our pre-trained LLM of choice is available in different sizes, the model size is the only hyperparameter affecting the model‚Äôs makeup we can actively control.\n",
      "The size of an LLM refers to the total number of parameters it contains, which influences the model‚Äôs capacity to understand and generate complex language patterns. Hyperparameters set and tuned during pre-training influence the total size of an LLM.\n",
      "One hyperparameter influencing a model‚Äôs size is its depth, corresponding to the total number of layers stacked sequentially. Each additional layer in an LLM adds more parameters, such as the weights for the self-attention mechanism and feed-forward layers in a transformer block.\n",
      "Another hyperparameter influencing an LLM‚Äôs size is its hidden size, which refers to the dimensionality of the token embeddings and the internal representations within each layer. The hidden size determines how richly the model can encode information about each input token and how effectively it can process complex language patterns. A larger hidden size means each token is represented in a higher-dimensional space, allowing the model to capture more detailed semantic and syntactic nuances.\n",
      "Further, the number of parallel attention heads in each transformer block influences the size of the LLM. Multiple heads allow the model to focus on different input aspects simultaneously. Through multi-query and grouped-query attention, we can reduce the number of necessary parameters.\n",
      "Finally, the vocabulary size and context window (maximum sequence length) also impact the model‚Äôs size. They determine the language diversity a model can handle and the context length it can maintain, respectively.These hyperparameters, set before beginning the training process and unable to be changed later, determine the model size. For example, GPT-3 has 96 layers, a hidden size of 12,288, 96 attention heads, a vocabulary of 50,257 tokens, and a context window of 2,048 tokens, resulting in a total of 175 billion parameters.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                What Does GPT-3 Mean For the Future of MLOps? With David Hershey            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning rate\n",
      "The learning rate (LR) is a critical hyperparameter in training LLMs. Optimizing these hyperparameters is essential for efficient learning, stable convergence, and good generalization to unseen data.\n",
      "The learning rate determines how much model weights are changed during each update. A high learning rate helps speed up the training process but increases the risk of instability and overfitting. A low learning rate increases stability and tends to benefit generalization but leads to slow training.\n",
      "In the case of LLMs, the learning rate is typically not constant but varies as training progresses. This variation is governed by a learning rate schedule (LRS). The schedule is usually tied to the number of tokens seen‚Äîeither directly, or indirectly through the number of samples, steps, or epochs. At a high level, it contains phases of a rising, constant, and decreasing learning rate.\n",
      "How does the learning rate affect training duration and quality?\n",
      "Following theoretical work by Stanford researcher Kaiyue Wen and colleagues published in December 2024, we can think of LLM training as progressing along a loss landscape that looks like a river valley. They hypothesize that the existence and overall direction of the river are due to the facts and knowledge an LLM learns, which are reflected as highly deterministic and, therefore, easy-to-predict tokens. The valley slopes arise from flexibility and ambiguity inherent to language, i.e., hard-to-predict tokens.\n",
      "\n",
      "\n",
      "In this picture, the training goal is to reach the river mouth, at which point we should be as close to the bottom of the valley as possible. The first crucial insight is that it does not matter whether we stay at the bottom of the valley until then. Thus, if we can make faster progress down the river by bouncing back and forth between points high up the loss valley‚Äôs slopes, we can do this without affecting the final outcome.\n",
      "Thus, we should aim to use a high learning rate‚Äîresulting in large steps towards the loss minimum but leading to wildly fluctuating loss values‚Äîfor as long as possible. Towards the end of the training, the learning rate should be decreased to a very low value. This will slow down progress towards the river mouth but reduce the oscillations to a point where we constantly stay at the valley‚Äôs bottom, i.e., the local loss minimum.\n",
      "However, all of this is only going to work if we are already in a sufficiently deep loss river valley. When training is first starting, a high learning rate will lead to undirected jumps across the loss landscape. To avoid this, learning rate schedules for LLMs start with a small learning rate and slowly ramp it up to its maximum value. This is called the warmup phase.\n",
      "Cosine schedule\n",
      "The cosine schedule (also known as cosine decay or cosine annealing) implements this approach by starting with a linear warmup phase that brings the learning rate to its maximum value, followed by a slow decay following the cosine function:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LR(t) = LRmin + 0.5 (LRmax ‚Äì LRmin) (1 + cos(œÄ t/T)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here, LRmin and LRmax are the minimum and maximum learning rates, t is the training step, and T is the total number of training steps. The advantage of this schedule is that it stays close to the peak learning rate for a long time, and the final decay is gradual. It‚Äôs also easy to implement, as it depends on just three hyperparameters (LRmax, LRmin, and T) linked by the cosine function.\n",
      "Cosine schedules have been highly popular for pretraining LLMs. For example, it was used for BLOOM, a 176-billion-parameter multilingual model developed by the BigScience Research Workshop and released in 2022. In an initial warmup phase, the learning rate was ramped to a peak of 6 x 10-5 over 375 million tokens. Afterward, it was lowered to 10% of this value with cosine decay over 410 million tokens and remained at this value. The implementation and detailed description are publicly accessible in BLOOM‚Äôs GitHub repository.\n",
      "For pre-training their Llama 3 405B model, Meta used a slightly more involved variant of the cosine schedule. In the first stage, a warm-up phase of up to 8,000 steps brought the learning rate to a maximum of 8 x 10-5. Subsequently, the learning rate decreased to 8 x 10-7 over 1.2 million steps with a cosine decay. After the second stage focused on training the LLM up to its final context length of 128,000 tokens, the learning rate linearly decreased to 0 over 40 million tokens in the third stage. Supervised fine-tuning was conducted over about 9,000 steps with a learning rate of 10-5.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Fine-Tuning Llama 3 with LoRA: Step-by-Step Guide            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A major disadvantage of the cosine schedule is that the total number of training steps has to be known beforehand. When training large foundation models, the total compute budget is typically set, and the optimal number of training tokens can be estimated. However, when fine-tuning or experimenting, it would be preferable to base the decision on when to end training on the model‚Äôs performance.\n",
      "Warmup-stable-decay schedule\n",
      "The warmup-stable-decay (WSD) schedule is a simple protocol introduced by Shengding Hu and colleagues at Tsinghua University in 2024. It starts with a linear warmup to the maximum learning rate, keeps the learning rate constant for the majority of the training, and ramps it down at the end.\n",
      "Through experiments, they found that a decay phase that makes up 10% of the total length is sufficient. They also demonstrated that a WSD schedule leads to a lower loss than a cosine schedule. According to Wen and colleagues at Stanford, this can readily be understood in the river valley picture. In the WSD schedule, the learning rate stays at a high value longer than in the cosine schedule. Hence, we make it further down the valley before dropping to its bottom. Further, their analysis shows that training progress in the stable phase is dominated by learning to predict deterministic tokens (facts and knowledge), while in the decay phase, the LLM learns the stochastic tokens (language variability).\n",
      "\n",
      "\n",
      "While a WSD schedule yields a lower loss for the same training budget, knowing the total number of training steps ahead of time is still required for scheduling the decay phase. However, the WSD schedule offers a straightforward way to extend the total number of training steps retroactively: If we find that our final model‚Äôs performance is unsatisfactory, we can resume training from a model snapshot taken at the end of the stable phase. This beams us back a small distance up the loss river valley, from where we continue making large jumpy steps towards the river mouth as if we had never descended down to the valley‚Äôs bottom in the first place.\n",
      "Restarting this way, we still benefit from 90% of the compute budget spent so far. It allows us to determine the compute budget we need as we go, producing fully trained intermediate models‚Äîsomething that the cosine schedule inherently does not allow for.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aside\n",
      " \n",
      "\n",
      "\n",
      "    \n",
      "    Track months-long model training with more confidence. Use neptune.ai forking feature to iterate faster and optimize the usage of GPU resources.\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "With Neptune, users can visualize forked training out of the box. This means you can:\n",
      "\n",
      "Test multiple configs at the same time. Stop the runs that don‚Äôt improve accuracy. And continue from the most accurate last step. \n",
      "Restart failed training sessions from any previous step. The training history is inherited, and the entire experiment is visible on a single chart. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tSee in app\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Check the documentation\n",
      "\n",
      "\n",
      "\n",
      "Play with an interactive example project\n",
      "\n",
      "\n",
      "\n",
      "Get in touch¬†to go through a custom demo with our engineering team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cyclical cosine schedule\n",
      "Returning to a high learning rate after decaying to a minimum is not a new idea in machine learning. Long established in gradient-free optimization, it was made popular for deep learning training through the ‚ÄúStochastic Gradient Descent with Warm Restarts‚Äù technique proposed by Ilya Loshchilov and Frank Hutter in 2017. The learning rate is governed by a function very similar to the one for the cosine schedule:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LR(t) = LRmin + 0.5 (LRmax ‚àí LRmin) (1 + cos(œÄ (t mod T)/T))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This time, T is not the total number of training steps but is understood as the schedule‚Äôs period. For example, we might train for 10,000 steps with T = 1,000, leading to ten consecutive cosine decay cycles. Commonly, LRmax is set to a new, lower value at the beginning of each cycle.\n",
      "In the loss landscape river valley, we‚Äôre climbing down to the bottom over T steps, making ever slower progress down the river as we keep closer to the bottom. Then, we immediately go back to make large jumps toward the river mouth high up the valley‚Äôs slopes.\n",
      "Right at the beginning of a new cosine cycle, the loss will be significantly higher than it was previously. This could be due to the jump in the learning rate, which might perturb the model. However, Wen and colleagues argue, based on their experiments and theoretical insights, that it is the result of training with a small learning rate for too long.\n",
      "Whatever the cause, this doesn‚Äôt just make training less efficient. It‚Äôs also an obstacle to continue model training later. Whether we aim to further pre-train on newly acquired or different data, fine-tune an LLM, or incrementally evolve a model in a continual learning scenario‚Äîideally, we could take a model snapshot and train it effectively, making the most of the compute budget we have available and the compute budget we have already spent. The learning rate schedule used during pretraining directly impacts this.\n",
      "Cyclical warmup-stable-decay schedule\n",
      "The Warmup-Stable-Decay (WSD) schedule allows continuing training from the final model checkpoint of the stable phase without incurring a loss penalty. This preserves a large fraction of the compute budget spent, as we only have to discard what we spent on intermediate decay phases. But this is not negligible at the scale of LLM pretraining, where the costs regularly exceed tens of millions of US dollars.\n",
      "As Wen and colleagues found, starting from the final decay phase model checkpoint in a WSD schedule does not cause the same loss penalty as the cosine schedule. As the WSD schedule‚Äôs decay phase is rather short, they hypothesize it does not have the same destructive effect as the cosine schedule‚Äôs long and slow decay. Given a total compute budget, consecutively repeating the WSD cycle is more efficient than restarting from the final checkpoint of the latest stable phase.\n",
      "A cyclical WSD schedule is easier to implement than WSD restarts, as the model evolves continuously down the loss landscape river valley, and no prior checkpoints have to be reloaded. It also helps downstream users, who initially often utilize few-shot prompting to adapt an LLM to their use case. If they later decide to fine-tune it, and the LLM is trained with a WSD schedule, training the same model checkpoint they already use for inference is efficient.\n",
      "Learning behavior\n",
      "In a neural network, the weights are the parameters of its neurons learned during training. In an LLM, weights include the query, key, and value matrices in the attention heads and the activation function parameters in the feed-forward layers. While the learning rate governs the scale of changes made to the model‚Äôs weights, we can also control how the weights change on a more fine-grained level.\n",
      "Weight decay\n",
      "Employing weight decay during training penalizes large weights, preventing small parts of the model from dominating its output. Weight decay in stochastic gradient descent is implemented by adding a term to the loss function. For example, using L2 regularization, the adapted loss function looks like this:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "L = Lorig¬†+ Œª Œ£iwi2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here, Lorig is the original loss function, Œª is the weight decay factor, and wi are the model weights.\n",
      "Weight decay has been applied to transformer-based NLP models since the beginning. In the seminal 2018 paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, the authors state that they trained the model using ‚ÄúAdam with [a] learning rate of 1e-4, Œ≤‚ÇÅ=0.9, Œ≤‚ÇÇ=0.999, L2 weight decay of 0.01, learning rate warm up over the first 10,000 steps, and linear decay of the learning rate.‚Äù\n",
      "As Ilya Loshchilov and Frank Hutter point out in their 2019 paper Decoupled Weight Decay Regularization, in adaptive optimizers like Adam, L2 regularization and weight decay are not identical, and L2 regularization is not effective. In Adam, the gradient of the regularization term is scaled with the gradient of Lorig, which leads to minimal regularization for terms in L for which the gradient is large. They introduced the AdamW optimizer, where the weight decay term is independent of the gradient-based update. AdamW is widely used for LLMs, such as for training Megatron-LM (2019), Llama 1 (2023), Llama 2 (2023), and Llama 3 (2024).\n",
      "In LLM pretraining, models often see each training sample only once. Thus, overfitting to training data, which weight decay helps prevent in traditional deep learning scenarios, is only of concern if there are many similar or even identical samples in the training dataset. Still, weight decay positively affects training speed and the final loss.\n",
      "According to a 2023 analysis by Francesco D‚ÄôAngelo and colleagues at EPFL, this is because weight decay increases the effective learning rate. The effective learning rate at training step t is defined as LR(t)/||wt||2, the learning rate scaled by the inverse norm of the weight vector. The smaller the weights, the larger the influence of a weight update. Further, D‚ÄôAngelo and colleagues find that weight decay stabilizes training in reduced floating-point precision.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                How to Optimize GPU Usage During Model Training with neptune.ai¬†            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Gradient clipping\n",
      "Gradient clipping caps gradient magnitudes, helping maintain numerical stability. In the river valley analogy, we impose a threshold on slope steepness when deciding where to move next. Rather than jumping off a cliff, we treat it as a moderately steep hillside.\n",
      "There are two common types of gradient clipping:\n",
      "\n",
      "Clipping by value: Set predefined minimum and maximum values for gradient magnitudes. A gradient component is clipped to the respective limit if it exceeds these thresholds. This approach has the key benefit of not requiring access to the entire gradient vector.\n",
      "Clipping by norm: The entire gradient vector is scaled down if the norm exceeds a specified threshold. For example, Nvidia‚Äôs original Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism paper first published in 2019 notes: ‚Äú[W]e use global gradient norm clipping of 1.0 to improve the stability of training large models.‚Äù In contrast to clipping by value, this preserves the gradient vector‚Äôs direction but requires access to the entire gradient vector to compute.\n",
      "\n",
      "In 2022, Yang and Ma introduced the Component-Wise Gradient Norm Clipping (CWGNC) approach for fine-tuning LLMs. In a nutshell, CWGNC applies gradient-clipping by norm separately to components in the LLM, such as the key, query, and value matrices or feed-forward layers. This stabilizes the training of each component individually, which might progress at significantly different rates.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Position: Understanding LLMs Requires More Than Statistical Generalization [Paper Reflection]            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Next-token generation\n",
      "LLMs are autoregressive language models. They predict the next token by taking the sequence of previously generated tokens as input and producing a vector containing a probability for each token in the vocabulary. Different post-processing techniques can be used to determine the next token from these probabilities.\n",
      "Temperature\n",
      "Typically, LLMs use a softmax function as the final step in computing token probabilities. A temperature parameter controls this function.\n",
      "The temperature influences the degree of randomness (or ‚Äúoriginality‚Äù or ‚Äúcreativity‚Äù) in an LLM‚Äôs predicted text. At low temperatures, the model becomes more deterministic, rarely considering less likely options and instead focusing on the tokens with the highest probabilities. Conversely, a high temperature increases unpredictability, allowing the model to choose from a broader range of tokens. Thus, lower temperatures are helpful when you need reliable answers, while higher temperatures lead to more varied and surprising outputs.\n",
      "The Text Gen Playground Hugging Face Space allows users to experiment with different temperature settings and models. By inputting a prompt and adjusting the temperature parameter, you can observe how the model‚Äôs output varies from predictable and deterministic to creative and varied.\n",
      "For example, using the prompt ‚ÄúThe sun rises in the‚Äù at different temperatures:\n",
      "\n",
      "Low Temperature (e.g., T = 0.2): The model will likely complete the sentence with ‚Äúeast,‚Äù reflecting a common and expected continuation.\n",
      "High Temperature (e.g., T = 1.2): The model might generate more imaginative completions like ‚Äúmorning haze‚Äù or ‚Äúgolden skies,‚Äù showcasing increased creativity.\n",
      "\n",
      "Adjusting the temperature parameter in such playgrounds provides valuable insights into controlling the balance between determinism and creativity in language model outputs.\n",
      "Sampling strategy\n",
      "Given the vector of probabilities, there are many ways to select the next token.\n",
      "A straightforward strategy is always picking the most likely token. Since the sampling process only considers the probabilities for the very next token, this ‚Äúgreedy decoding‚Äù leads to highly probable multi-token sequences being discarded if they start with a token that ‚Äì viewed in isolation ‚Äì is less likely.\n",
      "Using beam search or random sampling according to the token probabilities can mitigate this. While the former produces deterministic outputs and thus no variety, the latter can lead to the selection of highly improbable tokens, producing nonsensical sequences.\n",
      "A more balanced approach is top-k sampling, which restricts sampling of the next token to the k most probable tokens. Alternatively, in top-p sampling, only the most likely tokens up to a cumulative probability of p are considered. This approach adapts dynamically to the probability distribution, sampling from many tokens in uncertain scenarios and picking from only a few when the model is more confident. (p and k can be adjusted during training or inference time.)\n",
      "As ML Engineers, we can fine-tune temperature and sampling strategy parameters according to your project needs. For example, if our tasks require precision (e.g., technical writing or summarization), we‚Äôll use lower temperatures and top-k sampling to prioritize high-probability tokens. If we need more diversity, we‚Äôll begin with common default values (temperature 0.7, top-k: k = 40, top-p: p = 0.9). We‚Äôll iteratively adjust them based on the qualitative evaluation of outputs and document our findings to build a shared knowledge base with your team.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Customizing LLM Output: Post-Processing Techniques¬†            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How do we find the optimal hyperparameters?\n",
      "LLM training involves many hyperparameters, resulting in a combinatorial explosion of the search space. Simply guessing hyperparameters is unlikely to yield good results. Further, hyperparameters interact in complex ways, so the optimal value for one may depend on the values of others. Thus, adjusting hyperparameters one at a time may lead to suboptimal solutions, as we easily become trapped in local optima and don‚Äôt adequately explore the hyperparameter space.\n",
      "Finding an optimal combination of hyperparameters requires a systematic approach. First, it‚Äôs paramount to understand the relevant hyperparameters and their influence on the particular LLM. It‚Äôs essential to research how similar architectures were trained or how the LLM we want to fine-tune was pre-trained. Further, we should clarify the available time, our compute budget, and the training objectives.\n",
      "Next, we can sketch a roadmap. Can we afford to conduct experiments with particular hyperparameter combinations we believe are useful? Do we already have an experiment tracker and resource monitoring in place, or do we need to set it up first? What will be the decision points and criteria that ensure we end up with a fully trained LLM at the end of the project? Finally, we can start executing this roadmap and adjust our plans as we gather more information and insight.\n",
      "The BLOOM team published a detailed paper on their preliminary experiments to determine the optimal model size and architecture. They describe how they started with GPT-3‚Äôs hyperparameters and conducted trial runs to estimate the optimal balance between model size and number of tokens given their fixed compute budget. Similar experiments were run by the Meta team that trained Llama3, who also aimed to predict downstream task performance.\n",
      "Can we use traditional machine learning hyperparameter optimization methods for LLMs?\n",
      "Methods for systematic hyperparameter optimization have long been studied in machine learning:\n",
      "\n",
      "Learning curve analysis involves training models with varying hyperparameters over several epochs and plotting the loss to identify trends. In deep-learning models, plotting the gradient can further help assess whether and how efficiently a model learns.\n",
      "\n",
      "\n",
      "Grid search systematically steps through the hyperparameter space, training a model for each possible combination. Random search samples the hyperparameter space, training models for randomly selected combinations.\n",
      "\n",
      "While these approaches have successfully been applied to optimize LLM hyperparameters, their use is severely limited by the fact that LLMs are very expensive to train. The computational and memory requirements make it unviable to train large numbers of models. If training a model takes several months on a large cluster, we‚Äôll only get one shot at a full training run.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Observability in LLMOps: Different Levels of Scale            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Advanced strategies for LLM hyperparameter optimization\n",
      "Beyond starting from a well-known hyperparameter combination and systematically conducting experiments, there is a range of approaches for automatically identifying or optimizing LLM hyperparameters in specific circumstances.\n",
      "Population-based training (PBT)\n",
      "Population-Based Training (PBT) is an approach pioneered by Google DeepMind that combines the concepts of evolutionary search and online training. Instead of fixing hyperparameters at the start of training and leaving them static throughout the process, PBT adapts them dynamically, informed by the models‚Äô performance.\n",
      "In a nutshell, the population-based training process consists of the following steps:\n",
      "\n",
      "Set up a population of models, each with unique hyperparameters hi and weights i.¬†\n",
      "Train each model, updating i every iteration.\n",
      "After a fixed number of iterations, evaluate each model‚Äôs performance on a validation dataset.\n",
      "Identify models that are underperforming relative to others. Replace their current weights‚Äã and hyperparameters with those of a better-performing model (exploitation).\n",
      "Slightly perturb the hyperparameters of previously underperforming models to prevent the population from converging to a single configuration too early and improve diversity (exploration).\n",
      "Conclude the training if the compute budget is exhausted or the objective has been met. Otherwise, repeat the process starting from step 2.\n",
      "\n",
      "This process initially appears resource-intensive since it requires maintaining and updating multiple models simultaneously, which can increase total GPU hours. However, PBT‚Äôs dynamic refinement of hyperparameters during training can significantly save wall-clock time. By avoiding restarting from scratch for each hyperparameter configuration and leveraging partially trained models, PBT reduces the number of training epochs needed to achieve optimal performance.\n",
      "The 2017 DeepMind study on Population-Based Training (PBT) showcased its potential for LLMs by fine-tuning the first transformer model on the WMT 2014 English-German machine translation benchmark. They manually optimized a baseline model and compared it to a model where they used PBT to optimize the dropouts for different layers and the learning rate. Their evaluation showed that the PBT-optimized model outperformed their hand-tuned baseline. Further, they discovered that the learning rate schedule generated through PBT mimicked the human-created one. Starting with a small learning rate, it then jumped to a high value before something resembling an exponential decay‚Äù brought it down to a low value again. DeepMind‚Äôs original PBT transformer model also learned noticeably faster.\n",
      "Ray Tune is a hyperparameter tuning library that supports population-based training. It is part of the open-source Ray framework for scaling machine-learning applications. The Ray Tune documentation includes an example of tuning BERT and RoBERTa on the GLUE benchmark dataset using population-based training.\n",
      "Bayesian optimization\n",
      "Bayesian optimization is a popular method for efficiently navigating the hyperparameter space by building a probabilistic model (surrogate model) of the influence of the hyperparameters on the objective (e.g., validation loss). The surrogate model is used to predict promising hyperparameter combinations to try next. The results of this exploration are then used to refine the surrogate model.\n",
      "The 2024 paper Crafting Efficient Fine-Tuning Strategies for Large Language Models investigates the applicability of Bayesian optimization to fine-tuning LLMs. First, a population of N models is trained for a pre-defined budget t1. As each model is trained, the surrogate model is updated, and the updated version is used to set the hyperparameters of the next model. Once all N models are trained, the top k models are selected and are trained up to t2. Finally, the best model among the k fully trained models is selected.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                How to Optimize Hyperparameter Search Using Bayesian Optimization and Optuna¬†            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Adaptive Low-Rank Adaptation (LoRA)\n",
      "Low-Rank Adaptation (LoRA) is a popular technique for reducing the memory footprint and computational demands when fine-tuning LLMs. In brief, the idea is to represent the weights of the fine-tuned model as¬†\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Wfine = Wpre + ‚àÜW =¬† Wpre + BA\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here, the fine-tuned weights Wfine are the sum of the original weights Wpre and a difference ‚àÜW, which is the product of two matrices, B and A. Only B and A are updated during fine-tuning, while Wpre remains unchanged. If Wpre and ‚àÜW have dimensions m x n, B and A have dimensions m x r and r x n, respectively. If the rank r is much smaller than m and n, the number of weights to be updated is greatly reduced, leading to faster training progress while requiring less memory.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                LLM Fine-Tuning and Model Selection Using Neptune and Transformers¬†            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In practice, it is often unclear to which LLM components LoRA should be applied for the best outcome. While we know that not all weights influence task performance equally, identifying which components are important for a particular objective would require extensive ablation studies. Thus, LoRA is often applied across all suitable weight matrices in a model.\n",
      "AdaLoRA (Adaptive Low-Rank Adaptation) is a method to allocate a given parameter budget across weight matrices. The core idea is to apply LoRA to all LLM components but to use different values for the rank r. Important components use a matrix pair with a large r, leading to a ‚àÜW with many weights. Less important components are approximated using a lower-rank matrix pair. AdaLoRA assigns an importance score to each component and sets the values for r such that the total number of weights remains within the user-defined budget. This leads to an optimal training outcome for a fixed compute and memory budget.\n",
      "AdaMoLE (Adaptive Mixture of Low-Rank Adaptation Experts) similarly aims to reduce the number of weights that need to be updated. It replaces the single low-rank matrix pair of the original LoRA with a collection of multiple matrix pairs (LoRA experts) that are activated dynamically based on the input context. This enables the LLM to learn different tasks with a minimal total number of weights.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Related                \n",
      "\n",
      "                Mixture of Experts LLMs: Key Concepts Explained            \n",
      "\n",
      "\n",
      "                    Read more                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hands-on: LLM hyperparameter optimization with neptune.ai\n",
      "Optuna is a framework for optimizing hyperparameter search using Bayesian optimization. It can be applied to various machine-learning tasks, including LLM hyperparameter tuning.\n",
      "To see this in action, we‚Äôve prepared a Colab notebook that walks you through the process of finding the optimal combination of learning rate, batch size, and number of epochs for fine-tuning a Hugging Face Transformers model on the IMBD dataset.\n",
      "The tutorial uses neptune.ai to track training progress and analyze the different hyperparameters. If you don‚Äôt want to go through the tutorial yourself right now, you can still explore example results in this public Neptune project.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Editor‚Äôs note\n",
      " \n",
      "\n",
      "\n",
      "    \n",
      "    How about being one of the first to access Neptune Scale?\n",
      "    \n",
      "Neptune Scale is our upcoming product release built for teams that train foundation models. It offers enhanced scalability and exciting new features. You can join our beta program to benefit from Neptune Scale earlier.\n",
      "\n",
      "\n",
      "\n",
      "See the docs¬†or watch a short¬†product demo (2 min)\n",
      "\n",
      "\n",
      "\n",
      "Play with a live Neptune Scale project\n",
      "\n",
      "\n",
      "\n",
      "Request your early access\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What‚Äôs next in LLM hyperparameter optimization?\n",
      "Finding an optimal combination of hyperparameters is essential for training LLMs. In this article, we‚Äôve reviewed key LLM hyperparameters and their influence on the model and training performance. We‚Äôve also discussed how to approach hyperparameter optimization systematically and explored methods to assist or even automate this task in certain scenarios.From the examples of hyperparameter choices for state-of-the-art LLMs, we‚Äôve seen that while architectures, training tasks, and data change, most models are trained with relatively similar learning rate schedules and optimizer configurations. As our understanding of the model and training mechanics deepens and more experiments yield empirical evidence, we‚Äôll likely see an evolution of the standard recipes and more diversity.\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tWas the article useful?\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tYes\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tNo\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tSuggest changes\t\t\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Your email\n",
      "\n",
      " Your message (optional)\n",
      "\n",
      "\n",
      "This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I am familiar with the Privacy Policy*\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Submit\n",
      "\n",
      "Œî\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tMore about\t\t\t\n",
      "\t\t\tHyperparameter Optimization For LLMs: Advanced Strategies\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\tCheck out our \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "product resources \n",
      "and\n",
      "\n",
      "\n",
      "\n",
      "related articles below:\n",
      "\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRelated article\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tFrom Research to Production: Building The Most Scalable Experiment Tracker For Foundation Models\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRelated article\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tHow to Build and Evaluate a RAG System Using LangChain, Ragas, and neptune.ai\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRelated article\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tFine-Tuning Llama 3 with LoRA: Step-by-Step Guide\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tProduct resource\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tHow Neptune Helps Artera Bring AI Solutions to Market Faster\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tExplore more content topics:\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tComputer Vision\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tGeneral\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tLLMOps\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tML Model Development\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tML Tools\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tMLOps\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tNatural Language Processing\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tPaper Reflections\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tProduct Updates\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tReinforcement Learning\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tTabular Data\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tTime Series\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markdown = extract_content(html, format='markdown')\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### package main_content_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<article class=\"single-post\">\\n'\n",
      " ' <div class=\"l-container l-container--main\">\\n'\n",
      " '  <div class=\"l-content content-wrapper js-content\">\\n'\n",
      " '   <section class=\"block-note c-box c-box--default c-box--dark '\n",
      " 'c-box--no-hover c-box--standard\" '\n",
      " 'id=\"note-block_0a2efafcec672c32672d6121959d76cf\">\\n'\n",
      " '    <h3 class=\"block-note__header\">\\n'\n",
      " '     TL;DR\\n'\n",
      " '    </h3>\\n'\n",
      " '    <div class=\"block-note__content\">\\n'\n",
      " '     <div class=\"c-item c-item--text\">\\n'\n",
      " '      <img alt=\"\" class=\"c-item__arrow\" decoding=\"async\" height=\"10\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '      <div class=\"c-item__content\">\\n'\n",
      " '       <p>\\n'\n",
      " '        Finding an optimal set of hyperparameters is essential for efficient '\n",
      " 'and effective training of Large Language Models (LLMs).\\n'\n",
      " '       </p>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <div class=\"c-item c-item--text\">\\n'\n",
      " '      <img alt=\"\" class=\"c-item__arrow\" decoding=\"async\" height=\"10\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '      <div class=\"c-item__content\">\\n'\n",
      " '       <p>\\n'\n",
      " '        The key LLM hyperparameters influence the model size, learning rate, '\n",
      " 'learning behavior, and token generation process.\\n'\n",
      " '       </p>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <div class=\"c-item c-item--text\">\\n'\n",
      " '      <img alt=\"\" class=\"c-item__arrow\" decoding=\"async\" height=\"10\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '      <div class=\"c-item__content\">\\n'\n",
      " '       <p>\\n'\n",
      " '        Due to their computational demands, traditional methods for '\n",
      " 'optimizing hyperparameters, such as grid search, are impractical for LLMs.\\n'\n",
      " '       </p>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <div class=\"c-item c-item--text\">\\n'\n",
      " '      <img alt=\"\" class=\"c-item__arrow\" decoding=\"async\" height=\"10\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '      <div class=\"c-item__content\">\\n'\n",
      " '       <p>\\n'\n",
      " '        Advanced hyperparameter optimization strategies, like '\n",
      " 'population-based training, Bayesian optimization, and adaptive LoRA, promise '\n",
      " 'to balance computational effort and outcome.\\n'\n",
      " '       </p>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </section>\\n'\n",
      " '   <p>\\n'\n",
      " '    The rise of large language models (LLMs) is bringing advances in text '\n",
      " 'generation and contextual understanding. Hyperparameters control the size of '\n",
      " 'LLMs, their training process, and how they generate outputs.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    An optimal combination of hyperparameters is fundamental to efficiently '\n",
      " 'pre-training and fine-tuning LLMs. Since LLM training is computationally '\n",
      " 'intensive, exhaustive experimentation is not viable. This rules out '\n",
      " 'traditional machine-learning hyperparameter optimization (HPO) methods that '\n",
      " 'rely on systematically exploring the hyperparameter space by training many '\n",
      " 'models with slightly different configurations.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    When configuring models and training processes, LLM developers rely on a '\n",
      " 'thorough understanding of each hyperparameter‚Äôs influence, insights from '\n",
      " 'fundamental research, and empirical evidence gained from training '\n",
      " 'state-of-the-art foundation models. Methods for estimating optimal '\n",
      " 'hyperparameter values with limited compute budgets and adapting '\n",
      " 'hyperparameters throughout the training process can help pre-training and '\n",
      " 'fine-tuning.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    After reading this article, you‚Äôll be able to answer the following '\n",
      " 'questions:\\n'\n",
      " '   </p>\\n'\n",
      " '   <ul class=\"wp-block-list\">\\n'\n",
      " '    <li>\\n'\n",
      " '     What key hyperparameters should be considered when developing, '\n",
      " 'training, and applying LLMs?\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     How does each hyperparameter influence the LLM, and which trade-offs do '\n",
      " 'we need to be aware of?\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     How can we select an optimal combination of hyperparameters in our '\n",
      " 'scenario without fully training multiple model variants?\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     What advanced hyperparameter optimization techniques are available for '\n",
      " 'LLMs, and when can we apply them?\\n'\n",
      " '    </li>\\n'\n",
      " '   </ul>\\n'\n",
      " '   <h2 class=\"wp-block-heading\" id=\"h-llm-hyperparameters\">\\n'\n",
      " '    LLM hyperparameters\\n'\n",
      " '   </h2>\\n'\n",
      " '   <p>\\n'\n",
      " '    A\\n'\n",
      " '    <em>\\n'\n",
      " '     hyperparameter\\n'\n",
      " '    </em>\\n'\n",
      " '    is a configuration value that controls the behavior of a '\n",
      " 'machine-learning model during the training or inference process. Unlike '\n",
      " 'model parameters (the weights), which are learned directly from the training '\n",
      " 'data, hyperparameters are defined by the model developers. A hyperparameter '\n",
      " 'can be constant or adjusted dynamically according to predefined rules or '\n",
      " 'schedules.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h3 class=\"wp-block-heading\" id=\"h-model-size\">\\n'\n",
      " '    Model size\\n'\n",
      " '   </h3>\\n'\n",
      " '   <p>\\n'\n",
      " '    In the case of LLMs, we often work with pre-trained models, where the '\n",
      " 'activation functions, internal architecture of layers or blocks, and their '\n",
      " 'connections‚Äîall examples of hyperparameters‚Äîare fixed. If our pre-trained '\n",
      " 'LLM of choice is available in different sizes, the model size is the only '\n",
      " 'hyperparameter affecting the model‚Äôs makeup we can actively control.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    The size of an LLM refers to the total number of parameters it contains, '\n",
      " 'which influences the model‚Äôs capacity to understand and generate complex '\n",
      " 'language patterns. Hyperparameters set and tuned during pre-training '\n",
      " 'influence the total size of an LLM.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    One hyperparameter influencing a model‚Äôs size is its depth, '\n",
      " 'corresponding to the total number of layers stacked sequentially. Each '\n",
      " 'additional layer in an LLM adds more parameters, such as the weights for the '\n",
      " 'self-attention mechanism and feed-forward layers in a transformer block.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Another hyperparameter influencing an LLM‚Äôs size is its hidden size, '\n",
      " 'which refers to the dimensionality of the token embeddings and the internal '\n",
      " 'representations within each layer. The hidden size determines how richly the '\n",
      " 'model can encode information about each input token and how effectively it '\n",
      " 'can process complex language patterns. A larger hidden size means each token '\n",
      " 'is represented in a higher-dimensional space, allowing the model to capture '\n",
      " 'more detailed semantic and syntactic nuances.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Further, the number of parallel attention heads in each transformer '\n",
      " 'block influences the size of the LLM. Multiple heads allow the model to '\n",
      " 'focus on different input aspects simultaneously. Through\\n'\n",
      " '    <a '\n",
      " 'href=\"/blog/fine-tuning-llama-3-with-lora#h-deep-dive-multi-head-multi-query-and-grouped-query-attention\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     multi-query and grouped-query attention\\n'\n",
      " '    </a>\\n'\n",
      " '    , we can reduce the number of necessary parameters.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Finally, the vocabulary size and context window (maximum sequence '\n",
      " 'length) also impact the model‚Äôs size. They determine the language diversity '\n",
      " 'a model can handle and the context length it can maintain, respectively.\\n'\n",
      " '    <br/>\\n'\n",
      " '    <br/>\\n'\n",
      " '    These hyperparameters, set before beginning the training process and '\n",
      " 'unable to be changed later, determine the model size. For example, GPT-3 has '\n",
      " '96 layers, a hidden size of 12,288, 96 attention heads, a\\n'\n",
      " '    <a '\n",
      " 'href=\"https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     vocabulary of 50,257 tokens\\n'\n",
      " '    </a>\\n'\n",
      " '    , and a context window of 2,048 tokens, resulting in\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2005.14165\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     a total of 175 billion parameters\\n'\n",
      " '    </a>\\n'\n",
      " '    .\\n'\n",
      " '    <br/>\\n'\n",
      " '   </p>\\n'\n",
      " '   <a class=\"block-cta-box-related-link l-margin__top--standard '\n",
      " 'l-margin__bottom--standard\" '\n",
      " 'href=\"/blog/future-of-mlops-and-gpt-3-with-david-hershey\" '\n",
      " 'id=\"cta-box-related-link-block_3e5add5b7a53be4df8037012a309f769\" '\n",
      " 'rel=\"nofollow noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '    <div class=\"block-cta-box-related-link__description-wrapper '\n",
      " 'block-cta-box-related-link__description-wrapper--full\">\\n'\n",
      " '     <div class=\"c-eyebrow\">\\n'\n",
      " '      <img alt=\"\" class=\"c-eyebrow__icon\" decoding=\"async\" height=\"16\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-related--article.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '      <div class=\"c-eyebrow__text\">\\n'\n",
      " '       Related\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <h3 class=\"c-header\" '\n",
      " 'id=\"h-what-does-gpt-3-mean-for-the-future-of-mlops-with-david-hershey\">\\n'\n",
      " '      What Does GPT-3 Mean For the Future of MLOps? With David Hershey\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '      <span class=\"c-button__text\">\\n'\n",
      " '       Read more\\n'\n",
      " '      </span>\\n'\n",
      " '      <img alt=\"\" class=\"c-button__arrow\" decoding=\"async\" height=\"12\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </a>\\n'\n",
      " '   <h3 class=\"wp-block-heading\" id=\"h-learning-rate\">\\n'\n",
      " '    Learning rate\\n'\n",
      " '   </h3>\\n'\n",
      " '   <p>\\n'\n",
      " '    The learning rate (LR) is a critical hyperparameter in training LLMs. '\n",
      " 'Optimizing these hyperparameters is essential for efficient learning, stable '\n",
      " 'convergence, and good generalization to unseen data.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    The learning rate determines how much model weights are changed during '\n",
      " 'each update. A high learning rate helps speed up the training process but '\n",
      " 'increases the risk of instability and overfitting. A low learning rate '\n",
      " 'increases stability and tends to benefit generalization but leads to slow '\n",
      " 'training.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    In the case of LLMs, the learning rate is typically not constant but '\n",
      " 'varies as training progresses. This variation is governed by a learning rate '\n",
      " 'schedule (LRS). The schedule is usually tied to the number of tokens '\n",
      " 'seen‚Äîeither directly, or indirectly through the number of samples, steps, or '\n",
      " 'epochs. At a high level, it contains phases of a rising, constant, and '\n",
      " 'decreasing learning rate.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h4 class=\"wp-block-heading\">\\n'\n",
      " '    How does the learning rate affect training duration and quality?\\n'\n",
      " '   </h4>\\n'\n",
      " '   <p>\\n'\n",
      " '    Following theoretical\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2410.05192\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     work by Stanford researcher Kaiyue Wen and colleagues published in '\n",
      " 'December 2024\\n'\n",
      " '    </a>\\n'\n",
      " '    , we can think of LLM training as progressing along a loss landscape '\n",
      " 'that looks like a river valley. They hypothesize that the existence and '\n",
      " 'overall direction of the river are due to the facts and knowledge an LLM '\n",
      " 'learns, which are reflected as highly deterministic and, therefore, '\n",
      " 'easy-to-predict tokens. The valley slopes arise from flexibility and '\n",
      " 'ambiguity inherent to language, i.e., hard-to-predict tokens.\\n'\n",
      " '   </p>\\n'\n",
      " '   <div class=\"wp-block-image\">\\n'\n",
      " '    <figure class=\"aligncenter size-full is-resized\">\\n'\n",
      " '     <img alt=\"Visualization of LLM training as traveling down a river '\n",
      " 'valley. Using a stable but high learning rate ensures quick progress down '\n",
      " 'the river but leads to jumps between relatively high loss values. Reducing '\n",
      " 'the learning rate during a subsequent decay phase brings the model towards a '\n",
      " 'local loss minimum. \" class=\"wp-image-43615\" data-recalc-dims=\"1\" '\n",
      " 'decoding=\"async\" fetchpriority=\"high\" height=\"784\" sizes=\"(max-width: 575px) '\n",
      " '100vw, 575px\" '\n",
      " 'src=\"https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-4.png?resize=575%2C784&amp;ssl=1\" '\n",
      " 'srcset=\"https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-4.png?w=575&amp;ssl=1 '\n",
      " '575w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-4.png?resize=147%2C200&amp;ssl=1 '\n",
      " '147w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-4.png?resize=220%2C300&amp;ssl=1 '\n",
      " '220w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-4.png?resize=120%2C164&amp;ssl=1 '\n",
      " '120w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-4.png?resize=160%2C218&amp;ssl=1 '\n",
      " '160w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-4.png?resize=300%2C409&amp;ssl=1 '\n",
      " '300w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-4.png?resize=480%2C654&amp;ssl=1 '\n",
      " '480w\" style=\"width:387px;height:auto\" width=\"575\"/>\\n'\n",
      " '     <figcaption class=\"wp-element-caption\">\\n'\n",
      " '      Visualization of LLM training as traveling down a river valley. Using '\n",
      " 'a stable but high learning rate ensures quick progress down the river but '\n",
      " 'leads to jumps between relatively high loss values. Reducing the learning '\n",
      " 'rate during a subsequent decay phase brings the model towards a local loss '\n",
      " 'minimum. |\\n'\n",
      " '      <a href=\"https://arxiv.org/pdf/2410.05192\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '       Source\\n'\n",
      " '      </a>\\n'\n",
      " '     </figcaption>\\n'\n",
      " '    </figure>\\n'\n",
      " '   </div>\\n'\n",
      " '   <p>\\n'\n",
      " '    In this picture, the training goal is to reach the river mouth, at which '\n",
      " 'point we should be as close to the bottom of the valley as possible. The '\n",
      " 'first crucial insight is that it does not matter whether we stay at the '\n",
      " 'bottom of the valley until then. Thus, if we can make faster progress down '\n",
      " 'the river by bouncing back and forth between points high up the loss '\n",
      " 'valley‚Äôs slopes, we can do this without affecting the final outcome.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Thus, we should aim to use a high learning rate‚Äîresulting in large steps '\n",
      " 'towards the loss minimum but leading to wildly fluctuating loss values‚Äîfor '\n",
      " 'as long as possible. Towards the end of the training, the learning rate '\n",
      " 'should be decreased to a very low value. This will slow down progress '\n",
      " 'towards the river mouth but reduce the oscillations to a point where we '\n",
      " 'constantly stay at the valley‚Äôs bottom, i.e., the local loss minimum.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    However, all of this is only going to work if we are already in a '\n",
      " 'sufficiently deep loss river valley. When training is first starting, a high '\n",
      " 'learning rate will lead to undirected jumps across the loss landscape. To '\n",
      " 'avoid this, learning rate schedules for LLMs start with a small learning '\n",
      " 'rate and slowly ramp it up to its maximum value. This is called the warmup '\n",
      " 'phase.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h4 class=\"wp-block-heading\">\\n'\n",
      " '    Cosine schedule\\n'\n",
      " '   </h4>\\n'\n",
      " '   <p>\\n'\n",
      " '    The cosine schedule (also known as cosine decay or cosine annealing) '\n",
      " 'implements this approach by starting with a linear warmup phase that brings '\n",
      " 'the learning rate to its maximum value, followed by a slow decay following '\n",
      " 'the cosine function:\\n'\n",
      " '   </p>\\n'\n",
      " '   <section class=\"block-note c-box c-box--default c-box--dark '\n",
      " 'c-box--no-hover c-box--standard\" '\n",
      " 'id=\"note-block_7432ba86ee2044b9cfc9300d1d406c4b\">\\n'\n",
      " '    <div class=\"block-note__content\">\\n'\n",
      " '     <div class=\"c-item c-item--wysiwyg_editor\">\\n'\n",
      " '      <div class=\"c-item__content\">\\n'\n",
      " '       <p>\\n'\n",
      " '        LR(t) = LR\\n'\n",
      " '        <sub>\\n'\n",
      " '         min\\n'\n",
      " '        </sub>\\n'\n",
      " '        + 0.5 (LR\\n'\n",
      " '        <sub>\\n'\n",
      " '         max\\n'\n",
      " '        </sub>\\n'\n",
      " '        ‚Äì LR\\n'\n",
      " '        <sub>\\n'\n",
      " '         min\\n'\n",
      " '        </sub>\\n'\n",
      " '        ) (1 + cos(œÄ t/T)\\n'\n",
      " '       </p>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </section>\\n'\n",
      " '   <p>\\n'\n",
      " '    Here,\\n'\n",
      " '    <em>\\n'\n",
      " '     LR\\n'\n",
      " '    </em>\\n'\n",
      " '    <em>\\n'\n",
      " '     <sub>\\n'\n",
      " '      min\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    and\\n'\n",
      " '    <em>\\n'\n",
      " '     LR\\n'\n",
      " '    </em>\\n'\n",
      " '    <em>\\n'\n",
      " '     <sub>\\n'\n",
      " '      max\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    are the minimum and maximum learning rates,\\n'\n",
      " '    <em>\\n'\n",
      " '     t\\n'\n",
      " '    </em>\\n'\n",
      " '    is the training step, and\\n'\n",
      " '    <em>\\n'\n",
      " '     T\\n'\n",
      " '    </em>\\n'\n",
      " '    is the total number of training steps. The advantage of this schedule is '\n",
      " 'that it stays close to the peak learning rate for a long time, and the final '\n",
      " 'decay is gradual. It‚Äôs also easy to implement, as it depends on just three '\n",
      " 'hyperparameters (\\n'\n",
      " '    <em>\\n'\n",
      " '     LR\\n'\n",
      " '    </em>\\n'\n",
      " '    <em>\\n'\n",
      " '     <sub>\\n'\n",
      " '      max\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    ,\\n'\n",
      " '    <em>\\n'\n",
      " '     LR\\n'\n",
      " '    </em>\\n'\n",
      " '    <em>\\n'\n",
      " '     <sub>\\n'\n",
      " '      min\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    , and\\n'\n",
      " '    <em>\\n'\n",
      " '     T\\n'\n",
      " '    </em>\\n'\n",
      " '    ) linked by the cosine function.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Cosine schedules have been highly popular for pretraining LLMs. For '\n",
      " 'example, it was used for\\n'\n",
      " '    <a href=\"https://arxiv.org/abs/2211.05100\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     BLOOM\\n'\n",
      " '    </a>\\n'\n",
      " '    , a 176-billion-parameter multilingual model developed by the\\n'\n",
      " '    <a href=\"https://bigscience.huggingface.co/\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     BigScience Research Workshop\\n'\n",
      " '    </a>\\n'\n",
      " '    and released in 2022. In an initial warmup phase, the learning rate was '\n",
      " 'ramped to a peak of 6 x 10\\n'\n",
      " '    <sup>\\n'\n",
      " '     -5\\n'\n",
      " '    </sup>\\n'\n",
      " '    over 375 million tokens. Afterward, it was lowered to 10% of this value '\n",
      " 'with cosine decay over 410 million tokens and remained at this value. The '\n",
      " 'implementation and detailed description are publicly accessible\\n'\n",
      " '    <a '\n",
      " 'href=\"https://github.com/bigscience-workshop/bigscience/tree/master/train/tr11-176B-ml#optimizer\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     in BLOOM‚Äôs GitHub repository\\n'\n",
      " '    </a>\\n'\n",
      " '    .\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    For\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2407.21783\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     pre-training their Llama 3 405B model\\n'\n",
      " '    </a>\\n'\n",
      " '    , Meta used a slightly more involved variant of the cosine schedule. In '\n",
      " 'the first stage, a warm-up phase of up to 8,000 steps brought the learning '\n",
      " 'rate to a maximum of 8 x 10\\n'\n",
      " '    <sup>\\n'\n",
      " '     -5\\n'\n",
      " '    </sup>\\n'\n",
      " '    . Subsequently, the learning rate decreased to 8 x 10\\n'\n",
      " '    <sup>\\n'\n",
      " '     -7\\n'\n",
      " '    </sup>\\n'\n",
      " '    over 1.2 million steps with a cosine decay. After the second stage '\n",
      " 'focused on training the LLM up to its final context length of 128,000 '\n",
      " 'tokens, the learning rate linearly decreased to 0 over 40 million tokens in '\n",
      " 'the third stage. Supervised fine-tuning was conducted over about 9,000 steps '\n",
      " 'with a learning rate of 10\\n'\n",
      " '    <sup>\\n'\n",
      " '     -5\\n'\n",
      " '    </sup>\\n'\n",
      " '    .\\n'\n",
      " '   </p>\\n'\n",
      " '   <a class=\"block-cta-box-related-link l-margin__top--standard '\n",
      " 'l-margin__bottom--standard\" href=\"/blog/fine-tuning-llama-3-with-lora\" '\n",
      " 'id=\"cta-box-related-link-block_1ecae09cbf9e0f39b12a397540cdb430\" '\n",
      " 'rel=\"nofollow noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '    <div class=\"block-cta-box-related-link__description-wrapper '\n",
      " 'block-cta-box-related-link__description-wrapper--full\">\\n'\n",
      " '     <div class=\"c-eyebrow\">\\n'\n",
      " '      <img alt=\"\" class=\"c-eyebrow__icon\" decoding=\"async\" height=\"16\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-related--article.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '      <div class=\"c-eyebrow__text\">\\n'\n",
      " '       Related\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <h3 class=\"c-header\" '\n",
      " 'id=\"h-fine-tuning-llama-3-with-lora-step-by-step-guide\">\\n'\n",
      " '      Fine-Tuning Llama 3 with LoRA: Step-by-Step Guide\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '      <span class=\"c-button__text\">\\n'\n",
      " '       Read more\\n'\n",
      " '      </span>\\n'\n",
      " '      <img alt=\"\" class=\"c-button__arrow\" decoding=\"async\" height=\"12\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </a>\\n'\n",
      " '   <p>\\n'\n",
      " '    A major disadvantage of the cosine schedule is that the total number of '\n",
      " 'training steps has to be known beforehand. When training large foundation '\n",
      " 'models, the total compute budget is typically set, and\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2203.15556\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     the optimal number of training tokens can be estimated\\n'\n",
      " '    </a>\\n'\n",
      " '    . However, when fine-tuning or experimenting, it would be preferable to '\n",
      " 'base the decision on when to end training on the model‚Äôs performance.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h4 class=\"wp-block-heading\">\\n'\n",
      " '    Warmup-stable-decay schedule\\n'\n",
      " '   </h4>\\n'\n",
      " '   <p>\\n'\n",
      " '    The warmup-stable-decay (WSD) schedule is a simple protocol introduced '\n",
      " 'by\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2404.06395\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Shengding Hu and colleagues at Tsinghua University in 2024\\n'\n",
      " '    </a>\\n'\n",
      " '    . It starts with a linear warmup to the maximum learning rate, keeps the '\n",
      " 'learning rate constant for the majority of the training, and ramps it down '\n",
      " 'at the end.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Through experiments, they found that a decay phase that makes up 10% of '\n",
      " 'the total length is sufficient. They also demonstrated that a WSD schedule '\n",
      " 'leads to a lower loss than a cosine schedule. According to\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2410.05192\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Wen and colleagues at Stanford\\n'\n",
      " '    </a>\\n'\n",
      " '    , this can readily be understood in the river valley picture. In the WSD '\n",
      " 'schedule, the learning rate stays at a high value longer than in the cosine '\n",
      " 'schedule. Hence, we make it further down the valley before dropping to its '\n",
      " 'bottom. Further, their analysis shows that training progress in the stable '\n",
      " 'phase is dominated by learning to predict deterministic tokens (facts and '\n",
      " 'knowledge), while in the decay phase, the LLM learns the stochastic tokens '\n",
      " '(language variability).\\n'\n",
      " '   </p>\\n'\n",
      " '   <div class=\"wp-block-image\">\\n'\n",
      " '    <figure class=\"aligncenter size-full is-resized\">\\n'\n",
      " '     <img alt=\"Comparison of the loss curves resulting from a cosine and '\n",
      " 'warmup-stable-decay (WSD) learning rate schedule. In the WSD schedule, the '\n",
      " 'learning rate remains at a constant high value during the stable phase. This '\n",
      " 'leads to high intermediate loss values as the loss fluctuates around the '\n",
      " 'local minimum as it progresses towards lower values. During the final 10% of '\n",
      " 'the total training steps, the learning rate is decreased to its minimum, '\n",
      " 'leading to a sharp drop in the loss. Since the learning rate remained at a '\n",
      " 'high value for longer, the final loss resulting from the WSD schedule is '\n",
      " 'smaller than the loss from the cosine schedule. \" class=\"wp-image-43621\" '\n",
      " 'data-recalc-dims=\"1\" decoding=\"async\" height=\"661\" sizes=\"(max-width: 899px) '\n",
      " '100vw, 899px\" '\n",
      " 'src=\"https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-6.png?resize=899%2C661&amp;ssl=1\" '\n",
      " 'srcset=\"https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-6.png?w=899&amp;ssl=1 '\n",
      " '899w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-6.png?resize=768%2C565&amp;ssl=1 '\n",
      " '768w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-6.png?resize=200%2C147&amp;ssl=1 '\n",
      " '200w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-6.png?resize=220%2C162&amp;ssl=1 '\n",
      " '220w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-6.png?resize=120%2C88&amp;ssl=1 '\n",
      " '120w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-6.png?resize=160%2C118&amp;ssl=1 '\n",
      " '160w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-6.png?resize=300%2C221&amp;ssl=1 '\n",
      " '300w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-for-LLMs-6.png?resize=480%2C353&amp;ssl=1 '\n",
      " '480w\" style=\"width:548px;height:auto\" width=\"899\"/>\\n'\n",
      " '     <figcaption class=\"wp-element-caption\">\\n'\n",
      " '      Comparison of the loss curves resulting from a cosine and '\n",
      " 'warmup-stable-decay (WSD) learning rate schedule. In the WSD schedule, the '\n",
      " 'learning rate remains at a constant high value during the stable phase. This '\n",
      " 'leads to high intermediate loss values as the loss fluctuates around the '\n",
      " 'local minimum as it progresses towards lower values. During the final 10% of '\n",
      " 'the total training steps, the learning rate is decreased to its minimum, '\n",
      " 'leading to a sharp drop in the loss. Since the learning rate remained at a '\n",
      " 'high value for longer, the final loss resulting from the WSD schedule is '\n",
      " 'smaller than the loss from the cosine schedule. |\\n'\n",
      " '      <a href=\"https://arxiv.org/pdf/2410.05192\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '       Source\\n'\n",
      " '      </a>\\n'\n",
      " '     </figcaption>\\n'\n",
      " '    </figure>\\n'\n",
      " '   </div>\\n'\n",
      " '   <p>\\n'\n",
      " '    While a WSD schedule yields a lower loss for the same training budget, '\n",
      " 'knowing the total number of training steps ahead of time is still required '\n",
      " 'for scheduling the decay phase. However, the WSD schedule offers a '\n",
      " 'straightforward way to extend the total number of training steps '\n",
      " 'retroactively: If we find that our final model‚Äôs performance is '\n",
      " 'unsatisfactory, we can resume training from a model snapshot taken at the '\n",
      " 'end of the stable phase. This beams us back a small distance up the loss '\n",
      " 'river valley, from where we continue making large jumpy steps towards the '\n",
      " 'river mouth as if we had never descended down to the valley‚Äôs bottom in the '\n",
      " 'first place.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Restarting this way, we still benefit from 90% of the compute budget '\n",
      " 'spent so far. It allows us to determine the compute budget we need as we go, '\n",
      " 'producing fully trained intermediate models‚Äîsomething that the cosine '\n",
      " 'schedule inherently does not allow for.\\n'\n",
      " '   </p>\\n'\n",
      " '   <section class=\"block-i-box l-margin__top--large '\n",
      " 'l-margin__bottom--x-large\" '\n",
      " 'id=\"i-box-block_bdb6122b52ac44ea5db42e910c122f4f\">\\n'\n",
      " '    <div class=\"block-i-box__inner\">\\n'\n",
      " '     <div class=\"block-custom-text white l-padding__top--0 '\n",
      " 'l-padding__bottom--0\" '\n",
      " 'id=\"custom-text-block_574c5d05458323a5150976e0ee02aa61\" style=\"max-width: '\n",
      " '100%; font-size: 1rem; line-height: 1.33; font-weight: 600;\">\\n'\n",
      " '      Track months-long model training with more confidence. Use neptune.ai '\n",
      " 'forking feature to iterate faster and optimize the usage of GPU resources.\\n'\n",
      " '     </div>\\n'\n",
      " '     <div class=\"b-group-of-boxes l-padding__top--large '\n",
      " 'l-padding__bottom--large\" '\n",
      " 'id=\"group-of-boxes-block_41cc93591b430b485453fcd5fce8e48c\">\\n'\n",
      " '      <div class=\"c-wrapper c-wrapper--align-auto '\n",
      " 'c-wrapper--align-vertical-auto\">\\n'\n",
      " '       <div class=\"b-group-of-boxes__grid l-grid--cols-2 l-grid--boxes\">\\n'\n",
      " '        <div class=\"c-box c-box--transparent c-box--dark c-box--no-hover '\n",
      " 'c-box--micro c-box--vertical-center c-box--horizontal-flex-start '\n",
      " 'c-box--paddings-none l-margin__top--0 l-margin__bottom--0\">\\n'\n",
      " '         <p>\\n'\n",
      " '          With Neptune, users can visualize forked training out of the box. '\n",
      " 'This means you can:\\n'\n",
      " '         </p>\\n'\n",
      " '         <ul class=\"wp-block-list\">\\n'\n",
      " '          <li>\\n'\n",
      " '           Test multiple configs at the same time. Stop the runs that don‚Äôt '\n",
      " 'improve accuracy. And continue from the most accurate last step.\\n'\n",
      " '          </li>\\n'\n",
      " '          <li>\\n'\n",
      " '           Restart failed training sessions from any previous step. The '\n",
      " 'training history is inherited, and the entire experiment is visible on a '\n",
      " 'single chart.\\n'\n",
      " '          </li>\\n'\n",
      " '         </ul>\\n'\n",
      " '        </div>\\n'\n",
      " '        <div class=\"c-box c-box--transparent c-box--dark c-box--no-hover '\n",
      " 'c-box--micro c-box--vertical-flex-start c-box--horizontal-flex-start '\n",
      " 'c-box--paddings-none l-margin__top--0 l-margin__bottom--0\">\\n'\n",
      " '         <div class=\"block-app-screenshot '\n",
      " 'js-block-with-image-full-screen-modal\" '\n",
      " 'data-button-icon=\"https://neptune.ai/wp-content/themes/neptune/img/icon-close.svg\" '\n",
      " 'data-image-full-screen-modal=\"https://i0.wp.com/neptune.ai/wp-content/uploads/2024/11/Forking-of-runs.jpg?fit=1020%2C496&amp;ssl=1\" '\n",
      " 'data-show-controls=\"false\" data-unmute=\"false\" data-video-url=\"\" '\n",
      " 'id=\"app-screenshot-block_483e23fc40c559d00d73d1296ace5049\">\\n'\n",
      " '          <div class=\"block-app-screenshot__image-wrapper\">\\n'\n",
      " '           <div class=\"block-app-screenshot__bar\">\\n'\n",
      " '            <figure class=\"block-app-screenshot__bar-buttons-wrapper\">\\n'\n",
      " '             <img alt=\"\" class=\"block-app-screenshot__bar-buttons\" '\n",
      " 'height=\"9\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/app-screenshot/bar-buttons.svg\" '\n",
      " 'width=\"34\"/>\\n'\n",
      " '            </figure>\\n'\n",
      " '           </div>\\n'\n",
      " '           <img alt=\"\" class=\"block-app-screenshot__image\" height=\"496\" '\n",
      " 'srcset=\"\\n'\n",
      " '\\t\\t\\t\\t\\t'\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2024/11/Forking-of-runs.jpg?fit=480%2C233&amp;ssl=1 '\n",
      " '480w,\\t\\t\\t\\t\\t'\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2024/11/Forking-of-runs.jpg?fit=768%2C374&amp;ssl=1 '\n",
      " '768w,\\t\\t\\t\\t\\t'\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2024/11/Forking-of-runs.jpg?fit=1020%2C496&amp;ssl=1 '\n",
      " '1020w\" style=\"\" width=\"1020\"/>\\n'\n",
      " '           <div class=\"block-app-screenshot__overlay\">\\n'\n",
      " '            <a class=\"c-button c-button--primary c-button--small '\n",
      " 'c-button--cta\" '\n",
      " 'href=\"https://scale.neptune.ai/o/neptune/org/LLM-training-example/runs/compare?viewId=9d0e032a-5a78-4a0e-81d1-98e0a7c81a8f&amp;dash=charts&amp;query=((%60sys%2Ftags%60%3AstringSet%20CONTAINS%20%22forks%22))%20AND%20((%60sys%2Fgroup_tags%60%3AstringSet%20CONTAINS%20%22experiments_CGB5CSFI%22))&amp;lbViewUnpacked=true&amp;sortBy=%5B%22sys%2Fcreation_time%22%5D&amp;sortFieldType=%5B%22datetime%22%5D&amp;sortFieldAggregationMode=%5B%22auto%22%5D&amp;sortDirection=%5B%22descending%22%5D&amp;experimentsOnly=false&amp;runsLineage=FULL&amp;compare=u0MsW4a1PJIUJ75nglpjHa9XUKFfAmcBRbLhNatCHX20\">\\n'\n",
      " '             <img alt=\"\" class=\"c-button__icon\" decoding=\"async\" height=\"19\" '\n",
      " 'loading=\"lazy\" rel=\"nofollow noopener noreferrer\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button--test-tube.svg\" '\n",
      " 'target=\"_blank\" width=\"16\"/>\\n'\n",
      " '             <span class=\"c-button__text\">\\n'\n",
      " '              See in app\\n'\n",
      " '             </span>\\n'\n",
      " '            </a>\\n'\n",
      " '            <button class=\"js-c-image-full-screen-modal c-button '\n",
      " 'c-button--tertiary c-button--small\">\\n'\n",
      " '             <img alt=\"zoom\" class=\"c-button__icon\" decoding=\"async\" '\n",
      " 'height=\"17\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-zoom.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '             <span class=\"c-button__text\">\\n'\n",
      " '              Full screen preview\\n'\n",
      " '             </span>\\n'\n",
      " '            </button>\\n'\n",
      " '           </div>\\n'\n",
      " '          </div>\\n'\n",
      " '         </div>\\n'\n",
      " '        </div>\\n'\n",
      " '       </div>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <ul class=\"block-arrow-list block-list-item--font-size-regular\" '\n",
      " 'id=\"arrow-list-block_b1349a90904fb1435825c696dfc4ea48\">\\n'\n",
      " '      <li class=\"block-list-item\">\\n'\n",
      " '       <img alt=\"\" class=\"block-list-item__arrow lazyload\" '\n",
      " 'data-src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/list-item/arrow.svg\" '\n",
      " 'decoding=\"async\" height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '       <p>\\n'\n",
      " '        Check the\\n'\n",
      " '        <a href=\"https://docs-beta.neptune.ai/fork_experiment/\">\\n'\n",
      " '         documentation\\n'\n",
      " '        </a>\\n'\n",
      " '       </p>\\n'\n",
      " '      </li>\\n'\n",
      " '      <li class=\"block-list-item\">\\n'\n",
      " '       <img alt=\"\" class=\"block-list-item__arrow lazyload\" '\n",
      " 'data-src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/list-item/arrow.svg\" '\n",
      " 'decoding=\"async\" height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '       <p>\\n'\n",
      " '        Play with an\\n'\n",
      " '        <a '\n",
      " 'href=\"https://scale.neptune.ai/o/neptune/org/LLM-training-example/runs/compare?viewId=9d0e032a-5a78-4a0e-81d1-98e0a7c81a8f&amp;detailsTab=metadata&amp;dash=charts&amp;type=run&amp;experimentOnly=true&amp;compare=u0MsW4a1PJIUJ75nglpjHa9XUKFfAmcBRbLhNatCHX20\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '         interactive example project\\n'\n",
      " '        </a>\\n'\n",
      " '       </p>\\n'\n",
      " '      </li>\\n'\n",
      " '      <li class=\"block-list-item\">\\n'\n",
      " '       <img alt=\"\" class=\"block-list-item__arrow lazyload\" '\n",
      " 'data-src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/list-item/arrow.svg\" '\n",
      " 'decoding=\"async\" height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '       <p>\\n'\n",
      " '        <a href=\"/contact-us\" previewlistener=\"true\" rel=\"noreferrer '\n",
      " 'noopener\" target=\"_blank\">\\n'\n",
      " '         Get in touch\\n'\n",
      " '        </a>\\n'\n",
      " '        to go through a custom demo with our engineering team\\n'\n",
      " '       </p>\\n'\n",
      " '      </li>\\n'\n",
      " '     </ul>\\n'\n",
      " '    </div>\\n'\n",
      " '   </section>\\n'\n",
      " '   <h4 class=\"wp-block-heading\">\\n'\n",
      " '    Cyclical cosine schedule\\n'\n",
      " '   </h4>\\n'\n",
      " '   <p>\\n'\n",
      " '    Returning to a high learning rate after decaying to a minimum is not a '\n",
      " 'new idea in machine learning. Long established in gradient-free '\n",
      " 'optimization, it was made popular for deep learning training through the '\n",
      " '‚ÄúStochastic Gradient Descent with Warm Restarts‚Äù technique\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/1608.03983v5\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     proposed by Ilya Loshchilov and Frank Hutter in 2017\\n'\n",
      " '    </a>\\n'\n",
      " '    . The learning rate is governed by a function very similar to the one '\n",
      " 'for the cosine schedule:\\n'\n",
      " '   </p>\\n'\n",
      " '   <section class=\"block-note c-box c-box--default c-box--dark '\n",
      " 'c-box--no-hover c-box--standard\" '\n",
      " 'id=\"note-block_88f67063d3d3f366fe1fd8dfd023c4e0\">\\n'\n",
      " '    <div class=\"block-note__content\">\\n'\n",
      " '     <div class=\"c-item c-item--wysiwyg_editor\">\\n'\n",
      " '      <div class=\"c-item__content\">\\n'\n",
      " '       <p>\\n'\n",
      " '        LR(t) = LR\\n'\n",
      " '        <sub>\\n'\n",
      " '         min\\n'\n",
      " '        </sub>\\n'\n",
      " '        + 0.5 (LR\\n'\n",
      " '        <sub>\\n'\n",
      " '         max\\n'\n",
      " '        </sub>\\n'\n",
      " '        ‚àí LR\\n'\n",
      " '        <sub>\\n'\n",
      " '         min\\n'\n",
      " '        </sub>\\n'\n",
      " '        ) (1 + cos(œÄ (t mod T)/T))\\n'\n",
      " '       </p>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </section>\\n'\n",
      " '   <p>\\n'\n",
      " '    This time,\\n'\n",
      " '    <em>\\n'\n",
      " '     T\\n'\n",
      " '    </em>\\n'\n",
      " '    is not the total number of training steps but is understood as the '\n",
      " 'schedule‚Äôs period. For example, we might train for 10,000 steps with\\n'\n",
      " '    <em>\\n'\n",
      " '     T\\n'\n",
      " '    </em>\\n'\n",
      " '    = 1,000, leading to ten consecutive cosine decay cycles. Commonly, LR\\n'\n",
      " '    <sub>\\n'\n",
      " '     max\\n'\n",
      " '    </sub>\\n'\n",
      " '    is set to a new, lower value at the beginning of each cycle.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    In the loss landscape river valley, we‚Äôre climbing down to the bottom '\n",
      " 'over\\n'\n",
      " '    <em>\\n'\n",
      " '     T\\n'\n",
      " '    </em>\\n'\n",
      " '    steps, making ever slower progress down the river as we keep closer to '\n",
      " 'the bottom. Then, we immediately go back to make large jumps toward the '\n",
      " 'river mouth high up the valley‚Äôs slopes.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Right at the beginning of a new cosine cycle, the loss will be '\n",
      " 'significantly higher than it was previously. This could be due to the jump '\n",
      " 'in the learning rate, which might perturb the model. However,\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2410.05192\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Wen and colleagues\\n'\n",
      " '    </a>\\n'\n",
      " '    argue, based on their experiments and theoretical insights, that it is '\n",
      " 'the result of training with a small learning rate for too long.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Whatever the cause, this doesn‚Äôt just make training less efficient. It‚Äôs '\n",
      " 'also an obstacle to continue model training later. Whether we aim to further '\n",
      " 'pre-train on newly acquired or different data, fine-tune an LLM, or '\n",
      " 'incrementally evolve a model in a\\n'\n",
      " '    <a href=\"/blog/continual-learning-methods-and-application\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     continual learning scenario\\n'\n",
      " '    </a>\\n'\n",
      " '    ‚Äîideally, we could take a model snapshot and train it effectively, '\n",
      " 'making the most of the compute budget we have available and the compute '\n",
      " 'budget we have already spent. The learning rate schedule used during '\n",
      " 'pretraining directly impacts this.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h4 class=\"wp-block-heading\">\\n'\n",
      " '    Cyclical warmup-stable-decay schedule\\n'\n",
      " '   </h4>\\n'\n",
      " '   <p>\\n'\n",
      " '    The Warmup-Stable-Decay (WSD) schedule allows continuing training from '\n",
      " 'the final model checkpoint of the stable phase without incurring a loss '\n",
      " 'penalty. This preserves a large fraction of the compute budget spent, as we '\n",
      " 'only have to discard what we spent on intermediate decay phases. But this is '\n",
      " 'not negligible at the\\n'\n",
      " '    <a '\n",
      " 'href=\"/blog/observability-in-llmops#h-scalability-drivers-in-llm-pretraining\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     scale of LLM pretraining\\n'\n",
      " '    </a>\\n'\n",
      " '    , where the costs regularly exceed tens of millions of US dollars.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    As\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2410.05192\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Wen and colleagues\\n'\n",
      " '    </a>\\n'\n",
      " '    found, starting from the final decay phase model checkpoint in a WSD '\n",
      " 'schedule does not cause the same loss penalty as the cosine schedule. As the '\n",
      " 'WSD schedule‚Äôs decay phase is rather short, they hypothesize it does not '\n",
      " 'have the same destructive effect as the cosine schedule‚Äôs long and slow '\n",
      " 'decay. Given a total compute budget, consecutively repeating the WSD cycle '\n",
      " 'is more efficient than restarting from the final checkpoint of the latest '\n",
      " 'stable phase.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    A cyclical WSD schedule is easier to implement than WSD restarts, as the '\n",
      " 'model evolves continuously down the loss landscape river valley, and no '\n",
      " 'prior checkpoints have to be reloaded. It also helps downstream users, who '\n",
      " 'initially often utilize\\n'\n",
      " '    <a href=\"/blog/zero-shot-and-few-shot-learning-with-llms\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     few-shot prompting\\n'\n",
      " '    </a>\\n'\n",
      " '    to adapt an LLM to their use case. If they later decide to fine-tune it, '\n",
      " 'and the LLM is trained with a WSD schedule, training the same model '\n",
      " 'checkpoint they already use for inference is efficient.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h3 class=\"wp-block-heading\" id=\"h-learning-behavior\">\\n'\n",
      " '    Learning behavior\\n'\n",
      " '   </h3>\\n'\n",
      " '   <p>\\n'\n",
      " '    In a neural network, the weights are the parameters of its neurons '\n",
      " 'learned during training. In an LLM, weights include the query, key, and '\n",
      " 'value matrices in the attention heads and the activation function parameters '\n",
      " 'in the feed-forward layers. While the learning rate governs the scale of '\n",
      " 'changes made to the model‚Äôs weights, we can also control how the weights '\n",
      " 'change on a more fine-grained level.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h4 class=\"wp-block-heading\">\\n'\n",
      " '    Weight decay\\n'\n",
      " '   </h4>\\n'\n",
      " '   <p>\\n'\n",
      " '    Employing\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/1810.12281\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     weight decay\\n'\n",
      " '    </a>\\n'\n",
      " '    during training penalizes large weights, preventing small parts of the '\n",
      " 'model from dominating its output. Weight decay in\\n'\n",
      " '    <a '\n",
      " 'href=\"/blog/deep-learning-optimization-algorithms#h-stochastic-gradient-descent-sgd\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     stochastic gradient descent\\n'\n",
      " '    </a>\\n'\n",
      " '    is implemented by adding a term to the loss function. For example, '\n",
      " 'using\\n'\n",
      " '    <a href=\"/blog/fighting-overfitting-with-l1-or-l2-regularization\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     L2 regularization\\n'\n",
      " '    </a>\\n'\n",
      " '    , the adapted loss function looks like this:\\n'\n",
      " '   </p>\\n'\n",
      " '   <section class=\"block-note c-box c-box--default c-box--dark '\n",
      " 'c-box--no-hover c-box--standard\" '\n",
      " 'id=\"note-block_eacfbf3ac44f82705985484dc03d272c\">\\n'\n",
      " '    <div class=\"block-note__content\">\\n'\n",
      " '     <div class=\"c-item c-item--wysiwyg_editor\">\\n'\n",
      " '      <div class=\"c-item__content\">\\n'\n",
      " '       <p>\\n'\n",
      " '        <span style=\"font-weight: 400;\">\\n'\n",
      " '         L = L\\n'\n",
      " '         <sub>\\n'\n",
      " '          orig\\n'\n",
      " '         </sub>\\n'\n",
      " '        </span>\\n'\n",
      " '        <span style=\"font-weight: 400;\">\\n'\n",
      " '         + Œª\\n'\n",
      " '        </span>\\n'\n",
      " '        <span style=\"font-weight: 400;\">\\n'\n",
      " '         Œ£\\n'\n",
      " '         <sub>\\n'\n",
      " '          i\\n'\n",
      " '         </sub>\\n'\n",
      " '        </span>\\n'\n",
      " '        <span style=\"font-weight: 400;\">\\n'\n",
      " '         w\\n'\n",
      " '         <sub>\\n'\n",
      " '          i\\n'\n",
      " '         </sub>\\n'\n",
      " '         <sup>\\n'\n",
      " '          2\\n'\n",
      " '         </sup>\\n'\n",
      " '        </span>\\n'\n",
      " '       </p>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </section>\\n'\n",
      " '   <p>\\n'\n",
      " '    Here,\\n'\n",
      " '    <em>\\n'\n",
      " '     L\\n'\n",
      " '    </em>\\n'\n",
      " '    <em>\\n'\n",
      " '     <sub>\\n'\n",
      " '      orig\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    is the original loss function,\\n'\n",
      " '    <em>\\n'\n",
      " '     Œª\\n'\n",
      " '    </em>\\n'\n",
      " '    is the weight decay factor, and\\n'\n",
      " '    <em>\\n'\n",
      " '     w\\n'\n",
      " '    </em>\\n'\n",
      " '    <em>\\n'\n",
      " '     <sub>\\n'\n",
      " '      i\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    are the model weights.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Weight decay has been applied to transformer-based NLP models since the '\n",
      " 'beginning. In the\\n'\n",
      " '    <a href=\"/blog/bert-and-the-transformer-architecture\" rel=\"noreferrer '\n",
      " 'noopener\" target=\"_blank\">\\n'\n",
      " '     seminal 2018 paper\\n'\n",
      " '    </a>\\n'\n",
      " '    <em>\\n'\n",
      " '     BERT: Pre-training of Deep Bidirectional Transformers for Language\\n'\n",
      " '    </em>\\n'\n",
      " '    <em>\\n'\n",
      " '     Understanding\\n'\n",
      " '    </em>\\n'\n",
      " '    , the authors state that they trained the model using ‚Äú\\n'\n",
      " '    <a '\n",
      " 'href=\"/blog/deep-learning-optimization-algorithms#h-adam-adaptive-moment-estimation\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     Adam\\n'\n",
      " '    </a>\\n'\n",
      " '    with [a] learning rate of 1e-4, Œ≤‚ÇÅ=0.9, Œ≤‚ÇÇ=0.999, L2 weight decay of '\n",
      " '0.01, learning rate warm up over the first 10,000 steps, and linear decay of '\n",
      " 'the learning rate.‚Äù\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    As Ilya Loshchilov and Frank Hutter point out in their 2019 paper\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/1711.05101\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     <em>\\n'\n",
      " '      Decoupled Weight Decay Regularization\\n'\n",
      " '     </em>\\n'\n",
      " '    </a>\\n'\n",
      " '    , in\\n'\n",
      " '    <a '\n",
      " 'href=\"/blog/deep-learning-optimization-algorithms#h-adam-adaptive-moment-estimation\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     adaptive optimizers like Adam\\n'\n",
      " '    </a>\\n'\n",
      " '    , L2 regularization and weight decay are not identical, and L2 '\n",
      " 'regularization is not effective. In Adam, the gradient of the regularization '\n",
      " 'term is scaled with the gradient of\\n'\n",
      " '    <em>\\n'\n",
      " '     L\\n'\n",
      " '     <sub>\\n'\n",
      " '      orig\\n'\n",
      " '     </sub>\\n'\n",
      " '     ,\\n'\n",
      " '    </em>\\n'\n",
      " '    which leads to minimal regularization for terms in\\n'\n",
      " '    <em>\\n'\n",
      " '     L\\n'\n",
      " '    </em>\\n'\n",
      " '    for which the gradient is large. They introduced the AdamW optimizer, '\n",
      " 'where the weight decay term is independent of the gradient-based update. '\n",
      " 'AdamW is widely used for LLMs, such as for training\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/1909.08053\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Megatron-LM\\n'\n",
      " '    </a>\\n'\n",
      " '    (2019),\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2302.13971\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Llama 1\\n'\n",
      " '    </a>\\n'\n",
      " '    (2023),\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2307.09288\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Llama 2\\n'\n",
      " '    </a>\\n'\n",
      " '    (2023), and\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2407.21783\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Llama 3\\n'\n",
      " '    </a>\\n'\n",
      " '    (2024).\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    In LLM pretraining, models often see each training sample only once. '\n",
      " 'Thus, overfitting to training data, which weight decay helps prevent in '\n",
      " 'traditional deep learning scenarios, is only of concern if there are many '\n",
      " 'similar or even identical samples in the training dataset. Still, weight '\n",
      " 'decay positively affects training speed and the final loss.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    According to a\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2310.04415\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     2023 analysis by Francesco D‚ÄôAngelo and colleagues at EPFL\\n'\n",
      " '    </a>\\n'\n",
      " '    , this is because weight decay increases the\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/1706.05350\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     effective learning rate\\n'\n",
      " '    </a>\\n'\n",
      " '    . The effective learning rate at training step\\n'\n",
      " '    <em>\\n'\n",
      " '     t\\n'\n",
      " '    </em>\\n'\n",
      " '    is defined as LR(\\n'\n",
      " '    <em>\\n'\n",
      " '     t\\n'\n",
      " '    </em>\\n'\n",
      " '    )/||w\\n'\n",
      " '    <sub>\\n'\n",
      " '     t\\n'\n",
      " '    </sub>\\n'\n",
      " '    ||\\n'\n",
      " '    <sub>\\n'\n",
      " '     2\\n'\n",
      " '    </sub>\\n'\n",
      " '    , the learning rate scaled by the inverse norm of the weight vector. The '\n",
      " 'smaller the weights, the larger the influence of a weight update. Further, '\n",
      " 'D‚ÄôAngelo and colleagues find that weight decay stabilizes training in\\n'\n",
      " '    <a '\n",
      " 'href=\"/blog/deep-learning-model-optimization-methods#h-quantization-reducing-the-memory-footprint-by-lowering-computational-precision\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     reduced floating-point precision\\n'\n",
      " '    </a>\\n'\n",
      " '    .\\n'\n",
      " '   </p>\\n'\n",
      " '   <a class=\"block-cta-box-related-link l-margin__top--standard '\n",
      " 'l-margin__bottom--standard\" '\n",
      " 'href=\"/blog/optimizing-gpu-usage-during-model-training-with-neptune\" '\n",
      " 'id=\"cta-box-related-link-block_0339aa3309637e36df73aed237ec2f74\" '\n",
      " 'rel=\"nofollow noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '    <div class=\"block-cta-box-related-link__description-wrapper '\n",
      " 'block-cta-box-related-link__description-wrapper--full\">\\n'\n",
      " '     <div class=\"c-eyebrow\">\\n'\n",
      " '      <img alt=\"\" class=\"c-eyebrow__icon\" decoding=\"async\" height=\"16\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-related--article.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '      <div class=\"c-eyebrow__text\">\\n'\n",
      " '       Related\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <h3 class=\"c-header\" '\n",
      " 'id=\"h-how-to-optimize-gpu-usage-during-model-training-with-neptune-ai\">\\n'\n",
      " '      How to Optimize GPU Usage During Model Training with neptune.ai\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '      <span class=\"c-button__text\">\\n'\n",
      " '       Read more\\n'\n",
      " '      </span>\\n'\n",
      " '      <img alt=\"\" class=\"c-button__arrow\" decoding=\"async\" height=\"12\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </a>\\n'\n",
      " '   <h4 class=\"wp-block-heading\">\\n'\n",
      " '    Gradient clipping\\n'\n",
      " '   </h4>\\n'\n",
      " '   <p>\\n'\n",
      " '    <a '\n",
      " 'href=\"/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     Gradient clipping\\n'\n",
      " '    </a>\\n'\n",
      " '    caps gradient magnitudes, helping maintain numerical stability. In the '\n",
      " 'river valley analogy, we impose a threshold on slope steepness when deciding '\n",
      " 'where to move next. Rather than jumping off a cliff, we treat it as a '\n",
      " 'moderately steep hillside.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    There are two common types of gradient clipping:\\n'\n",
      " '   </p>\\n'\n",
      " '   <ol class=\"wp-block-list\">\\n'\n",
      " '    <li>\\n'\n",
      " '     <strong>\\n'\n",
      " '      Clipping by value:\\n'\n",
      " '     </strong>\\n'\n",
      " '     Set predefined minimum and maximum values for gradient magnitudes. A '\n",
      " 'gradient component is clipped to the respective limit if it exceeds these '\n",
      " 'thresholds. This approach has the key benefit of not requiring access to the '\n",
      " 'entire gradient vector.\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     <strong>\\n'\n",
      " '      Clipping by norm:\\n'\n",
      " '     </strong>\\n'\n",
      " '     The entire gradient vector is scaled down if the norm exceeds a '\n",
      " 'specified threshold. For example, Nvidia‚Äôs original\\n'\n",
      " '     <a href=\"https://arxiv.org/abs/1909.08053\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '      <em>\\n'\n",
      " '       Megatron-LM: Training Multi-Billion Parameter Language Models Using '\n",
      " 'Model Parallelism\\n'\n",
      " '      </em>\\n'\n",
      " '     </a>\\n'\n",
      " '     paper first published in 2019 notes: ‚Äú[W]e use global gradient norm '\n",
      " 'clipping of 1.0 to improve the stability of training large models.‚Äù In '\n",
      " 'contrast to clipping by value, this preserves the gradient vector‚Äôs '\n",
      " 'direction but requires access to the entire gradient vector to compute.\\n'\n",
      " '    </li>\\n'\n",
      " '   </ol>\\n'\n",
      " '   <p>\\n'\n",
      " '    In 2022, Yang and Ma introduced the\\n'\n",
      " '    <a href=\"https://arxiv.org/abs/2210.10325\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Component-Wise Gradient Norm Clipping (CWGNC)\\n'\n",
      " '    </a>\\n'\n",
      " '    approach for fine-tuning LLMs. In a nutshell, CWGNC applies '\n",
      " 'gradient-clipping by norm separately to components in the LLM, such as the '\n",
      " 'key, query, and value matrices or feed-forward layers. This stabilizes the '\n",
      " 'training of each component individually, which might progress at '\n",
      " 'significantly different rates.\\n'\n",
      " '   </p>\\n'\n",
      " '   <a class=\"block-cta-box-related-link l-margin__top--standard '\n",
      " 'l-margin__bottom--standard\" '\n",
      " 'href=\"/blog/understanding-llms-requires-more-than-statistical-generalization\" '\n",
      " 'id=\"cta-box-related-link-block_14ba6829e706412bb17cf8ac80f95206\" '\n",
      " 'rel=\"nofollow noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '    <div class=\"block-cta-box-related-link__description-wrapper '\n",
      " 'block-cta-box-related-link__description-wrapper--full\">\\n'\n",
      " '     <div class=\"c-eyebrow\">\\n'\n",
      " '      <img alt=\"\" class=\"c-eyebrow__icon\" decoding=\"async\" height=\"16\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-related--article.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '      <div class=\"c-eyebrow__text\">\\n'\n",
      " '       Related\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <h3 class=\"c-header\" '\n",
      " 'id=\"h-position-understanding-llms-requires-more-than-statistical-generalization-paper-reflection\">\\n'\n",
      " '      Position: Understanding LLMs Requires More Than Statistical '\n",
      " 'Generalization [Paper Reflection]\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '      <span class=\"c-button__text\">\\n'\n",
      " '       Read more\\n'\n",
      " '      </span>\\n'\n",
      " '      <img alt=\"\" class=\"c-button__arrow\" decoding=\"async\" height=\"12\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </a>\\n'\n",
      " '   <h3 class=\"wp-block-heading\" id=\"h-next-token-generation\">\\n'\n",
      " '    Next-token generation\\n'\n",
      " '   </h3>\\n'\n",
      " '   <p>\\n'\n",
      " '    LLMs are autoregressive language models. They predict the next token by '\n",
      " 'taking the sequence of previously generated tokens as input and producing a '\n",
      " 'vector containing a probability for each token in the vocabulary. Different\\n'\n",
      " '    <a href=\"/blog/customizing-llm-output-post-processing-techniques\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     post-processing techniques\\n'\n",
      " '    </a>\\n'\n",
      " '    can be used to determine the next token from these probabilities.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h4 class=\"wp-block-heading\">\\n'\n",
      " '    Temperature\\n'\n",
      " '   </h4>\\n'\n",
      " '   <p>\\n'\n",
      " '    Typically, LLMs use a\\n'\n",
      " '    <a href=\"https://en.wikipedia.org/wiki/Softmax_function\" rel=\"noreferrer '\n",
      " 'noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     softmax function\\n'\n",
      " '    </a>\\n'\n",
      " '    as the final step in computing token probabilities. A temperature '\n",
      " 'parameter controls this function.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    The temperature influences the degree of randomness (or ‚Äúoriginality‚Äù or '\n",
      " '‚Äúcreativity‚Äù) in an LLM‚Äôs predicted text. At low temperatures, the model '\n",
      " 'becomes more deterministic, rarely considering less likely options and '\n",
      " 'instead focusing on the tokens with the highest probabilities. Conversely, a '\n",
      " 'high temperature increases unpredictability, allowing the model to choose '\n",
      " 'from a broader range of tokens. Thus, lower temperatures are helpful when '\n",
      " 'you need reliable answers, while higher temperatures lead to more varied and '\n",
      " 'surprising outputs.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    The\\n'\n",
      " '    <a href=\"https://huggingface.co/spaces/Nymbo/Text-Gen-Playground\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     Text Gen Playground\\n'\n",
      " '    </a>\\n'\n",
      " '    Hugging Face Space allows users to experiment with different temperature '\n",
      " 'settings and models. By inputting a prompt and adjusting the temperature '\n",
      " 'parameter, you can observe how the model‚Äôs output varies from predictable '\n",
      " 'and deterministic to creative and varied.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    For example, using the prompt ‚ÄúThe sun rises in the‚Äù at different '\n",
      " 'temperatures:\\n'\n",
      " '   </p>\\n'\n",
      " '   <ul class=\"wp-block-list\">\\n'\n",
      " '    <li>\\n'\n",
      " '     <strong>\\n'\n",
      " '      Low Temperature (e.g., T = 0.2)\\n'\n",
      " '     </strong>\\n'\n",
      " '     : The model will likely complete the sentence with ‚Äúeast,‚Äù reflecting a '\n",
      " 'common and expected continuation.\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     <strong>\\n'\n",
      " '      High Temperature (e.g., T = 1.2)\\n'\n",
      " '     </strong>\\n'\n",
      " '     : The model might generate more imaginative completions like ‚Äúmorning '\n",
      " 'haze‚Äù or ‚Äúgolden skies,‚Äù showcasing increased creativity.\\n'\n",
      " '    </li>\\n'\n",
      " '   </ul>\\n'\n",
      " '   <p>\\n'\n",
      " '    Adjusting the temperature parameter in such playgrounds provides '\n",
      " 'valuable insights into controlling the balance between determinism and '\n",
      " 'creativity in language model outputs.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h4 class=\"wp-block-heading\">\\n'\n",
      " '    Sampling strategy\\n'\n",
      " '   </h4>\\n'\n",
      " '   <p>\\n'\n",
      " '    Given the vector of probabilities, there are many ways to select the '\n",
      " 'next token.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    A straightforward strategy is always picking the most likely token. '\n",
      " 'Since the sampling process only considers the probabilities for the very '\n",
      " 'next token, this ‚Äúgreedy decoding‚Äù leads to highly probable multi-token '\n",
      " 'sequences being discarded if they start with a token that ‚Äì viewed in '\n",
      " 'isolation ‚Äì is less likely.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Using beam search or random sampling according to the token '\n",
      " 'probabilities can mitigate this. While the former produces deterministic '\n",
      " 'outputs and thus no variety, the latter can lead to the selection of highly '\n",
      " 'improbable tokens, producing nonsensical sequences.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    A more balanced approach is top-k sampling, which restricts sampling of '\n",
      " 'the next token to the\\n'\n",
      " '    <em>\\n'\n",
      " '     k\\n'\n",
      " '    </em>\\n'\n",
      " '    most probable tokens. Alternatively, in top-p sampling, only the most '\n",
      " 'likely tokens up to a cumulative probability of\\n'\n",
      " '    <em>\\n'\n",
      " '     p\\n'\n",
      " '    </em>\\n'\n",
      " '    are considered. This approach adapts dynamically to the probability '\n",
      " 'distribution, sampling from many tokens in uncertain scenarios and picking '\n",
      " 'from only a few when the model is more confident. (\\n'\n",
      " '    <em>\\n'\n",
      " '     p\\n'\n",
      " '    </em>\\n'\n",
      " '    and\\n'\n",
      " '    <em>\\n'\n",
      " '     k\\n'\n",
      " '    </em>\\n'\n",
      " '    can be adjusted during training or inference time.)\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    As ML Engineers, we can fine-tune temperature and sampling strategy '\n",
      " 'parameters according to your project needs. For example, if our tasks '\n",
      " 'require precision (e.g., technical writing or summarization), we‚Äôll use '\n",
      " 'lower temperatures and top-k sampling to prioritize high-probability tokens. '\n",
      " 'If we need more diversity, we‚Äôll begin with common default values '\n",
      " '(temperature 0.7, top-k:\\n'\n",
      " '    <em>\\n'\n",
      " '     k\\n'\n",
      " '    </em>\\n'\n",
      " '    = 40, top-p:\\n'\n",
      " '    <em>\\n'\n",
      " '     p\\n'\n",
      " '    </em>\\n'\n",
      " '    = 0.9). We‚Äôll iteratively adjust them based on the qualitative '\n",
      " 'evaluation of outputs and document our findings to build a shared knowledge '\n",
      " 'base with your team.\\n'\n",
      " '   </p>\\n'\n",
      " '   <a class=\"block-cta-box-related-link l-margin__top--standard '\n",
      " 'l-margin__bottom--standard\" '\n",
      " 'href=\"/customizing-llm-output-post-processing-techniques\" '\n",
      " 'id=\"cta-box-related-link-block_62ab80a696dc049be0edcc48e10cc4b1\" '\n",
      " 'rel=\"nofollow noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '    <div class=\"block-cta-box-related-link__description-wrapper '\n",
      " 'block-cta-box-related-link__description-wrapper--full\">\\n'\n",
      " '     <div class=\"c-eyebrow\">\\n'\n",
      " '      <img alt=\"\" class=\"c-eyebrow__icon\" decoding=\"async\" height=\"16\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-related--article.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '      <div class=\"c-eyebrow__text\">\\n'\n",
      " '       Related\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <h3 class=\"c-header\" '\n",
      " 'id=\"h-customizing-llm-output-post-processing-techniques\">\\n'\n",
      " '      Customizing LLM Output: Post-Processing Techniques\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '      <span class=\"c-button__text\">\\n'\n",
      " '       Read more\\n'\n",
      " '      </span>\\n'\n",
      " '      <img alt=\"\" class=\"c-button__arrow\" decoding=\"async\" height=\"12\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </a>\\n'\n",
      " '   <h2 class=\"wp-block-heading\" '\n",
      " 'id=\"h-how-do-we-find-the-optimal-hyperparameters\">\\n'\n",
      " '    How do we find the optimal hyperparameters?\\n'\n",
      " '   </h2>\\n'\n",
      " '   <p>\\n'\n",
      " '    LLM training involves many hyperparameters, resulting in a combinatorial '\n",
      " 'explosion of the search space. Simply guessing hyperparameters is unlikely '\n",
      " 'to yield good results. Further, hyperparameters interact in complex ways, so '\n",
      " 'the optimal value for one may depend on the values of others. Thus, '\n",
      " 'adjusting hyperparameters one at a time may lead to suboptimal solutions, as '\n",
      " 'we easily become trapped in local optima and don‚Äôt adequately explore the '\n",
      " 'hyperparameter space.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Finding an optimal combination of hyperparameters requires a systematic '\n",
      " 'approach. First, it‚Äôs paramount to understand the relevant hyperparameters '\n",
      " 'and their influence on the particular LLM. It‚Äôs essential to research how '\n",
      " 'similar architectures were trained or how the LLM we want to fine-tune was '\n",
      " 'pre-trained. Further, we should clarify the available time, our compute '\n",
      " 'budget, and the training objectives.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    Next, we can sketch a roadmap. Can we afford to conduct experiments with '\n",
      " 'particular hyperparameter combinations we believe are useful? Do we already '\n",
      " 'have an\\n'\n",
      " '    <a href=\"/blog/ml-experiment-tracking\" rel=\"noreferrer noopener\" '\n",
      " 'target=\"_blank\">\\n'\n",
      " '     experiment tracker\\n'\n",
      " '    </a>\\n'\n",
      " '    and\\n'\n",
      " '    <a href=\"/blog/optimizing-gpu-usage-during-model-training-with-neptune\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     resource monitoring\\n'\n",
      " '    </a>\\n'\n",
      " '    in place, or do we need to set it up first? What will be the decision '\n",
      " 'points and criteria that ensure we end up with a fully trained LLM at the '\n",
      " 'end of the project? Finally, we can start executing this roadmap and adjust '\n",
      " 'our plans as we gather more information and insight.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    The BLOOM team\\n'\n",
      " '    <a href=\"https://openreview.net/pdf?id=rI7BL3fHIZq\" rel=\"noreferrer '\n",
      " 'noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     published a detailed paper\\n'\n",
      " '    </a>\\n'\n",
      " '    on their preliminary experiments to determine the optimal model size and '\n",
      " 'architecture. They describe how they started with GPT-3‚Äôs hyperparameters '\n",
      " 'and conducted trial runs to estimate the optimal balance between model size '\n",
      " 'and number of tokens given their fixed compute budget. Similar experiments\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2407.21783\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     were run by the Meta team that trained Llama3\\n'\n",
      " '    </a>\\n'\n",
      " '    , who also aimed to predict downstream task performance.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h3 class=\"wp-block-heading\" '\n",
      " 'id=\"h-can-we-use-traditional-machine-learning-hyperparameter-optimization-methods-for-llms\">\\n'\n",
      " '    Can we use traditional machine learning hyperparameter optimization '\n",
      " 'methods for LLMs?\\n'\n",
      " '   </h3>\\n'\n",
      " '   <p>\\n'\n",
      " '    Methods for\\n'\n",
      " '    <a '\n",
      " 'href=\"/blog/improving-ml-model-performance#h-how-to-improve-ml-model-performance-using-hyperparameter-optimization\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     systematic hyperparameter optimization\\n'\n",
      " '    </a>\\n'\n",
      " '    have long been studied in machine learning:\\n'\n",
      " '   </p>\\n'\n",
      " '   <ul class=\"wp-block-list\">\\n'\n",
      " '    <li>\\n'\n",
      " '     <a href=\"/blog/deep-learning-visualization#h-training-dynamics-plots\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '      Learning curve analysis\\n'\n",
      " '     </a>\\n'\n",
      " '     involves training models with varying hyperparameters over several '\n",
      " 'epochs and plotting the loss to identify trends. In deep-learning models,\\n'\n",
      " '     <a '\n",
      " 'href=\"/blog/deep-learning-visualization#h-training-dynamics-plots#h-gradient-plots\" '\n",
      " 'rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '      plotting the gradient\\n'\n",
      " '     </a>\\n'\n",
      " '     can further help assess whether and how efficiently a model learns.\\n'\n",
      " '    </li>\\n'\n",
      " '   </ul>\\n'\n",
      " '   <ul class=\"wp-block-list\">\\n'\n",
      " '    <li>\\n'\n",
      " '     Grid search systematically steps through the hyperparameter space, '\n",
      " 'training a model for each possible combination. Random search samples the '\n",
      " 'hyperparameter space, training models for randomly selected combinations.\\n'\n",
      " '    </li>\\n'\n",
      " '   </ul>\\n'\n",
      " '   <p>\\n'\n",
      " '    While these approaches\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/2309.08859\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     have successfully been applied to optimize LLM hyperparameters\\n'\n",
      " '    </a>\\n'\n",
      " '    , their use is severely limited by the fact that LLMs are very expensive '\n",
      " 'to train. The computational and memory requirements make it unviable to '\n",
      " 'train large numbers of models. If training a model takes several months on a '\n",
      " 'large cluster, we‚Äôll only get one shot at a full training run.\\n'\n",
      " '   </p>\\n'\n",
      " '   <a class=\"block-cta-box-related-link l-margin__top--standard '\n",
      " 'l-margin__bottom--standard\" href=\"/blog/observability-in-llmops\" '\n",
      " 'id=\"cta-box-related-link-block_fc50577f02f2f02454dc820e8743770b\" '\n",
      " 'rel=\"nofollow noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '    <div class=\"block-cta-box-related-link__description-wrapper '\n",
      " 'block-cta-box-related-link__description-wrapper--full\">\\n'\n",
      " '     <div class=\"c-eyebrow\">\\n'\n",
      " '      <img alt=\"\" class=\"c-eyebrow__icon\" decoding=\"async\" height=\"16\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-related--article.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '      <div class=\"c-eyebrow__text\">\\n'\n",
      " '       Related\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <h3 class=\"c-header\" '\n",
      " 'id=\"h-observability-in-llmops-different-levels-of-scale\">\\n'\n",
      " '      Observability in LLMOps: Different Levels of Scale\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '      <span class=\"c-button__text\">\\n'\n",
      " '       Read more\\n'\n",
      " '      </span>\\n'\n",
      " '      <img alt=\"\" class=\"c-button__arrow\" decoding=\"async\" height=\"12\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </a>\\n'\n",
      " '   <h2 class=\"wp-block-heading\" '\n",
      " 'id=\"h-advanced-strategies-for-llm-hyperparameter-optimization\">\\n'\n",
      " '    Advanced strategies for LLM hyperparameter optimization\\n'\n",
      " '   </h2>\\n'\n",
      " '   <p>\\n'\n",
      " '    Beyond starting from a well-known hyperparameter combination and '\n",
      " 'systematically conducting experiments, there is a range of approaches for '\n",
      " 'automatically identifying or optimizing LLM hyperparameters in specific '\n",
      " 'circumstances.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h3 class=\"wp-block-heading\" id=\"h-population-based-training-pbt\">\\n'\n",
      " '    Population-based training (PBT)\\n'\n",
      " '   </h3>\\n'\n",
      " '   <p>\\n'\n",
      " '    <a '\n",
      " 'href=\"https://deepmind.google/discover/blog/population-based-training-of-neural-networks/\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     Population-Based Training (PBT)\\n'\n",
      " '    </a>\\n'\n",
      " '    is an approach pioneered by\\n'\n",
      " '    <a href=\"https://deepmind.google/\" rel=\"noreferrer noopener nofollow\" '\n",
      " 'target=\"_blank\">\\n'\n",
      " '     Google DeepMind\\n'\n",
      " '    </a>\\n'\n",
      " '    that combines the concepts of evolutionary search and online training. '\n",
      " 'Instead of fixing hyperparameters at the start of training and leaving them '\n",
      " 'static throughout the process, PBT adapts them dynamically, informed by the '\n",
      " 'models‚Äô performance.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    In a nutshell, the population-based training process consists of the '\n",
      " 'following steps:\\n'\n",
      " '   </p>\\n'\n",
      " '   <ol class=\"wp-block-list\">\\n'\n",
      " '    <li>\\n'\n",
      " '     Set up a population of models, each with unique hyperparameters hi and '\n",
      " 'weights i.\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     Train each model, updating i every iteration.\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     After a fixed number of iterations, evaluate each model‚Äôs performance '\n",
      " 'on a validation dataset.\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     Identify models that are underperforming relative to others. Replace '\n",
      " 'their current weights\\u200b and hyperparameters with those of a '\n",
      " 'better-performing model (exploitation).\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     Slightly perturb the hyperparameters of previously underperforming '\n",
      " 'models to prevent the population from converging to a single configuration '\n",
      " 'too early and improve diversity (exploration).\\n'\n",
      " '    </li>\\n'\n",
      " '    <li>\\n'\n",
      " '     Conclude the training if the compute budget is exhausted or the '\n",
      " 'objective has been met. Otherwise, repeat the process starting from step 2.\\n'\n",
      " '    </li>\\n'\n",
      " '   </ol>\\n'\n",
      " '   <p>\\n'\n",
      " '    This process initially appears resource-intensive since it requires '\n",
      " 'maintaining and updating multiple models simultaneously, which can increase '\n",
      " 'total GPU hours. However, PBT‚Äôs dynamic refinement of hyperparameters during '\n",
      " 'training can significantly save wall-clock time. By avoiding restarting from '\n",
      " 'scratch for each hyperparameter configuration and leveraging partially '\n",
      " 'trained models, PBT reduces the number of training epochs needed to achieve '\n",
      " 'optimal performance.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    The\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/1711.09846\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     2017 DeepMind study on Population-Based Training (PBT)\\n'\n",
      " '    </a>\\n'\n",
      " '    showcased its potential for LLMs by fine-tuning the f\\n'\n",
      " '    <a href=\"https://arxiv.org/pdf/1706.03762\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     irst transformer model\\n'\n",
      " '    </a>\\n'\n",
      " '    on the\\n'\n",
      " '    <a '\n",
      " 'href=\"https://paperswithcode.com/sota/machine-translation-on-wmt2014-english-german\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     WMT 2014 English-German machine translation benchmark\\n'\n",
      " '    </a>\\n'\n",
      " '    . They manually optimized a baseline model and compared it to a model '\n",
      " 'where they used PBT to optimize the dropouts for different layers and the '\n",
      " 'learning rate. Their evaluation showed that the PBT-optimized model '\n",
      " 'outperformed their hand-tuned baseline. Further, they discovered that the '\n",
      " 'learning rate schedule generated through PBT mimicked the human-created one. '\n",
      " 'Starting with a small learning rate, it then jumped to a high value before '\n",
      " 'something resembling an exponential decay‚Äù brought it down to a low value '\n",
      " 'again. DeepMind‚Äôs original PBT transformer model also learned noticeably '\n",
      " 'faster.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    <a href=\"https://docs.ray.io/en/latest/tune/index.html\" rel=\"noreferrer '\n",
      " 'noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     Ray Tune\\n'\n",
      " '    </a>\\n'\n",
      " '    is a hyperparameter tuning library that\\n'\n",
      " '    <a href=\"https://docs.ray.io/en/latest/tune/examples/pbt_guide.html\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     supports population-based training\\n'\n",
      " '    </a>\\n'\n",
      " '    . It is part of the open-source\\n'\n",
      " '    <a href=\"https://docs.ray.io/en/latest/index.html\" rel=\"noreferrer '\n",
      " 'noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     Ray framework for scaling machine-learning applications\\n'\n",
      " '    </a>\\n'\n",
      " '    . The Ray Tune documentation includes an example of\\n'\n",
      " '    <a '\n",
      " 'href=\"https://docs.ray.io/en/latest/tune/examples/pbt_transformers.html\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     tuning BERT and RoBERTa on the GLUE benchmark dataset\\n'\n",
      " '    </a>\\n'\n",
      " '    using population-based training.\\n'\n",
      " '   </p>\\n'\n",
      " '   <h3 class=\"wp-block-heading\" id=\"h-bayesian-optimization\">\\n'\n",
      " '    Bayesian optimization\\n'\n",
      " '   </h3>\\n'\n",
      " '   <p>\\n'\n",
      " '    Bayesian optimization is a popular method for efficiently navigating the '\n",
      " 'hyperparameter space by building a probabilistic model (surrogate model) of '\n",
      " 'the influence of the hyperparameters on the objective (e.g., validation '\n",
      " 'loss). The surrogate model is used to predict promising hyperparameter '\n",
      " 'combinations to try next. The results of this exploration are then used to '\n",
      " 'refine the surrogate model.\\n'\n",
      " '    <br/>\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    The 2024 paper\\n'\n",
      " '    <a href=\"https://arxiv.org/abs/2407.13906\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     <em>\\n'\n",
      " '      Crafting Efficient Fine-Tuning Strategies for Large Language Models\\n'\n",
      " '     </em>\\n'\n",
      " '    </a>\\n'\n",
      " '    investigates the applicability of Bayesian optimization to fine-tuning '\n",
      " 'LLMs. First, a population of\\n'\n",
      " '    <em>\\n'\n",
      " '     N\\n'\n",
      " '    </em>\\n'\n",
      " '    models is trained for a pre-defined budget\\n'\n",
      " '    <em>\\n'\n",
      " '     t\\n'\n",
      " '     <sub>\\n'\n",
      " '      1\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    . As each model is trained, the surrogate model is updated, and the '\n",
      " 'updated version is used to set the hyperparameters of the next model. Once '\n",
      " 'all\\n'\n",
      " '    <em>\\n'\n",
      " '     N\\n'\n",
      " '    </em>\\n'\n",
      " '    models are trained, the top\\n'\n",
      " '    <em>\\n'\n",
      " '     k\\n'\n",
      " '    </em>\\n'\n",
      " '    models are selected and are trained up to\\n'\n",
      " '    <em>\\n'\n",
      " '     t\\n'\n",
      " '     <sub>\\n'\n",
      " '      2\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    . Finally, the best model among the\\n'\n",
      " '    <em>\\n'\n",
      " '     k\\n'\n",
      " '    </em>\\n'\n",
      " '    fully trained models is selected.\\n'\n",
      " '   </p>\\n'\n",
      " '   <a class=\"block-cta-box-related-link l-margin__top--standard '\n",
      " 'l-margin__bottom--standard\" '\n",
      " 'href=\"/blog/how-to-optimize-hyperparameter-search\" '\n",
      " 'id=\"cta-box-related-link-block_cda6fadba8cf63e0df1b049b40cb477a\" '\n",
      " 'rel=\"nofollow noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '    <div class=\"block-cta-box-related-link__description-wrapper '\n",
      " 'block-cta-box-related-link__description-wrapper--full\">\\n'\n",
      " '     <div class=\"c-eyebrow\">\\n'\n",
      " '      <img alt=\"\" class=\"c-eyebrow__icon\" decoding=\"async\" height=\"16\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-related--article.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '      <div class=\"c-eyebrow__text\">\\n'\n",
      " '       Related\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <h3 class=\"c-header\" '\n",
      " 'id=\"h-how-to-optimize-hyperparameter-search-using-bayesian-optimization-and-optuna\">\\n'\n",
      " '      How to Optimize Hyperparameter Search Using Bayesian Optimization and '\n",
      " 'Optuna\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '      <span class=\"c-button__text\">\\n'\n",
      " '       Read more\\n'\n",
      " '      </span>\\n'\n",
      " '      <img alt=\"\" class=\"c-button__arrow\" decoding=\"async\" height=\"12\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </a>\\n'\n",
      " '   <h3 class=\"wp-block-heading\" id=\"h-adaptive-low-rank-adaptation-lora\">\\n'\n",
      " '    Adaptive Low-Rank Adaptation (LoRA)\\n'\n",
      " '   </h3>\\n'\n",
      " '   <p>\\n'\n",
      " '    <a href=\"https://arxiv.org/abs/2106.09685\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     Low-Rank Adaptation\\n'\n",
      " '    </a>\\n'\n",
      " '    (LoRA) is a popular technique for reducing the memory footprint and '\n",
      " 'computational demands when fine-tuning LLMs. In brief, the idea is to '\n",
      " 'represent the weights of the fine-tuned model as\\n'\n",
      " '   </p>\\n'\n",
      " '   <section class=\"block-note c-box c-box--default c-box--dark '\n",
      " 'c-box--no-hover c-box--standard\" '\n",
      " 'id=\"note-block_384c574f5c169e8d628e4c7efeb5d773\">\\n'\n",
      " '    <div class=\"block-note__content\">\\n'\n",
      " '     <div class=\"c-item c-item--wysiwyg_editor\">\\n'\n",
      " '      <div class=\"c-item__content\">\\n'\n",
      " '       <p>\\n'\n",
      " '        W\\n'\n",
      " '        <sub>\\n'\n",
      " '         fine\\n'\n",
      " '        </sub>\\n'\n",
      " '        = W\\n'\n",
      " '        <sub>\\n'\n",
      " '         pre\\n'\n",
      " '        </sub>\\n'\n",
      " '        + ‚àÜW =\\xa0 W\\n'\n",
      " '        <sub>\\n'\n",
      " '         pre\\n'\n",
      " '        </sub>\\n'\n",
      " '        + BA\\n'\n",
      " '       </p>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </section>\\n'\n",
      " '   <p>\\n'\n",
      " '    Here, the fine-tuned weights\\n'\n",
      " '    <em>\\n'\n",
      " '     W\\n'\n",
      " '    </em>\\n'\n",
      " '    <em>\\n'\n",
      " '     <sub>\\n'\n",
      " '      fine\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    are the sum of the original weights\\n'\n",
      " '    <em>\\n'\n",
      " '     W\\n'\n",
      " '    </em>\\n'\n",
      " '    <em>\\n'\n",
      " '     <sub>\\n'\n",
      " '      pre\\n'\n",
      " '     </sub>\\n'\n",
      " '    </em>\\n'\n",
      " '    and a difference\\n'\n",
      " '    <em>\\n'\n",
      " '     ‚àÜW\\n'\n",
      " '    </em>\\n'\n",
      " '    , which is the product of two matrices,\\n'\n",
      " '    <em>\\n'\n",
      " '     B\\n'\n",
      " '    </em>\\n'\n",
      " '    and\\n'\n",
      " '    <em>\\n'\n",
      " '     A\\n'\n",
      " '    </em>\\n'\n",
      " '    . Only\\n'\n",
      " '    <em>\\n'\n",
      " '     B\\n'\n",
      " '    </em>\\n'\n",
      " '    and\\n'\n",
      " '    <em>\\n'\n",
      " '     A\\n'\n",
      " '    </em>\\n'\n",
      " '    are updated during fine-tuning, while W\\n'\n",
      " '    <sub>\\n'\n",
      " '     pre\\n'\n",
      " '    </sub>\\n'\n",
      " '    remains unchanged. If W\\n'\n",
      " '    <sub>\\n'\n",
      " '     pre\\n'\n",
      " '    </sub>\\n'\n",
      " '    and ‚àÜW have dimensions\\n'\n",
      " '    <em>\\n'\n",
      " '     m\\n'\n",
      " '    </em>\\n'\n",
      " '    x\\n'\n",
      " '    <em>\\n'\n",
      " '     n\\n'\n",
      " '    </em>\\n'\n",
      " '    ,\\n'\n",
      " '    <em>\\n'\n",
      " '     B\\n'\n",
      " '    </em>\\n'\n",
      " '    and\\n'\n",
      " '    <em>\\n'\n",
      " '     A\\n'\n",
      " '    </em>\\n'\n",
      " '    have dimensions\\n'\n",
      " '    <em>\\n'\n",
      " '     m\\n'\n",
      " '    </em>\\n'\n",
      " '    x\\n'\n",
      " '    <em>\\n'\n",
      " '     r\\n'\n",
      " '    </em>\\n'\n",
      " '    and\\n'\n",
      " '    <em>\\n'\n",
      " '     r\\n'\n",
      " '    </em>\\n'\n",
      " '    x\\n'\n",
      " '    <em>\\n'\n",
      " '     n\\n'\n",
      " '    </em>\\n'\n",
      " '    , respectively. If the rank\\n'\n",
      " '    <em>\\n'\n",
      " '     r\\n'\n",
      " '    </em>\\n'\n",
      " '    is much smaller than\\n'\n",
      " '    <em>\\n'\n",
      " '     m\\n'\n",
      " '    </em>\\n'\n",
      " '    and\\n'\n",
      " '    <em>\\n'\n",
      " '     n\\n'\n",
      " '    </em>\\n'\n",
      " '    , the number of weights to be updated is greatly reduced, leading to '\n",
      " 'faster training progress while requiring less memory.\\n'\n",
      " '   </p>\\n'\n",
      " '   <a class=\"block-cta-box-related-link l-margin__top--standard '\n",
      " 'l-margin__bottom--standard\" '\n",
      " 'href=\"/blog/llm-fine-tuning-and-model-selection-with-neptune-transformers\" '\n",
      " 'id=\"cta-box-related-link-block_2118978f3c5722ba9c5fb9cba9e7efa4\" '\n",
      " 'rel=\"nofollow noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '    <div class=\"block-cta-box-related-link__description-wrapper '\n",
      " 'block-cta-box-related-link__description-wrapper--full\">\\n'\n",
      " '     <div class=\"c-eyebrow\">\\n'\n",
      " '      <img alt=\"\" class=\"c-eyebrow__icon\" decoding=\"async\" height=\"16\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-related--article.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '      <div class=\"c-eyebrow__text\">\\n'\n",
      " '       Related\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <h3 class=\"c-header\" '\n",
      " 'id=\"h-llm-fine-tuning-and-model-selection-using-neptune-and-transformers\">\\n'\n",
      " '      LLM Fine-Tuning and Model Selection Using Neptune and Transformers\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '      <span class=\"c-button__text\">\\n'\n",
      " '       Read more\\n'\n",
      " '      </span>\\n'\n",
      " '      <img alt=\"\" class=\"c-button__arrow\" decoding=\"async\" height=\"12\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </a>\\n'\n",
      " '   <p>\\n'\n",
      " '    In practice, it is often unclear to which LLM components LoRA should be '\n",
      " 'applied for the best outcome. While we know that not all weights influence '\n",
      " 'task performance equally, identifying which components are important for a '\n",
      " 'particular objective would require extensive ablation studies. Thus, LoRA is '\n",
      " 'often applied across all suitable weight matrices in a model.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    <a href=\"https://arxiv.org/abs/2303.10512\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     AdaLoRA\\n'\n",
      " '    </a>\\n'\n",
      " '    (Adaptive Low-Rank Adaptation) is a method to allocate a given parameter '\n",
      " 'budget across weight matrices. The core idea is to apply LoRA to all LLM '\n",
      " 'components but to use different values for the rank\\n'\n",
      " '    <em>\\n'\n",
      " '     r\\n'\n",
      " '    </em>\\n'\n",
      " '    . Important components use a matrix pair with a large\\n'\n",
      " '    <em>\\n'\n",
      " '     r\\n'\n",
      " '    </em>\\n'\n",
      " '    , leading to a\\n'\n",
      " '    <em>\\n'\n",
      " '     ‚àÜW\\n'\n",
      " '    </em>\\n'\n",
      " '    with many weights. Less important components are approximated using a '\n",
      " 'lower-rank matrix pair. AdaLoRA assigns an importance score to each '\n",
      " 'component and sets the values for\\n'\n",
      " '    <em>\\n'\n",
      " '     r\\n'\n",
      " '    </em>\\n'\n",
      " '    such that the total number of weights remains within the user-defined '\n",
      " 'budget. This leads to an optimal training outcome for a fixed compute and '\n",
      " 'memory budget.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    <a href=\"https://arxiv.org/abs/2405.00361\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '     AdaMoLE\\n'\n",
      " '    </a>\\n'\n",
      " '    (Adaptive Mixture of Low-Rank Adaptation Experts) similarly aims to '\n",
      " 'reduce the number of weights that need to be updated. It replaces the single '\n",
      " 'low-rank matrix pair of the original LoRA with a collection of multiple '\n",
      " 'matrix pairs (LoRA experts) that are activated dynamically based on the '\n",
      " 'input context. This enables the LLM to learn different tasks with a minimal '\n",
      " 'total number of weights.\\n'\n",
      " '   </p>\\n'\n",
      " '   <div class=\"wp-block-image\">\\n'\n",
      " '    <figure class=\"aligncenter size-full\">\\n'\n",
      " '     <img alt=\"Fine-tuning an LLM with the Adaptive Mixture of Low-Rank '\n",
      " 'Adaptation Experts approach. The fine-tuned weights are approximated as the '\n",
      " 'sum of the frozen pre-trained weights and a number of so-called LoRA experts '\n",
      " 'that are activated by a gating function and a threshold function. Different '\n",
      " 'LoRA experts specialize in different contexts, allowing the LLM to learn '\n",
      " 'different tasks with a minimal number of weights.\" class=\"wp-image-43637\" '\n",
      " 'data-recalc-dims=\"1\" decoding=\"async\" height=\"1350\" loading=\"lazy\" '\n",
      " 'sizes=\"auto, (max-width: 1000px) 100vw, 1000px\" '\n",
      " 'src=\"https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=1350%2C1350&amp;ssl=1\" '\n",
      " 'srcset=\"https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?w=1350&amp;ssl=1 '\n",
      " '1350w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=768%2C768&amp;ssl=1 '\n",
      " '768w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=200%2C200&amp;ssl=1 '\n",
      " '200w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=220%2C220&amp;ssl=1 '\n",
      " '220w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=120%2C120&amp;ssl=1 '\n",
      " '120w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=88%2C88&amp;ssl=1 '\n",
      " '88w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=44%2C44&amp;ssl=1 '\n",
      " '44w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=160%2C160&amp;ssl=1 '\n",
      " '160w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=300%2C300&amp;ssl=1 '\n",
      " '300w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=480%2C480&amp;ssl=1 '\n",
      " '480w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=1020%2C1020&amp;ssl=1 '\n",
      " '1020w, '\n",
      " 'https://i0.wp.com/neptune.ai/wp-content/uploads/2025/01/Hyperparameter-Optimization-For-LLMs-Advanced-Strategies.png?resize=100%2C100&amp;ssl=1 '\n",
      " '100w\" width=\"1350\"/>\\n'\n",
      " '     <figcaption class=\"wp-element-caption\">\\n'\n",
      " '      Fine-tuning an LLM with the Adaptive Mixture of Low-Rank Adaptation '\n",
      " 'Experts approach. The fine-tuned weights are approximated as the sum of the '\n",
      " 'frozen pre-trained weights and a number of so-called LoRA experts that are '\n",
      " 'activated by a gating function and a threshold function. Different LoRA '\n",
      " 'experts specialize in different contexts, allowing the LLM to learn '\n",
      " 'different tasks with a minimal number of weights. | Modified based on:\\n'\n",
      " '      <a href=\"https://arxiv.org/pdf/2405.00361\" rel=\"noreferrer noopener '\n",
      " 'nofollow\" target=\"_blank\">\\n'\n",
      " '       source\\n'\n",
      " '      </a>\\n'\n",
      " '     </figcaption>\\n'\n",
      " '    </figure>\\n'\n",
      " '   </div>\\n'\n",
      " '   <a class=\"block-cta-box-related-link l-margin__top--standard '\n",
      " 'l-margin__bottom--standard\" href=\"/blog/mixture-of-experts-llms\" '\n",
      " 'id=\"cta-box-related-link-block_8ded872e5dd4e7b6bbe71a5ac1db631a\" '\n",
      " 'rel=\"nofollow noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '    <div class=\"block-cta-box-related-link__description-wrapper '\n",
      " 'block-cta-box-related-link__description-wrapper--full\">\\n'\n",
      " '     <div class=\"c-eyebrow\">\\n'\n",
      " '      <img alt=\"\" class=\"c-eyebrow__icon\" decoding=\"async\" height=\"16\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-related--article.svg\" '\n",
      " 'width=\"16\"/>\\n'\n",
      " '      <div class=\"c-eyebrow__text\">\\n'\n",
      " '       Related\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '     <h3 class=\"c-header\" '\n",
      " 'id=\"h-mixture-of-experts-llms-key-concepts-explained\">\\n'\n",
      " '      Mixture of Experts LLMs: Key Concepts Explained\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '      <span class=\"c-button__text\">\\n'\n",
      " '       Read more\\n'\n",
      " '      </span>\\n'\n",
      " '      <img alt=\"\" class=\"c-button__arrow\" decoding=\"async\" height=\"12\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"12\"/>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </a>\\n'\n",
      " '   <h2 class=\"wp-block-heading\" '\n",
      " 'id=\"h-hands-on-llm-hyperparameter-optimization-with-neptune-ai\">\\n'\n",
      " '    Hands-on: LLM hyperparameter optimization with neptune.ai\\n'\n",
      " '   </h2>\\n'\n",
      " '   <p>\\n'\n",
      " '    <a href=\"https://optuna.org/\" rel=\"noreferrer noopener nofollow\" '\n",
      " 'target=\"_blank\">\\n'\n",
      " '     Optuna\\n'\n",
      " '    </a>\\n'\n",
      " '    is a framework for\\n'\n",
      " '    <a href=\"/blog/how-to-optimize-hyperparameter-search\" rel=\"noreferrer '\n",
      " 'noopener\" target=\"_blank\">\\n'\n",
      " '     optimizing hyperparameter search using Bayesian optimization\\n'\n",
      " '    </a>\\n'\n",
      " '    . It can be applied to various machine-learning tasks, including LLM '\n",
      " 'hyperparameter tuning.\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    To see this in action, we‚Äôve prepared\\n'\n",
      " '    <a '\n",
      " 'href=\"https://colab.research.google.com/drive/1QXTpW6bwJAv7GtJasBACD1TbBGe4zDWM?usp=sharing\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     a Colab notebook\\n'\n",
      " '    </a>\\n'\n",
      " '    that walks you through the process of finding the optimal combination of '\n",
      " 'learning rate, batch size, and number of epochs for fine-tuning a\\n'\n",
      " '    <a href=\"https://huggingface.co/docs/transformers/index\" rel=\"noreferrer '\n",
      " 'noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     Hugging Face Transformers\\n'\n",
      " '    </a>\\n'\n",
      " '    model on the\\n'\n",
      " '    <a href=\"https://huggingface.co/datasets/stanfordnlp/imdb\">\\n'\n",
      " '     IMBD dataset\\n'\n",
      " '    </a>\\n'\n",
      " '    .\\n'\n",
      " '   </p>\\n'\n",
      " '   <p>\\n'\n",
      " '    The tutorial uses\\n'\n",
      " '    <a href=\"/\" rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '     neptune.ai\\n'\n",
      " '    </a>\\n'\n",
      " '    to track training progress and analyze the different hyperparameters. If '\n",
      " 'you don‚Äôt want to go through the tutorial yourself right now, you can still '\n",
      " 'explore example results in\\n'\n",
      " '    <a '\n",
      " 'href=\"https://app.neptune.ai/community/hyperparameter-optimization-for-LLMs\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '     this public Neptune project\\n'\n",
      " '    </a>\\n'\n",
      " '    .\\n'\n",
      " '   </p>\\n'\n",
      " '   <section class=\"block-i-box l-margin__top--large l-margin__bottom--large\" '\n",
      " 'id=\"i-box-block_4cdcaad82413dc3b7c8ebd4896ccdf06\">\\n'\n",
      " '    <div class=\"block-i-box__inner\">\\n'\n",
      " '     <div class=\"block-custom-text white l-padding__top--0 '\n",
      " 'l-padding__bottom--small\" '\n",
      " 'id=\"custom-text-block_aff987e3d6a3bb3185bf64bf5d851c46\" style=\"max-width: '\n",
      " '100%; font-size: 1rem; line-height: 1.33; font-weight: 600;\">\\n'\n",
      " '      How about being one of the first to access Neptune Scale?\\n'\n",
      " '     </div>\\n'\n",
      " '     <p>\\n'\n",
      " '      Neptune Scale is our upcoming product release built for teams that '\n",
      " 'train foundation models. It offers enhanced scalability and exciting new '\n",
      " 'features. You can join our beta program to benefit from Neptune Scale '\n",
      " 'earlier.\\n'\n",
      " '     </p>\\n'\n",
      " '     <ul class=\"block-arrow-list block-list-item--font-size-regular\" '\n",
      " 'id=\"arrow-list-block_b1349a90904fb1435825c696dfc4ea48\">\\n'\n",
      " '      <li class=\"block-list-item\">\\n'\n",
      " '       <img alt=\"\" class=\"block-list-item__arrow lazyload\" '\n",
      " 'data-src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/list-item/arrow.svg\" '\n",
      " 'decoding=\"async\" height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '       <p>\\n'\n",
      " '        <a href=\"https://docs-beta.neptune.ai/\" rel=\"noreferrer noopener\" '\n",
      " 'target=\"_blank\">\\n'\n",
      " '         See the docs\\n'\n",
      " '        </a>\\n'\n",
      " '        or watch a short\\n'\n",
      " '        <a href=\"/walkthrough\" rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '         product demo (2 min)\\n'\n",
      " '        </a>\\n'\n",
      " '       </p>\\n'\n",
      " '      </li>\\n'\n",
      " '      <li class=\"block-list-item\">\\n'\n",
      " '       <img alt=\"\" class=\"block-list-item__arrow lazyload\" '\n",
      " 'data-src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/list-item/arrow.svg\" '\n",
      " 'decoding=\"async\" height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '       <p>\\n'\n",
      " '        Play with a\\n'\n",
      " '        <a '\n",
      " 'href=\"https://scale.neptune.ai/o/neptune/org/LLM-training-example/runs/compare?viewId=9d0e032a-5a78-4a0e-81d1-98e0a7c81a8f&amp;detailsTab=metadata&amp;dash=charts&amp;type=run&amp;experimentOnly=true&amp;compare=u0MsW4a1PJIUJ75nglpjHa9XUKFfAmcBRbLhNatCHX20\" '\n",
      " 'rel=\"noreferrer noopener nofollow\" target=\"_blank\">\\n'\n",
      " '         live Neptune Scale project\\n'\n",
      " '        </a>\\n'\n",
      " '       </p>\\n'\n",
      " '      </li>\\n'\n",
      " '      <li class=\"block-list-item\">\\n'\n",
      " '       <img alt=\"\" class=\"block-list-item__arrow lazyload\" '\n",
      " 'data-src=\"https://neptune.ai/wp-content/themes/neptune/img/blocks/list-item/arrow.svg\" '\n",
      " 'decoding=\"async\" height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '       <p>\\n'\n",
      " '        Request your\\n'\n",
      " '        <a href=\"/early-access\" rel=\"noreferrer noopener\" target=\"_blank\">\\n'\n",
      " '         early access\\n'\n",
      " '        </a>\\n'\n",
      " '       </p>\\n'\n",
      " '      </li>\\n'\n",
      " '     </ul>\\n'\n",
      " '    </div>\\n'\n",
      " '   </section>\\n'\n",
      " '   <h2 class=\"wp-block-heading\" '\n",
      " 'id=\"h-whats-next-in-llm-hyperparameter-optimization\">\\n'\n",
      " '    What‚Äôs next in LLM hyperparameter optimization?\\n'\n",
      " '   </h2>\\n'\n",
      " '   <p>\\n'\n",
      " '    Finding an optimal combination of hyperparameters is essential for '\n",
      " 'training LLMs. In this article, we‚Äôve reviewed key LLM hyperparameters and '\n",
      " 'their influence on the model and training performance. We‚Äôve also discussed '\n",
      " 'how to approach hyperparameter optimization systematically and explored '\n",
      " 'methods to assist or even automate this task in certain scenarios.\\n'\n",
      " '    <br/>\\n'\n",
      " '    <br/>\\n'\n",
      " '    From the examples of hyperparameter choices for state-of-the-art LLMs, '\n",
      " 'we‚Äôve seen that while architectures, training tasks, and data change, most '\n",
      " 'models are trained with relatively similar learning rate schedules and '\n",
      " 'optimizer configurations. As our understanding of the model and training '\n",
      " 'mechanics deepens and more experiments yield empirical evidence, we‚Äôll '\n",
      " 'likely see an evolution of the standard recipes and more diversity.\\n'\n",
      " '   </p>\\n'\n",
      " '   <div class=\"c-article-rating\" data-post-id=\"43609\">\\n'\n",
      " '    <h2 class=\"c-article-rating__header\">\\n'\n",
      " '     Was the article useful?\\n'\n",
      " '    </h2>\\n'\n",
      " '    <div class=\"c-article-rating__buttons\">\\n'\n",
      " '     <button class=\"js-c-button js-c-button--yes c-button c-button--yes\" '\n",
      " 'data-status=\"default\" data-value=\"yes\">\\n'\n",
      " '      <img alt=\"yes\" class=\"c-button__icon\" decoding=\"async\" height=\"32\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-article-rating--yes.svg\" '\n",
      " 'width=\"32\"/>\\n'\n",
      " '      <span class=\"c-button__label\">\\n'\n",
      " '       Yes\\n'\n",
      " '      </span>\\n'\n",
      " '     </button>\\n'\n",
      " '     <button class=\"js-c-button js-c-button--no c-button c-button--no\" '\n",
      " 'data-status=\"default\" data-value=\"no\">\\n'\n",
      " '      <img alt=\"no\" class=\"c-button__icon\" decoding=\"async\" height=\"32\" '\n",
      " 'loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-article-rating--no.svg\" '\n",
      " 'width=\"32\"/>\\n'\n",
      " '      <span class=\"c-button__label\">\\n'\n",
      " '       No\\n'\n",
      " '      </span>\\n'\n",
      " '     </button>\\n'\n",
      " '    </div>\\n'\n",
      " '    <div class=\"c-article-feedback-form\">\\n'\n",
      " '     <button class=\"js-c-article-feedback-form__form-button '\n",
      " 'c-article-feedback-form__form-button\" data-status=\"inactive\">\\n'\n",
      " '      <img alt=\"\" class=\"c-item__icon\" height=\"20\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-bulb.svg\" '\n",
      " 'width=\"20\"/>\\n'\n",
      " '      <span class=\"c-item__label\">\\n'\n",
      " '       Suggest changes\\n'\n",
      " '      </span>\\n'\n",
      " '     </button>\\n'\n",
      " '     <div class=\"js-c-article-feedback-form__form-wrapper '\n",
      " 'c-article-feedback-form__form-wrapper\" data-status=\"inactive\" '\n",
      " 'style=\"max-height: 0;\">\\n'\n",
      " '      <div class=\"wpcf7 no-js\" data-wpcf7-id=\"36762\" dir=\"ltr\" '\n",
      " 'id=\"wpcf7-f36762-p43609-o1\" lang=\"en-GB\">\\n'\n",
      " '       <div class=\"screen-reader-response\">\\n'\n",
      " '        <p aria-atomic=\"true\" aria-live=\"polite\" role=\"status\">\\n'\n",
      " '        </p>\\n'\n",
      " '        <ul>\\n'\n",
      " '        </ul>\\n'\n",
      " '       </div>\\n'\n",
      " '       <form '\n",
      " 'action=\"/blog/hyperparameter-optimization-for-llms#wpcf7-f36762-p43609-o1\" '\n",
      " 'aria-label=\"Contact form\" class=\"wpcf7-form init\" data-status=\"init\" '\n",
      " 'method=\"post\" novalidate=\"novalidate\">\\n'\n",
      " '        <div style=\"display: none;\">\\n'\n",
      " '         <input name=\"_wpcf7\" type=\"hidden\" value=\"36762\"/>\\n'\n",
      " '         <input name=\"_wpcf7_version\" type=\"hidden\" value=\"6.0.5\"/>\\n'\n",
      " '         <input name=\"_wpcf7_locale\" type=\"hidden\" value=\"en_GB\"/>\\n'\n",
      " '         <input name=\"_wpcf7_unit_tag\" type=\"hidden\" '\n",
      " 'value=\"wpcf7-f36762-p43609-o1\"/>\\n'\n",
      " '         <input name=\"_wpcf7_container_post\" type=\"hidden\" value=\"43609\"/>\\n'\n",
      " '         <input name=\"_wpcf7_posted_data_hash\" type=\"hidden\" value=\"\"/>\\n'\n",
      " '         <input name=\"_wpcf7_recaptcha_response\" type=\"hidden\" value=\"\"/>\\n'\n",
      " '        </div>\\n'\n",
      " '        <label for=\"email\">\\n'\n",
      " '         Your email\\n'\n",
      " '        </label>\\n'\n",
      " '        <span class=\"wpcf7-form-control-wrap\" data-name=\"email-546\">\\n'\n",
      " '         <input aria-invalid=\"false\" class=\"wpcf7-form-control wpcf7-email '\n",
      " 'wpcf7-text wpcf7-validates-as-email fz-input fz-input--regular\" '\n",
      " 'maxlength=\"400\" name=\"email-546\" placeholder=\"Your email\" size=\"40\" '\n",
      " 'type=\"email\" value=\"\"/>\\n'\n",
      " '        </span>\\n'\n",
      " '        <label for=\"message\">\\n'\n",
      " '         Your message (optional)\\n'\n",
      " '        </label>\\n'\n",
      " '        <span class=\"wpcf7-form-control-wrap\" data-name=\"message\">\\n'\n",
      " '         <textarea aria-invalid=\"false\" class=\"wpcf7-form-control '\n",
      " 'wpcf7-textarea fz-input fz-input--regular\" cols=\"40\" maxlength=\"2000\" '\n",
      " 'name=\"message\" placeholder=\"Describe here exactly which parts of the article '\n",
      " 'should be changed or whether missing information should be added...\" '\n",
      " 'rows=\"10\"></textarea>\\n'\n",
      " '        </span>\\n'\n",
      " '        <div class=\"c-form__captcha-info\">\\n'\n",
      " '         This site is protected by reCAPTCHA and the Google\\n'\n",
      " '         <a href=\"https://policies.google.com/privacy\" rel=\"nofollow '\n",
      " 'noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '          Privacy Policy\\n'\n",
      " '         </a>\\n'\n",
      " '         and\\n'\n",
      " '         <a href=\"https://policies.google.com/terms\" rel=\"nofollow noopener '\n",
      " 'noreferrer\" target=\"_blank\">\\n'\n",
      " '          Terms of Service\\n'\n",
      " '         </a>\\n'\n",
      " '         apply.\\n'\n",
      " '        </div>\\n'\n",
      " '        <div class=\"c-form__acceptance-info c-modal__custom-checkbox '\n",
      " 'fz-acceptance\">\\n'\n",
      " '         <label class=\"privacy-policy\" id=\"privacy-policy\">\\n'\n",
      " '          <span class=\"wpcf7-form-control-wrap\" data-name=\"privacy-policy\">\\n'\n",
      " '           <span class=\"wpcf7-form-control wpcf7-acceptance\">\\n'\n",
      " '            <span class=\"wpcf7-list-item\">\\n'\n",
      " '             <label>\\n'\n",
      " '              <input aria-invalid=\"false\" name=\"privacy-policy\" '\n",
      " 'type=\"checkbox\" value=\"1\"/>\\n'\n",
      " '              <span class=\"wpcf7-list-item-label\">\\n'\n",
      " '               <span class=\"checkmark\">\\n'\n",
      " '               </span>\\n'\n",
      " '               <span>\\n'\n",
      " '                I am familiar with the\\n'\n",
      " '               </span>\\n'\n",
      " '               <a href=\"https://neptune.staginglab.eu/privacy-policy\">\\n'\n",
      " '                Privacy Policy\\n'\n",
      " '               </a>\\n'\n",
      " '               *\\n'\n",
      " '              </span>\\n'\n",
      " '             </label>\\n'\n",
      " '            </span>\\n'\n",
      " '           </span>\\n'\n",
      " '          </span>\\n'\n",
      " '         </label>\\n'\n",
      " '        </div>\\n'\n",
      " '        <div class=\"wpcf7-submit-loader js-wpcf7-submit\">\\n'\n",
      " '         <button class=\"wpcf7-form-control wpcf7-submit c-button '\n",
      " 'c-button--primary c-button--regular\">\\n'\n",
      " '          <span class=\"c-button__text\">\\n'\n",
      " '           Submit\\n'\n",
      " '          </span>\\n'\n",
      " '         </button>\\n'\n",
      " '        </div>\\n'\n",
      " '        <p class=\"akismet-fields-container\" data-prefix=\"_wpcf7_ak_\" '\n",
      " 'style=\"display: none !important;\">\\n'\n",
      " '         <label>\\n'\n",
      " '          Œî\\n'\n",
      " '          <textarea cols=\"45\" maxlength=\"100\" name=\"_wpcf7_ak_hp_textarea\" '\n",
      " 'rows=\"8\"></textarea>\\n'\n",
      " '         </label>\\n'\n",
      " '         <input id=\"ak_js_1\" name=\"_wpcf7_ak_js\" type=\"hidden\" value=\"48\"/>\\n'\n",
      " '        </p>\\n'\n",
      " '        <div aria-hidden=\"true\" class=\"wpcf7-response-output\">\\n'\n",
      " '        </div>\\n'\n",
      " '       </form>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </div>\\n'\n",
      " '   <div class=\"c-i-box c-i-box--blog\">\\n'\n",
      " '    <h4 class=\"c-header-2\">\\n'\n",
      " '     Check out our\\n'\n",
      " '     <span>\\n'\n",
      " '      <svg fill=\"none\" height=\"16\" viewbox=\"0 0 16 16\" width=\"16\" '\n",
      " 'xmlns=\"http://www.w3.org/2000/svg\">\\n'\n",
      " '       <path d=\"M8 0C8.44183 0 8.8 0.358172 8.8 0.8V1.6C8.8 2.04183 8.44183 '\n",
      " '2.4 8 2.4C7.55817 2.4 7.2 2.04183 7.2 1.6V0.8C7.2 0.358172 7.55817 0 8 0Z\" '\n",
      " 'fill=\"white\">\\n'\n",
      " '       </path>\\n'\n",
      " '       <path d=\"M9.6 13.6V14.8C9.6 15.4627 9.06274 16 8.4 16H7.6C6.93726 16 '\n",
      " '6.4 15.4627 6.4 14.8V13.6H9.6Z\" fill=\"white\">\\n'\n",
      " '       </path>\\n'\n",
      " '       <path d=\"M14.4 7.2C13.9582 7.2 13.6 7.55817 13.6 8C13.6 8.44183 '\n",
      " '13.9582 8.8 14.4 8.8H15.2C15.6418 8.8 16 8.44183 16 8C16 7.55817 15.6418 7.2 '\n",
      " '15.2 7.2H14.4Z\" fill=\"white\">\\n'\n",
      " '       </path>\\n'\n",
      " '       <path d=\"M0 8C0 7.55817 0.358172 7.2 0.8 7.2H1.6C2.04183 7.2 2.4 '\n",
      " '7.55817 2.4 8C2.4 8.44183 2.04183 8.8 1.6 8.8H0.8C0.358172 8.8 0 8.44183 0 '\n",
      " '8Z\" fill=\"white\">\\n'\n",
      " '       </path>\\n'\n",
      " '       <path d=\"M3.47452 2.34315C3.1621 2.03073 2.65557 2.03073 2.34315 '\n",
      " '2.34315C2.03073 2.65557 2.03073 3.1621 2.34315 3.47452L2.90883 '\n",
      " '4.04021C3.22125 4.35263 3.72778 4.35263 4.0402 4.04021C4.35262 3.72779 '\n",
      " '4.35262 3.22126 4.0402 2.90884L3.47452 2.34315Z\" fill=\"white\">\\n'\n",
      " '       </path>\\n'\n",
      " '       <path d=\"M11.9598 4.0402C11.6474 3.72778 11.6474 3.22125 11.9598 '\n",
      " '2.90883L12.5255 2.34314C12.8379 2.03072 13.3444 2.03072 13.6569 '\n",
      " '2.34314C13.9693 2.65556 13.9693 3.16209 13.6569 3.47451L13.0912 '\n",
      " '4.0402C12.7787 4.35262 12.2722 4.35262 11.9598 4.0402Z\" fill=\"white\">\\n'\n",
      " '       </path>\\n'\n",
      " '       <path d=\"M10.6144 9.04566C10.1198 9.74514 9.6 10.4995 9.6 '\n",
      " '11.3563V12H6.4V11.3563C6.4 10.4995 5.88024 9.74514 5.38555 9.04566C5.01672 '\n",
      " '8.52413 4.8 7.88737 4.8 7.2C4.8 5.43267 6.23269 4 8 4C9.76731 4 11.2 5.43267 '\n",
      " '11.2 7.2C11.2 7.88737 10.9833 8.52413 10.6144 9.04566Z\" fill=\"white\">\\n'\n",
      " '       </path>\\n'\n",
      " '      </svg>\\n'\n",
      " '      <strong>\\n'\n",
      " '       product resources\\n'\n",
      " '      </strong>\\n'\n",
      " '     </span>\\n'\n",
      " '     and\\n'\n",
      " '     <span>\\n'\n",
      " '      <svg fill=\"none\" height=\"16\" viewbox=\"0 0 16 16\" width=\"16\" '\n",
      " 'xmlns=\"http://www.w3.org/2000/svg\">\\n'\n",
      " '       <path clip-rule=\"evenodd\" d=\"M6.20005 '\n",
      " '2.5998H13.4V9.7998H12.5V11.5998H13.4C14.3942 11.5998 15.2 10.7939 15.2 '\n",
      " '9.7998V2.5998C15.2 1.60569 14.3942 0.799805 13.4 0.799805H6.20005C5.20594 '\n",
      " '0.799805 4.40005 1.60569 4.40005 2.5998V3.4998H6.20005V2.5998ZM2.60005 '\n",
      " '13.3998L2.60005 6.1998H9.80005V13.3998H2.60005ZM0.800049 6.1998C0.800049 '\n",
      " '5.20569 1.60594 4.3998 2.60005 4.3998H9.80005C10.7942 4.3998 11.6 5.20569 '\n",
      " '11.6 6.1998V13.3998C11.6 14.3939 10.7942 15.1998 9.80005 '\n",
      " '15.1998H2.60005C1.60594 15.1998 0.800049 14.3939 0.800049 13.3998V6.1998Z\" '\n",
      " 'fill=\"white\" fill-rule=\"evenodd\">\\n'\n",
      " '       </path>\\n'\n",
      " '      </svg>\\n'\n",
      " '      <strong>\\n'\n",
      " '       related articles\\n'\n",
      " '      </strong>\\n'\n",
      " '     </span>\\n'\n",
      " '     below:\\n'\n",
      " '    </h4>\\n'\n",
      " '    <div class=\"c-i-box-grid\">\\n'\n",
      " '     <a class=\"c-i-box-grid-box\" '\n",
      " 'href=\"https://neptune.ai/blog/building-the-most-scalable-experiment-tracker-for-foundation-models\" '\n",
      " 'rel=\"noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '      <span class=\"c-i-box-grid-box__source\">\\n'\n",
      " '       <img alt=\"\" decoding=\"async\" height=\"11\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/ibox-related.svg\" '\n",
      " 'width=\"11\"/>\\n'\n",
      " '       Related article\\n'\n",
      " '      </span>\\n'\n",
      " '      <h4 class=\"c-i-box-grid-box__title\">\\n'\n",
      " '       From Research to Production: Building The Most Scalable Experiment '\n",
      " 'Tracker For Foundation Models\\n'\n",
      " '      </h4>\\n'\n",
      " '      <span class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '       <span class=\"c-button__text\">\\n'\n",
      " '        Read more\\n'\n",
      " '       </span>\\n'\n",
      " '       <img alt=\"chevron\" class=\"c-button__arrow\" decoding=\"async\" '\n",
      " 'height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '      </span>\\n'\n",
      " '     </a>\\n'\n",
      " '     <a class=\"c-i-box-grid-box\" '\n",
      " 'href=\"https://neptune.ai/blog/building-and-evaluating-rag-system-using-langchain-ragas-neptune\" '\n",
      " 'rel=\"noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '      <span class=\"c-i-box-grid-box__source\">\\n'\n",
      " '       <img alt=\"\" decoding=\"async\" height=\"11\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/ibox-related.svg\" '\n",
      " 'width=\"11\"/>\\n'\n",
      " '       Related article\\n'\n",
      " '      </span>\\n'\n",
      " '      <h4 class=\"c-i-box-grid-box__title\">\\n'\n",
      " '       How to Build and Evaluate a RAG System Using LangChain, Ragas, and '\n",
      " 'neptune.ai\\n'\n",
      " '      </h4>\\n'\n",
      " '      <span class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '       <span class=\"c-button__text\">\\n'\n",
      " '        Read more\\n'\n",
      " '       </span>\\n'\n",
      " '       <img alt=\"chevron\" class=\"c-button__arrow\" decoding=\"async\" '\n",
      " 'height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '      </span>\\n'\n",
      " '     </a>\\n'\n",
      " '     <a class=\"c-i-box-grid-box\" '\n",
      " 'href=\"https://neptune.ai/blog/fine-tuning-llama-3-with-lora\" rel=\"noopener '\n",
      " 'noreferrer\" target=\"_blank\">\\n'\n",
      " '      <span class=\"c-i-box-grid-box__source\">\\n'\n",
      " '       <img alt=\"\" decoding=\"async\" height=\"11\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/ibox-related.svg\" '\n",
      " 'width=\"11\"/>\\n'\n",
      " '       Related article\\n'\n",
      " '      </span>\\n'\n",
      " '      <h4 class=\"c-i-box-grid-box__title\">\\n'\n",
      " '       Fine-Tuning Llama 3 with LoRA: Step-by-Step Guide\\n'\n",
      " '      </h4>\\n'\n",
      " '      <span class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '       <span class=\"c-button__text\">\\n'\n",
      " '        Read more\\n'\n",
      " '       </span>\\n'\n",
      " '       <img alt=\"chevron\" class=\"c-button__arrow\" decoding=\"async\" '\n",
      " 'height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '      </span>\\n'\n",
      " '     </a>\\n'\n",
      " '     <a class=\"c-i-box-grid-box\" href=\"https://neptune.ai/customers/artera\" '\n",
      " 'rel=\"noopener noreferrer\" target=\"_blank\">\\n'\n",
      " '      <span class=\"c-i-box-grid-box__source\">\\n'\n",
      " '       <img alt=\"\" decoding=\"async\" height=\"11\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/ibox-bulb.svg\" '\n",
      " 'width=\"11\"/>\\n'\n",
      " '       Product resource\\n'\n",
      " '      </span>\\n'\n",
      " '      <h4 class=\"c-i-box-grid-box__title\">\\n'\n",
      " '       How Neptune Helps Artera Bring AI Solutions to Market Faster\\n'\n",
      " '      </h4>\\n'\n",
      " '      <span class=\"c-button c-button--tertiary c-button--small\">\\n'\n",
      " '       <span class=\"c-button__text\">\\n'\n",
      " '        Read more\\n'\n",
      " '       </span>\\n'\n",
      " '       <img alt=\"chevron\" class=\"c-button__arrow\" decoding=\"async\" '\n",
      " 'height=\"10\" loading=\"lazy\" '\n",
      " 'src=\"https://neptune.ai/wp-content/themes/neptune/img/icon-button-arrow-right.svg\" '\n",
      " 'width=\"10\"/>\\n'\n",
      " '      </span>\\n'\n",
      " '     </a>\\n'\n",
      " '    </div>\\n'\n",
      " '    <div class=\"c-i-box-topics\">\\n'\n",
      " '     <h3 class=\"c-i-box-topics__title\">\\n'\n",
      " '      Explore more content topics:\\n'\n",
      " '     </h3>\\n'\n",
      " '     <div class=\"c-i-box-tags\">\\n'\n",
      " '      <div class=\"c-categories c-categories--clickable c-categories--wrap '\n",
      " 'c-categories--align-left\">\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/computer-vision\">\\n'\n",
      " '        Computer Vision\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/general\">\\n'\n",
      " '        General\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/llmops\">\\n'\n",
      " '        LLMOps\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/machine-learning-model-development\">\\n'\n",
      " '        ML Model Development\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/machine-learning-tools\">\\n'\n",
      " '        ML Tools\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/mlops\">\\n'\n",
      " '        MLOps\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/natural-language-processing\">\\n'\n",
      " '        Natural Language Processing\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/paper-reflections\">\\n'\n",
      " '        Paper Reflections\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/product-updates\">\\n'\n",
      " '        Product Updates\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/reinforcement-learning\">\\n'\n",
      " '        Reinforcement Learning\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/tabular-data\">\\n'\n",
      " '        Tabular Data\\n'\n",
      " '       </a>\\n'\n",
      " '       <a class=\"c-category c-category--neutral\" '\n",
      " 'href=\"https://neptune.ai/blog/category/time-series-forecasting\">\\n'\n",
      " '        Time Series\\n'\n",
      " '       </a>\\n'\n",
      " '      </div>\\n'\n",
      " '     </div>\\n'\n",
      " '    </div>\\n'\n",
      " '   </div>\\n'\n",
      " '  </div>\\n'\n",
      " ' </div>\\n'\n",
      " '</article>\\n')\n"
     ]
    }
   ],
   "source": [
    "from main_content_extractor import MainContentExtractor\n",
    "\n",
    "extracted_html = MainContentExtractor.extract(html)\n",
    "pprint(extracted_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Paull Young\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Maintainers\\n'\n",
      " '\\n'\n",
      " '###   5 GitHub Actions every maintainer needs to know\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'With these actions, you can keep your open source projects organized, '\n",
      " 'minimize\\n'\n",
      " 'repetitive and manual tasks, and focus more on writing code.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Git\\n'\n",
      " '\\n'\n",
      " '###   Highlights from Git 2.49 \\n'\n",
      " '\\n'\n",
      " 'The open source Git project just released Git 2.49. Here is GitHub‚Äôs look '\n",
      " 'at\\n'\n",
      " 'some of the most interesting features and changes introduced since last '\n",
      " 'time.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Maintainers\\n'\n",
      " '\\n'\n",
      " '###   4 steps toward building an open source community\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Three maintainers talk about how they fostered their open source '\n",
      " 'communities.\\n'\n",
      " '\\n')\n",
      "1347 535\n",
      "('Paull Young\\n'\n",
      " 'Maintainers\\n'\n",
      " '5 GitHub Actions every maintainer needs to know\\n'\n",
      " 'With these actions, you can keep your open source projects organized, '\n",
      " 'minimize repetitive and manual tasks, and focus more on writing code.\\n'\n",
      " 'Git\\n'\n",
      " 'Highlights from Git 2.49 \\n'\n",
      " 'The open source Git project just released Git 2.49. Here is GitHub‚Äôs look at '\n",
      " 'some of the most interesting features and changes introduced since last '\n",
      " 'time.\\n'\n",
      " 'Maintainers\\n'\n",
      " '4 steps toward building an open source community\\n'\n",
      " 'Three maintainers talk about how they fostered their open source '\n",
      " 'communities.')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_markdown(text):\n",
    "\n",
    "    # Remove urls\n",
    "    text = re.sub(r'(https?:\\/\\/|www\\.)([\\w\\.\\/-]+)', r'', text)\n",
    "\n",
    "    # Remove images but preserve alt text if present\n",
    "    text = re.sub(r'!\\[([^\\]]*?)\\]\\(.*?\\)', r'\\1', text, flags=re.DOTALL)\n",
    "\n",
    "    # Remove remaining links but keep the link text\n",
    "    text = re.sub(r'\\[([^\\]]*?)\\]\\(.*?\\)', r'\\1', text, flags=re.DOTALL)\n",
    "    pprint(text)\n",
    "\n",
    "    # Fix dashes separated by line breaks (e.g., \"-\\nword\" ‚Üí \"-word\")\n",
    "    text = re.sub(r'(-)\\n(\\w)', r'\\1\\2', text)\n",
    "\n",
    "    # Merge broken lines that are not paragraph breaks\n",
    "    text = re.sub(r'(\\S)\\n(?=\\S)', r'\\1 ', text)\n",
    "\n",
    "    # Fix markdown bullet lists\n",
    "    text = re.sub(r'\\s*\\*\\s*', r'\\n* ', text)\n",
    "\n",
    "    # Fix markdown numbered lists\n",
    "    text = re.sub(r' +(\\d+\\.) +', r'\\n\\1 ', text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # Remove lines full of [ \\*#\\n]\n",
    "    text = re.sub(r'\\n[ \\*#\\n]*', r'\\n', text, flags=re.DOTALL)\n",
    "\n",
    "    # Normalize whitespace and line breaks\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)         # Collapse multiple newlines\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)          # Collapse multiple spaces/tabs\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def extract_markdown_from_html(html):\n",
    "    extracted = MainContentExtractor.extract(html, output_format=\"markdown\")\n",
    "    return clean_markdown(extracted)\n",
    "\n",
    "test_url = \"https://github.blog/open-source/world-water-day-how-github-copilot-is-helping-bring-clean-water-to-communities/\"\n",
    "html = fetch_html(test_url)\n",
    "extracted_markdown = MainContentExtractor.extract(html, output_format=\"markdown\")\n",
    "cleaned_extracted_markdown = extract_markdown_from_html(html)\n",
    "print(len(extracted_markdown), len(cleaned_extracted_markdown))\n",
    "pprint(cleaned_extracted_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('![Paull Young](https://avatars.githubusercontent.com/u/157849754?v=4&s=200)\\n'\n",
      " '\\n'\n",
      " '![](https://github.blog/wp-content/uploads/2024/04/1200x630-Productivity-\\n'\n",
      " 'Unfurl-LIGHT-Logo@2x.png?resize=400%2C212)\\n'\n",
      " '\\n'\n",
      " '[Maintainers](https://github.blog/open-source/maintainers/)\\n'\n",
      " '\\n'\n",
      " '###  [ 5 GitHub Actions every maintainer needs to know\\n'\n",
      " '](https://github.blog/open-source/maintainers/5-github-actions-every-\\n'\n",
      " 'maintainer-needs-to-know/)\\n'\n",
      " '\\n'\n",
      " 'With these actions, you can keep your open source projects organized, '\n",
      " 'minimize\\n'\n",
      " 'repetitive and manual tasks, and focus more on writing code.\\n'\n",
      " '\\n'\n",
      " '![](https://github.blog/wp-\\n'\n",
      " 'content/uploads/2025/03/Git-249.png?resize=400%2C212)\\n'\n",
      " '\\n'\n",
      " '[Git](https://github.blog/open-source/git/)\\n'\n",
      " '\\n'\n",
      " '###  [ Highlights from Git 2.49 ](https://github.blog/open-\\n'\n",
      " 'source/git/highlights-from-git-2-49/)\\n'\n",
      " '\\n'\n",
      " 'The open source Git project just released Git 2.49. Here is GitHub‚Äôs look '\n",
      " 'at\\n'\n",
      " 'some of the most interesting features and changes introduced since last '\n",
      " 'time.\\n'\n",
      " '\\n'\n",
      " '![](https://github.blog/wp-content/uploads/2024/04/1200x630-Collaboration-\\n'\n",
      " 'Unfurl-LIGHT-Logo.png?resize=400%2C212)\\n'\n",
      " '\\n'\n",
      " '[Maintainers](https://github.blog/open-source/maintainers/)\\n'\n",
      " '\\n'\n",
      " '###  [ 4 steps toward building an open source community\\n'\n",
      " '](https://github.blog/open-source/maintainers/four-steps-toward-building-an-\\n'\n",
      " 'open-source-community/)\\n'\n",
      " '\\n'\n",
      " 'Three maintainers talk about how they fostered their open source '\n",
      " 'communities.\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(extracted_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.marktechpost.com/2025/03/11/reka-ai-open-sourced-reka-flash-3-a-21b-general-purpose-reasoning-model-that-was-trained-from-scratch/\n",
      "https://venturebeat.com/2022/03/15/you-com-partners-with-openai-to-launch-an-ai-powered-writing-tool/\n",
      "https://ai.facebook.com/blog/blenderbot-3-a-175b-parameter-publicly-available-chatbot-that-improves-its-skills-and-safety-over-time/\n",
      "https://venturebeat.com/2022/04/18/linkedin-creates-pass-to-tailor-graph-neural-networks-for-social-media/\n",
      "https://huggingface.co/blog/sagemaker-huggingface-llm\n"
     ]
    }
   ],
   "source": [
    "good_articles = pd.read_csv('../research/data/good_articles.csv')\n",
    "for url in good_articles.sample(5).link_url:\n",
    "    print(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
